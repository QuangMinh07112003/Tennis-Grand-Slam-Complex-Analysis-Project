{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73cffc75",
   "metadata": {},
   "source": [
    "# Name: Minh Trinh\n",
    "# Subject: Independent Study: Tennis Grand Slam Complex Analysis: A Statistical Approach into the Most Popular Racket Sports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8359ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca864ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de997b0",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fceb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import datasets Point by Point\n",
    "\n",
    "#Australian Open\n",
    "ao19 = pd.read_csv('ao19.csv')\n",
    "ao20 = pd.read_csv('ao20.csv')\n",
    "ao21 = pd.read_csv('ao21.csv')\n",
    "\n",
    "#Roland Garros\n",
    "rg19 = pd.read_csv('rg19.csv')\n",
    "rg20 = pd.read_csv('rg20.csv')\n",
    "rg21 = pd.read_csv('rg21.csv')\n",
    "\n",
    "#Wimbledon\n",
    "wim19 = pd.read_csv('wim19.csv')\n",
    "wim21 = pd.read_csv('wim21.csv')\n",
    "wim22 = pd.read_csv('wim22.csv')\n",
    "wim23 = pd.read_csv('wim23.csv')\n",
    "\n",
    "#US Open\n",
    "us19 = pd.read_csv('us19.csv')\n",
    "us20 = pd.read_csv('us20.csv')\n",
    "us21 = pd.read_csv('us21.csv')\n",
    "us22 = pd.read_csv('us22.csv')\n",
    "us23 = pd.read_csv('us23.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ac5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs19 = pd.read_csv('gs_2019.csv')\n",
    "gs20 = pd.read_csv('gs_2020.csv')\n",
    "gs21 = pd.read_csv('gs_2021.csv')\n",
    "gs22 = pd.read_csv('gs_2022.csv')\n",
    "gs23 = pd.read_csv('gs_2023.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9031e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUSTRALIAN OPEN MATCHES\n",
    "ao19_m = pd.read_csv('ao19_m.csv')\n",
    "ao20_m = pd.read_csv('ao20_m.csv')\n",
    "ao21_m = pd.read_csv('ao21_m.csv')\n",
    "\n",
    "#print(ao19_m.iloc[126])\n",
    "ao19_m = ao19_m.iloc[:127]\n",
    "\n",
    "#print(ao20_m.iloc[125])\n",
    "ao20_m = ao20_m.iloc[:126]\n",
    "\n",
    "#print(ao21_m.iloc[126])\n",
    "ao21_m = ao21_m.iloc[:127]\n",
    "\n",
    "ao_m = pd.concat([ao19_m, ao20_m, ao21_m], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a920e32",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e84a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROLAND GARROS MATCHES\n",
    "rg19_m = pd.read_csv('rg19_m.csv')\n",
    "rg20_m = pd.read_csv('rg20_m.csv')\n",
    "rg21_m = pd.read_csv('rg21_m.csv')\n",
    "\n",
    "#print(rg19_m.iloc[126])\n",
    "rg19_m = rg19_m.iloc[:127]\n",
    "\n",
    "#print(rg20_m.iloc[126])\n",
    "rg20_m = rg20_m.iloc[:127]\n",
    "\n",
    "#print(rg21_m.iloc[126])\n",
    "rg21_m = rg21_m.iloc[:127]\n",
    "\n",
    "rg_m = pd.concat([rg19_m, rg20_m, rg21_m], axis=0, ignore_index=True)\n",
    "\n",
    "#rg_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d593bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIMBLEDON MATCHES\n",
    "wim19_m = pd.read_csv('wim19_m.csv')\n",
    "wim21_m = pd.read_csv('wim21_m.csv')\n",
    "wim22_m = pd.read_csv('wim22_m.csv')\n",
    "wim23_m = pd.read_csv('wim23_m.csv')\n",
    "\n",
    "#print(wim19_m.iloc[126])\n",
    "wim19_m = wim19_m.iloc[:127]\n",
    "\n",
    "#print(wim21_m.iloc[125])\n",
    "wim21_m = wim21_m.iloc[:126]\n",
    "\n",
    "#print(wim22_m.iloc[124])\n",
    "wim22_m = wim22_m.iloc[:125]\n",
    "\n",
    "#print(wim23_m.iloc[126])\n",
    "wim23_m = wim23_m.iloc[:127]\n",
    "\n",
    "wim_m = pd.concat([wim19_m, wim21_m, wim22_m, wim23_m], axis=0, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37597822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#US OPEN MATCHES\n",
    "us19_m = pd.read_csv('us19_m.csv')\n",
    "us20_m = pd.read_csv('us20_m.csv')\n",
    "us21_m = pd.read_csv('us21_m.csv')\n",
    "us22_m = pd.read_csv('us22_m.csv')\n",
    "us23_m = pd.read_csv('us23_m.csv')\n",
    "\n",
    "#Delete women's singles\n",
    "#print(us19_m.iloc[124]) #last men's singles match\n",
    "us19_m = us19_m.iloc[:125]\n",
    "\n",
    "\n",
    "#print(us20_m.iloc[123]) \n",
    "us20_m = us20_m.iloc[:124]\n",
    "\n",
    "#print(us21_m.iloc[126]) \n",
    "us21_m = us21_m.iloc[:127]\n",
    "\n",
    "#print(us22_m.iloc[125])\n",
    "us22_m = us22_m.iloc[:126]\n",
    "\n",
    "#print(us23_m.iloc[126])\n",
    "us23_m = us23_m.iloc[:127]\n",
    "\n",
    "\n",
    "#Concatenate all datasets into US Open dataset 'us'\n",
    "us_m = pd.concat([us19_m, us20_m, us21_m, us22_m, us23_m], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3e53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the datasets into a single DataFrame\n",
    "gs_m = pd.concat([ao_m, rg_m, wim_m, us_m], ignore_index=True)\n",
    "\n",
    "# Display the resulting merged DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfedc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the datasets vertically\n",
    "us = pd.concat([us19, us20, us21, us22, us23], axis=0, ignore_index=True)\n",
    "wim = pd.concat([wim19, wim21, wim22, wim23], axis=0, ignore_index=True)\n",
    "rg = pd.concat([rg19, rg20, rg21], axis=0, ignore_index=True)\n",
    "ao = pd.concat([ao19, ao20, ao21], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be8caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the left merge, keeping all rows from 'us' and only adding 'player1' and 'player2' from 'us_m'\n",
    "us = pd.merge(us, us_m[['match_id', 'player1', 'player2']], on='match_id', how='left')\n",
    "\n",
    "# Drop rows where 'player1' or 'player2' is NaN, to drop all the points of the women's singles\n",
    "us = us.dropna(subset=['player1', 'player2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e526f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the left merge, keeping all rows from 'us' and only adding 'player1' and 'player2' from 'us_m'\n",
    "wim = pd.merge(wim, wim_m[['match_id', 'player1', 'player2']], on='match_id', how='left')\n",
    "ao = pd.merge(ao, ao_m[['match_id', 'player1', 'player2']], on='match_id', how='left')\n",
    "rg = pd.merge(rg, rg_m[['match_id', 'player1', 'player2']], on='match_id', how='left')\n",
    "\n",
    "# Drop rows where 'player1' or 'player2' is NaN, to drop all the points of the women's singles\n",
    "wim = wim.dropna(subset=['player1', 'player2'])\n",
    "rg = rg.dropna(subset=['player1', 'player2'])\n",
    "ao = ao.dropna(subset=['player1', 'player2'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e61c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.count of match_id         0.0\n",
      "ElapsedTime    100.0\n",
      "SetNo            0.0\n",
      "P1GamesWon     100.0\n",
      "P2GamesWon     100.0\n",
      "               ...  \n",
      "ServeWidth     100.0\n",
      "ServeDepth     100.0\n",
      "ReturnDepth    100.0\n",
      "player1          0.0\n",
      "player2          0.0\n",
      "Length: 67, dtype: float64>\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of null values for each column\n",
    "null_percentage = ao.isnull().mean() * 100\n",
    "\n",
    "# Display percentage of null values per column\n",
    "print(null_percentage.count)\n",
    "\n",
    "# Filter columns where null percentage is greater than 40%\n",
    "columns_with_null_above_40 = null_percentage[null_percentage < 40].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7078210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_columns_with_null_above_70(tournament_name):\n",
    "    # Calculate percentage of null values for each column\n",
    "    null_percentage = tournament_name.isnull().mean() * 100\n",
    "\n",
    "    # Identify columns with more than 70% null values\n",
    "    columns_with_null_above_70 = null_percentage[null_percentage > 70].index\n",
    "\n",
    "    # Drop those columns from the dataset\n",
    "    tournament_name_cleaned = tournament_name.drop(columns=columns_with_null_above_70)\n",
    "\n",
    "    # Return the cleaned dataset\n",
    "    return tournament_name_cleaned\n",
    "\n",
    "# Example usage\n",
    "wim = delete_columns_with_null_above_70(wim)\n",
    "ao = delete_columns_with_null_above_70(ao)\n",
    "rg = delete_columns_with_null_above_70(rg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd8de271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the threshold for non-missing values\n",
    "threshold = len(us) * 0.4  # 40% non-missing values\n",
    "\n",
    "# Drop columns where non-NaN values are less than the threshold\n",
    "us = us.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# If RallyCount = 1, there is no returns, no matter if it's out/hit to the net returns will be classified as 'M' or Missed\n",
    "us.loc[(us['RallyCount'] == 1) & (us['ReturnDepth'].isna()), 'ReturnDepth'] = 'M'\n",
    "wim.loc[(wim['RallyCount'] == 1) & (wim['ReturnDepth'].isna()), 'ReturnDepth'] = 'M'\n",
    "\n",
    "\n",
    "# Replace ReturnDepth with 'M' where RallyCount is 1\n",
    "us.loc[us['RallyCount'] == 1, 'ReturnDepth'] = 'M'\n",
    "wim.loc[wim['RallyCount'] == 1, 'ReturnDepth'] = 'M'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8015b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ServeWidth', 'ServeDepth', 'ReturnDepth', 'P1DistanceRun', 'P2DistanceRun']\n",
    "\n",
    "# Step 1: Create a mask for NaN values\n",
    "nan_mask = wim[cols].isna()\n",
    "\n",
    "# Step 2: Check if at least 2 out of 3 columns are NaN\n",
    "nan_condition = nan_mask.sum(axis=1) >= 3\n",
    "\n",
    "# Step 3: For each match_id, calculate consecutive NaNs\n",
    "def remove_consecutive_nans(group):\n",
    "    # Identify consecutive NaNs\n",
    "    group['consecutive_nans'] = nan_condition.rolling(window=21).sum() >= 10\n",
    "    # Remove rows where consecutive_nans is True\n",
    "    return group[~group['consecutive_nans']].drop(columns=['consecutive_nans'])\n",
    "\n",
    "# Step 4: Apply the function to each match_id group\n",
    "wim = wim.groupby('match_id', group_keys=False).apply(remove_consecutive_nans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4fffc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition where either P1DoubleFaults or P2DoubleFaults equals 1\n",
    "condition = (us['P1DoubleFault'] == 1) | (us['P2DoubleFault'] == 1)\n",
    "condition1 = (wim['P1DoubleFault'] == 1) | (wim['P2DoubleFault'] == 1)\n",
    "\n",
    "\n",
    "# Update ServeDepth, ServeWidth, and ReturnDepth to 0 when the condition is met\n",
    "us.loc[condition, ['ServeDepth', 'ServeWidth', 'ReturnDepth']] = '0'\n",
    "wim.loc[condition1, ['ServeDepth', 'ServeWidth', 'ReturnDepth']] = '0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19a3073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id               0.000000\n",
      "ElapsedTime            0.000000\n",
      "SetNo                  0.000000\n",
      "P1GamesWon             0.000000\n",
      "P2GamesWon             0.000000\n",
      "SetWinner              0.000000\n",
      "GameNo                 0.000000\n",
      "GameWinner             0.000000\n",
      "PointNumber            0.000000\n",
      "PointWinner            0.000000\n",
      "PointServer            0.000000\n",
      "Speed_KMH              0.000000\n",
      "P1Score                0.000000\n",
      "P2Score                0.000000\n",
      "P1Momentum             0.000000\n",
      "P2Momentum             0.000000\n",
      "P1PointsWon            0.000000\n",
      "P2PointsWon            0.000000\n",
      "P1Ace                  0.000000\n",
      "P2Ace                  0.000000\n",
      "P1Winner               0.000000\n",
      "P2Winner               0.000000\n",
      "P1DoubleFault          0.000000\n",
      "P2DoubleFault          0.000000\n",
      "P1UnfErr               0.000000\n",
      "P2UnfErr               0.000000\n",
      "P1NetPoint             0.000000\n",
      "P2NetPoint             0.000000\n",
      "P1NetPointWon          0.000000\n",
      "P2NetPointWon          0.000000\n",
      "P1BreakPoint           0.000000\n",
      "P2BreakPoint           0.000000\n",
      "P1BreakPointWon        0.000000\n",
      "P2BreakPointWon        0.000000\n",
      "History                0.924884\n",
      "Speed_MPH              0.000000\n",
      "P1BreakPointMissed     0.000000\n",
      "P2BreakPointMissed     0.000000\n",
      "ServeIndicator         0.000000\n",
      "ServeNumber            0.000000\n",
      "WinnerType             0.000000\n",
      "WinnerShotType         0.000000\n",
      "P1DistanceRun          0.000000\n",
      "P2DistanceRun          0.000000\n",
      "RallyCount             0.000000\n",
      "ServeWidth            17.377689\n",
      "ServeDepth            17.377689\n",
      "ReturnDepth           15.598050\n",
      "player1                0.000000\n",
      "player2                0.000000\n",
      "dtype: float64\n",
      "match_id              0.000000\n",
      "ElapsedTime           0.000000\n",
      "SetNo                 0.000000\n",
      "P1GamesWon            0.000000\n",
      "P2GamesWon            0.000000\n",
      "SetWinner             0.000000\n",
      "GameNo                0.000000\n",
      "GameWinner            0.000000\n",
      "PointNumber           0.000000\n",
      "PointWinner           0.000000\n",
      "PointServer           0.000000\n",
      "Speed_KMH             0.000000\n",
      "P1Score               0.000000\n",
      "P2Score               0.000000\n",
      "P1Momentum            0.000000\n",
      "P2Momentum            0.000000\n",
      "P1PointsWon           0.000000\n",
      "P2PointsWon           0.000000\n",
      "P1Ace                 0.000000\n",
      "P2Ace                 0.000000\n",
      "P1Winner              0.000000\n",
      "P2Winner              0.000000\n",
      "P1DoubleFault         0.000000\n",
      "P2DoubleFault         0.000000\n",
      "P1UnfErr              0.000000\n",
      "P2UnfErr              0.000000\n",
      "P1NetPoint            0.000000\n",
      "P2NetPoint            0.000000\n",
      "P1NetPointWon         0.000000\n",
      "P2NetPointWon         0.000000\n",
      "P1BreakPoint          0.000000\n",
      "P2BreakPoint          0.000000\n",
      "P1BreakPointWon       0.000000\n",
      "P2BreakPointWon       0.000000\n",
      "History               0.884559\n",
      "Speed_MPH             0.000000\n",
      "P1BreakPointMissed    0.000000\n",
      "P2BreakPointMissed    0.000000\n",
      "ServeIndicator        0.000000\n",
      "ServeNumber           0.000000\n",
      "WinnerType            0.000000\n",
      "WinnerShotType        0.000000\n",
      "P1DistanceRun         0.000000\n",
      "P2DistanceRun         0.000000\n",
      "RallyCount            0.000000\n",
      "ServeWidth            2.786451\n",
      "ServeDepth            2.786451\n",
      "ReturnDepth           8.087394\n",
      "player1               0.000000\n",
      "player2               0.000000\n",
      "dtype: float64\n",
      "match_id          0.00000\n",
      "SetNo             0.00000\n",
      "GameNo            0.00000\n",
      "PointNumber       0.00000\n",
      "PointWinner       0.00000\n",
      "PointServer       0.00000\n",
      "Speed_KMH        33.52499\n",
      "P1Score           0.00000\n",
      "P2Score           0.00000\n",
      "P1Ace             0.00000\n",
      "P2Ace             0.00000\n",
      "P1Winner          0.00000\n",
      "P2Winner          0.00000\n",
      "P1DoubleFault     0.00000\n",
      "P2DoubleFault     0.00000\n",
      "P1UnfErr          0.00000\n",
      "P2UnfErr          0.00000\n",
      "Speed_MPH        66.47501\n",
      "ServeNumber       0.00000\n",
      "RallyCount        0.00000\n",
      "player1           0.00000\n",
      "player2           0.00000\n",
      "dtype: float64\n",
      "match_id         0.0\n",
      "SetNo            0.0\n",
      "GameNo           0.0\n",
      "PointNumber      0.0\n",
      "PointWinner      0.0\n",
      "PointServer      0.0\n",
      "Speed_KMH        0.0\n",
      "P1Score          0.0\n",
      "P2Score          0.0\n",
      "P1Ace            0.0\n",
      "P2Ace            0.0\n",
      "P1Winner         0.0\n",
      "P2Winner         0.0\n",
      "P1DoubleFault    0.0\n",
      "P2DoubleFault    0.0\n",
      "P1UnfErr         0.0\n",
      "P2UnfErr         0.0\n",
      "ServeNumber      0.0\n",
      "RallyCount       0.0\n",
      "player1          0.0\n",
      "player2          0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of NaN values in each column\n",
    "nan_percentage = us.isna().mean() * 100\n",
    "nan_percentage1 = wim.isna().mean() * 100\n",
    "nan_percentage2 = rg.isna().mean() * 100\n",
    "nan_percentage3 = ao.isna().mean() * 100\n",
    "\n",
    "# Display the result\n",
    "print(nan_percentage)\n",
    "print(nan_percentage1)\n",
    "print(nan_percentage2)\n",
    "print(nan_percentage3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4723e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nan_rows = us[(us['ServeWidth'].isna()) | (us['ServeDepth'].isna()) | (us['ReturnDepth'].isna())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6feb79e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with PointNumber = '0X': 629\n"
     ]
    }
   ],
   "source": [
    "# Count rows where 'PointNumber' is '0X'\n",
    "count_0X = (us['PointNumber'] == '0X').sum()\n",
    "\n",
    "print(\"Number of rows with PointNumber = '0X':\", count_0X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7116aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition where RallyCount is 3 and either P1NetPointWon or P2NetPointWon is 1\n",
    "condition = (us['RallyCount'] == 3) & ((us['P1NetPointWon'] == 1) | (us['P2NetPointWon'] == 1))\n",
    "condition1 = (wim['RallyCount'] == 3) & ((wim['P1NetPointWon'] == 1) | (wim['P2NetPointWon'] == 1))\n",
    "\n",
    "\n",
    "# Update ReturnDepth to 0 where the condition is met\n",
    "us.loc[condition, 'ReturnDepth'] = '0'\n",
    "wim.loc[condition1, 'ReturnDepth'] = '0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37fc8ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2021-usopen-1148', '2021-usopen-1105', '2020-usopen-1218', '2020-usopen-1159', '2019-usopen-1116', '2019-usopen-1219', '2020-usopen-1138', '2019-usopen-1146', '2019-wimbledon-1115', '2020-usopen-1135', '2019-usopen-1143', '2019-usopen-1128', '2019-usopen-1156', '2020-usopen-1103', '2020-usopen-1137', '2019-usopen-1112', '2019-usopen-1220', '2019-usopen-1147', '2020-usopen-1129', '2019-usopen-1139', '2020-usopen-1151', '2020-usopen-1156', '2019-usopen-1135', '2022-usopen-1153', '2019-usopen-1202', '2019-usopen-1138', '2019-usopen-1110', '2021-usopen-1152', '2019-usopen-1124', '2020-usopen-1123', '2019-usopen-1129', '2020-usopen-1231', '2021-usopen-1127', '2020-usopen-1111', '2022-usopen-1163', '2020-usopen-1223', '2020-usopen-1147', '2019-usopen-1109', '2022-usopen-1134', '2020-usopen-1162', '2019-usopen-1120', '2021-usopen-1103', '2020-usopen-1114', '2019-usopen-1127', '2020-usopen-1118', '2020-usopen-1126', '2019-usopen-1103', '2019-usopen-1107', '2021-usopen-1153', '2019-usopen-1125', '2019-usopen-1214', '2020-usopen-1145', '2019-usopen-1131', '2019-usopen-1153', '2019-usopen-1151', '2019-usopen-1211', '2019-usopen-1161', '2020-usopen-1106', '2019-usopen-1122', '2019-usopen-1140', '2019-usopen-1152', '2019-usopen-1207', '2020-usopen-1110', '2020-usopen-1136', '2020-usopen-1202', '2020-usopen-1142', '2020-usopen-1115', '2021-usopen-1118', '2019-usopen-1210', '2019-usopen-1227', '2021-usopen-1128', '2019-usopen-1118', '2019-usopen-1137', '2019-usopen-1163', '2021-usopen-1104', '2021-usopen-1129', '2019-usopen-1158', '2020-usopen-1131', '2021-usopen-1111', '2020-usopen-1161', '2019-usopen-1223', '2019-usopen-1130', '2020-usopen-1504', '2019-usopen-1204', '2020-usopen-1107', '2022-usopen-1136', '2019-usopen-1104', '2019-usopen-1126', '2020-usopen-1203', '2020-usopen-1127', '2019-usopen-1106', '2019-usopen-1217', '2022-usopen-1135', '2020-usopen-1104', '2023-usopen-1109', '2022-usopen-1158', '2019-usopen-1134', '2021-usopen-1133', '2020-usopen-1144', '2019-usopen-1226', '2020-usopen-1119', '2022-usopen-1142', '2019-usopen-1142', '2019-usopen-1159', '2019-usopen-1224', '2019-usopen-1212', '2019-usopen-1121'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_match_with_consecutive_zeros(df, column, threshold=50):\n",
    "    \"\"\"\n",
    "    This function searches for a match_id that has at least a threshold number of consecutive 0.000 values in the given column.\n",
    "    \"\"\"\n",
    "    match_ids = []\n",
    "    current_match_id = None\n",
    "    consecutive_zeros = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if row[column] == 0.000:\n",
    "            if row['match_id'] != current_match_id:\n",
    "                current_match_id = row['match_id']\n",
    "                consecutive_zeros = 1\n",
    "            else:\n",
    "                consecutive_zeros += 1\n",
    "        else:\n",
    "            consecutive_zeros = 0\n",
    "\n",
    "        if consecutive_zeros >= threshold:\n",
    "            match_ids.append(current_match_id)\n",
    "            consecutive_zeros = 0  # Reset after finding the threshold\n",
    "\n",
    "    return match_ids\n",
    "\n",
    "# Example usage for your 'wim' dataset\n",
    "match_ids_p1 = find_match_with_consecutive_zeros(wim, 'P1DistanceRun', threshold=50)\n",
    "match_ids_p2 = find_match_with_consecutive_zeros(us, 'P1DistanceRun', threshold=50)\n",
    "\n",
    "# Combine results from both P1 and P2 distance columns\n",
    "match_ids = set(match_ids_p1 + match_ids_p2)\n",
    "\n",
    "# Print the match_ids\n",
    "print(match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44260ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of match_ids to remove from wim dataset\n",
    "remove_match_ids = ['2019-wimbledon-1115', '2021-wimbledon-1127', '2019-wimbledon-1162']\n",
    "\n",
    "# Filter the wim dataset to exclude rows with the specified match_ids\n",
    "wim = wim[~wim['match_id'].isin(remove_match_ids)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5511beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of specified match_ids\n",
    "match_ids = [\n",
    "    '2019-usopen-1104', '2020-usopen-1107', '2020-usopen-1145', '2019-usopen-1134', '2020-usopen-1118', \n",
    "    '2021-usopen-1118', '2020-usopen-1126', '2019-usopen-1106', '2020-usopen-1159', '2020-usopen-1203', \n",
    "    '2022-usopen-1135', '2019-usopen-1210', '2019-usopen-1112', '2020-usopen-1111', '2020-usopen-1218', \n",
    "    '2019-usopen-1147', '2020-usopen-1202', '2019-usopen-1126', '2019-usopen-1161', '2021-usopen-1152', \n",
    "    '2019-usopen-1131', '2019-usopen-1124', '2019-usopen-1129', '2019-usopen-1207', '2019-usopen-1146', \n",
    "    '2020-usopen-1129', '2020-usopen-1162', '2019-usopen-1219', '2019-usopen-1151', '2020-usopen-1151', \n",
    "    '2021-usopen-1148', '2019-usopen-1153', '2019-usopen-1163', '2019-usopen-1202', '2019-usopen-1125', \n",
    "    '2019-usopen-1152', '2019-usopen-1159', '2022-usopen-1136', '2019-usopen-1122', '2020-usopen-1104', \n",
    "    '2019-usopen-1120', '2022-usopen-1163', '2020-usopen-1123', '2021-wimbledon-1127', '2020-usopen-1231', \n",
    "    '2021-usopen-1127', '2019-wimbledon-1115', '2020-usopen-1103', '2021-usopen-1153', '2019-usopen-1143', \n",
    "    '2020-usopen-1114', '2019-usopen-1223', '2020-usopen-1110', '2022-usopen-1142', '2019-usopen-1214', \n",
    "    '2019-usopen-1217', '2020-usopen-1144', '2021-usopen-1105', '2019-usopen-1121', '2021-usopen-1103', \n",
    "    '2020-usopen-1136', '2019-usopen-1107', '2019-usopen-1109', '2019-usopen-1128', '2020-usopen-1119', \n",
    "    '2019-usopen-1118', '2022-usopen-1134', '2021-usopen-1111', '2019-usopen-1156', '2019-usopen-1204', \n",
    "    '2021-usopen-1104', '2019-usopen-1142', '2021-usopen-1128', '2022-usopen-1153', '2019-usopen-1135', \n",
    "    '2019-usopen-1226', '2020-usopen-1115', '2020-usopen-1156', '2019-usopen-1110', '2019-usopen-1140', \n",
    "    '2019-usopen-1158', '2020-usopen-1131', '2020-usopen-1142', '2019-usopen-1127', '2019-usopen-1138', \n",
    "    '2019-usopen-1227', '2020-usopen-1137', '2020-usopen-1161', '2021-usopen-1129', '2019-usopen-1130', \n",
    "    '2023-usopen-1109', '2020-usopen-1138', '2019-usopen-1137', '2020-usopen-1223', '2020-usopen-1504', \n",
    "    '2020-usopen-1127', '2020-usopen-1147', '2019-usopen-1224', '2019-usopen-1211', '2021-usopen-1133', \n",
    "    '2019-wimbledon-1162', '2020-usopen-1135', '2019-usopen-1139', '2019-usopen-1116', '2019-usopen-1220', \n",
    "    '2020-usopen-1106', '2019-usopen-1212', '2022-usopen-1158', '2019-usopen-1103'\n",
    "]\n",
    "\n",
    "# Filter the datasets to include only the specified match_ids\n",
    "filtered_wim = wim[wim['match_id'].isin(match_ids)]\n",
    "filtered_us = us[us['match_id'].isin(match_ids)]\n",
    "\n",
    "# Combine both filtered datasets\n",
    "combined_df = pd.concat([filtered_wim, filtered_us])\n",
    "\n",
    "# Group by 'match_id' and calculate the percentage of null values for 'ServeDepth' and 'ServeWidth'\n",
    "null_percentage = combined_df.groupby('match_id')[['ServeDepth', 'ServeWidth', 'ReturnDepth']].apply(\n",
    "    lambda x: x.isnull().mean() * 100\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4a1280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter match_ids where the null percentage for ServeWidth or ServeDepth is higher than 40%\n",
    "high_null_match_ids = null_percentage[(null_percentage['ServeWidth'] > 30) | (null_percentage['ServeDepth'] > 30)].index.tolist()\n",
    "\n",
    "us = us[~us['match_id'].isin(high_null_match_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b1eae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'ND' in ReturnDepth when RallyCount is 2: 7283\n",
      "Count of 'D' in ReturnDepth when RallyCount is 2: 4126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'us' is your DataFrame\n",
    "# Filter rows where RallyCount is 2\n",
    "filtered_data = wim[wim['RallyCount'] == 2]\n",
    "\n",
    "# Count occurrences of each value in ReturnDepth\n",
    "return_depth_counts = filtered_data['ReturnDepth'].value_counts()\n",
    "\n",
    "# Extract counts for 'ND' and 'D'\n",
    "count_nd = return_depth_counts.get('ND', 0)\n",
    "count_d = return_depth_counts.get('D', 0)\n",
    "\n",
    "print(f\"Count of 'ND' in ReturnDepth when RallyCount is 2: {count_nd}\")\n",
    "print(f\"Count of 'D' in ReturnDepth when RallyCount is 2: {count_d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a21de7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Training samples: 91092\n",
      "  Testing samples: 22773\n",
      "  Accuracy: 0.7144\n",
      "\n",
      "Fold 2:\n",
      "  Training samples: 91092\n",
      "  Testing samples: 22773\n",
      "  Accuracy: 0.7200\n",
      "\n",
      "Fold 3:\n",
      "  Training samples: 91092\n",
      "  Testing samples: 22773\n",
      "  Accuracy: 0.7117\n",
      "\n",
      "Fold 4:\n",
      "  Training samples: 91092\n",
      "  Testing samples: 22773\n",
      "  Accuracy: 0.7104\n",
      "\n",
      "Fold 5:\n",
      "  Training samples: 91092\n",
      "  Testing samples: 22773\n",
      "  Accuracy: 0.7119\n",
      "\n",
      "Average accuracy across 5 folds: 0.7137\n",
      "['D' '0' 'ND' 'M']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Features and target\n",
    "features = ['ServeWidth', 'ServeDepth', 'Speed_MPH', 'RallyCount', 'ServeNumber']\n",
    "target = 'ReturnDepth'\n",
    "\n",
    "# Copy the dataset to preserve the original\n",
    "# Define the columns to check for NaN values\n",
    "columns_to_check = ['ServeWidth', 'ServeDepth', 'Speed_MPH', 'RallyCount',\n",
    "                    'ReturnDepth', 'ServeNumber']\n",
    "\n",
    "# Exclude rows with NaN values in any of the specified columns\n",
    "complete_data = us.dropna(subset=columns_to_check)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['ServeWidth', 'ServeDepth', 'ServeNumber']\n",
    "numerical_features = ['Speed_MPH', 'RallyCount']\n",
    "\n",
    "# Separate features and target\n",
    "X = complete_data[features]\n",
    "y = complete_data[target]\n",
    "\n",
    "# Initialize LabelEncoder for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Set up preprocessing for the features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Standardize numerical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # Encode categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline that first preprocesses and then applies the KNN model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=157))\n",
    "])\n",
    "\n",
    "# KFold cross-validation setup (5 parts)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    \n",
    "    # Fit the pipeline and predict\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    print(f'Fold {fold+1}:')\n",
    "    print(f'  Training samples: {len(train_index)}')\n",
    "    print(f'  Testing samples: {len(test_index)}')\n",
    "    print(f'  Accuracy: {accuracy:.4f}\\n')\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy = np.mean(accuracy_list)\n",
    "print(f'Average accuracy across 5 folds: {average_accuracy:.4f}')\n",
    "\n",
    "print(complete_data[target].unique())  # Before encoding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d07b2b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/61118291.py:89: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load your image\n",
    "court_img = mpimg.imread('wimbledon_grass_court.jpg')\n",
    "\n",
    "# Example counts of \"Not Deep\" (ND), \"Deep\" (D), and \"Missed\" (M) returns\n",
    "nd_count = wim[wim['ReturnDepth'] == 'ND'].shape[0]\n",
    "d_count = wim[wim['ReturnDepth'] == 'D'].shape[0]\n",
    "m_count = wim[(wim['ReturnDepth'] == 'M') | (wim['ReturnDepth'] == '0')].shape[0]\n",
    "\n",
    "# Total returns\n",
    "total_count = nd_count + d_count + m_count\n",
    "\n",
    "# Calculate percentages\n",
    "nd_percentage = (nd_count / total_count) * 100\n",
    "d_percentage = (d_count / total_count) * 100\n",
    "m_percentage = (m_count / total_count) * 100\n",
    "\n",
    "# Define court boundaries (adjust these depending on the image resolution)\n",
    "court_x_min, court_x_max = 0, 80\n",
    "court_y_min, court_y_max = 0, 100  # Example values, adjust to match your court image\n",
    "\n",
    "# Coordinates for the shaded areas\n",
    "# \"Not Deep\" region (net to service line)\n",
    "not_deep_x_min = 22\n",
    "not_deep_x_max = 58\n",
    "not_deep_y_min = 26\n",
    "not_deep_y_max = 46\n",
    "\n",
    "# \"Deep\" region (service line to baseline)\n",
    "deep_x_min = 22\n",
    "deep_x_max = 58\n",
    "deep_y_min = 5\n",
    "deep_y_max = 26\n",
    "\n",
    "# Display the tennis court image\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.imshow(court_img, extent=[court_x_min, court_x_max, court_y_min, court_y_max])\n",
    "\n",
    "# Create shaded area for \"Not Deep\"\n",
    "plt.gca().add_patch(patches.Rectangle((not_deep_x_min, not_deep_y_min), \n",
    "                                       not_deep_x_max - not_deep_x_min, \n",
    "                                       not_deep_y_max - not_deep_y_min,\n",
    "                                       linewidth=1, edgecolor='none', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "# Create shaded area for \"Deep\"\n",
    "plt.gca().add_patch(patches.Rectangle((deep_x_min, deep_y_min), \n",
    "                                       deep_x_max - deep_x_min, \n",
    "                                       deep_y_max - deep_y_min,\n",
    "                                       linewidth=1, edgecolor='none', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "# Create shaded area for \"Missed\" (rectangles based on your specifications)\n",
    "\n",
    "plt.gca().add_patch(patches.Rectangle((0, 5), 22, 41, \n",
    "                                       linewidth=1, edgecolor='none', facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.gca().add_patch(patches.Rectangle((0, 0), 80, 5, \n",
    "                                       linewidth=1, edgecolor='none', facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.gca().add_patch(patches.Rectangle((58, 5), 22, 41, \n",
    "                                       linewidth=1, edgecolor='none', facecolor='red', alpha=0.3))\n",
    "\n",
    "# Add text to display the percentage and total counts\n",
    "plt.text((not_deep_x_min + not_deep_x_max) / 2, (not_deep_y_min + not_deep_y_max) / 2, \n",
    "         f'Not Deep\\n{nd_percentage:.1f}% ({nd_count})', color='white', fontsize=12,\n",
    "         ha='center', va='center', bbox=dict(facecolor='blue', alpha=0.5))\n",
    "\n",
    "plt.text((deep_x_min + deep_x_max) / 2, (deep_y_min + deep_y_max) / 2, \n",
    "         f'Deep\\n{d_percentage:.1f}% ({d_count})', color='black', fontsize=12,\n",
    "         ha='center', va='center', bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "plt.text((court_x_min + 5), \n",
    "         (court_y_max - 90), \n",
    "         f'Missed or 0\\n{m_percentage:.1f}% ({m_count})', color='white', fontsize=9,\n",
    "         ha='left', va='top', bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "plt.xlabel('Court X (width)')\n",
    "plt.ylabel('Court Y (length)')\n",
    "plt.title('Return Depth and Missed Distribution in Men Singles on Wimbledon 2019-2023')\n",
    "\n",
    "# Hide axis ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c554d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2353211301.py:93: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load your image\n",
    "court_img = mpimg.imread('usopencourt.jpg')\n",
    "\n",
    "# Example counts of \"Not Deep\" (ND), \"Deep\" (D), and \"Missed\" (M) returns\n",
    "nd_count = us[us['ReturnDepth'] == 'ND'].shape[0]\n",
    "d_count = us[us['ReturnDepth'] == 'D'].shape[0]\n",
    "m_count = us[(us['ReturnDepth'] == 'M') | (us['ReturnDepth'] == '0')].shape[0]\n",
    "\n",
    "# Total returns\n",
    "total_count = nd_count + d_count + m_count\n",
    "\n",
    "# Calculate percentages\n",
    "nd_percentage = (nd_count / total_count) * 100\n",
    "d_percentage = (d_count / total_count) * 100\n",
    "m_percentage = (m_count / total_count) * 100\n",
    "\n",
    "# Define court boundaries (adjust these depending on the image resolution)\n",
    "court_x_min, court_x_max = 0, 80\n",
    "court_y_min, court_y_max = 0, 100  # Example values, adjust to match your court image\n",
    "\n",
    "# Coordinates for the shaded areas\n",
    "# \"Not Deep\" region (net to service line)\n",
    "not_deep_x_min = 19\n",
    "not_deep_x_max = 61\n",
    "not_deep_y_min = 25\n",
    "not_deep_y_max = 50\n",
    "\n",
    "# \"Deep\" region (service line to baseline)\n",
    "deep_x_min = 19\n",
    "deep_x_max = 61\n",
    "deep_y_min = 7\n",
    "deep_y_max = 25\n",
    "\n",
    "# Display the tennis court image\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.imshow(court_img, extent=[court_x_min, court_x_max, court_y_min, court_y_max])\n",
    "\n",
    "# Create shaded area for \"Not Deep\"\n",
    "plt.gca().add_patch(patches.Rectangle((not_deep_x_min, not_deep_y_min), \n",
    "                                       not_deep_x_max - not_deep_x_min, \n",
    "                                       not_deep_y_max - not_deep_y_min,\n",
    "                                       linewidth=1, edgecolor='none', facecolor='grey', alpha=0.3))\n",
    "\n",
    "# Create shaded area for \"Deep\"\n",
    "plt.gca().add_patch(patches.Rectangle((deep_x_min, deep_y_min), \n",
    "                                       deep_x_max - deep_x_min, \n",
    "                                       deep_y_max - deep_y_min,\n",
    "                                       linewidth=1, edgecolor='none', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "# Create shaded area for \"Missed\" (rectangles based on your specifications)\n",
    "\n",
    "# Rectangle (0, 5) to (22, 46)\n",
    "plt.gca().add_patch(patches.Rectangle((0, 7), 19, 43, \n",
    "                                       linewidth=1, edgecolor='none', facecolor='red', alpha=0.3))\n",
    "\n",
    "# Rectangle (0, 0) to (80, 5)\n",
    "plt.gca().add_patch(patches.Rectangle((0, 0), 80, 7, \n",
    "                                       linewidth=1, edgecolor='none', facecolor='red', alpha=0.3))\n",
    "\n",
    "# Rectangle (58, 5) to (80, 46)\n",
    "plt.gca().add_patch(patches.Rectangle((61, 7), 22, 43, \n",
    "                                       linewidth=1, edgecolor='none', facecolor='red', alpha=0.3))\n",
    "\n",
    "# Add text to display the percentage and total counts\n",
    "plt.text((not_deep_x_min + not_deep_x_max) / 2, (not_deep_y_min + not_deep_y_max) / 2, \n",
    "         f'Not Deep\\n{nd_percentage:.1f}% ({nd_count})', color='white', fontsize=12,\n",
    "         ha='center', va='center', bbox=dict(facecolor='blue', alpha=0.5))\n",
    "\n",
    "plt.text((deep_x_min + deep_x_max) / 2, (deep_y_min + deep_y_max) / 2, \n",
    "         f'Deep\\n{d_percentage:.1f}% ({d_count})', color='black', fontsize=12,\n",
    "         ha='center', va='center', bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.text((court_x_min + 5), \n",
    "         (court_y_max - 90), \n",
    "         f'Missed or 0\\n{m_percentage:.1f}% ({m_count})', color='white', fontsize=9,\n",
    "         ha='left', va='top', bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Court X (width)')\n",
    "plt.ylabel('Court Y (length)')\n",
    "plt.title('Return Depth and Missed Distribution in Men Singles on Wimbledon 2019-2023')\n",
    "\n",
    "# Hide axis ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51d4ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1165397890.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ctl_counts['percentage'] = (ctl_counts['count'] / total_shots) * 100\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1165397890.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nctl_counts['percentage'] = (nctl_counts['count'] / total_shots) * 100\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1165397890.py:126: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load your image\n",
    "court_img = mpimg.imread('usopencourt.jpg')\n",
    "\n",
    "# Total shots in the dataset\n",
    "total_shots = us.shape[0]\n",
    "\n",
    "# Calculate the counts for ServeDepth and ServeWidth categories\n",
    "serve_depth_width_counts = us.groupby(['ServeDepth', 'ServeWidth']).size().reset_index(name='count')\n",
    "\n",
    "# ServeDepth and ServeWidth categories counts\n",
    "ctl_counts = serve_depth_width_counts[serve_depth_width_counts['ServeDepth'] == 'CTL']\n",
    "nctl_counts = serve_depth_width_counts[serve_depth_width_counts['ServeDepth'] == 'NCTL']\n",
    "\n",
    "# Calculate percentages for CTL and NCTL\n",
    "ctl_counts['percentage'] = (ctl_counts['count'] / total_shots) * 100\n",
    "nctl_counts['percentage'] = (nctl_counts['count'] / total_shots) * 100\n",
    "\n",
    "# Display the tennis court image\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(court_img, extent=[court_x_min, court_x_max, court_y_min, court_y_max])\n",
    "\n",
    "# Define the coordinates for ServeDepth and ServeWidth regions\n",
    "# Adjust these coordinates based on your image size\n",
    "\n",
    "# \"CTL\" (Close to the Line) ServeWidth categories (black to white)\n",
    "regions_ctl = {\n",
    "    'B': {'x_min': 27, 'x_max': 31, 'y_min': 25, 'y_max': 38, 'count': 1577.0, 'percentage': 1.294735, 'color': '#000000'},  # Black (fewest)\n",
    "    'BC': {'x_min': 31, 'x_max': 35, 'y_min': 25, 'y_max': 38, 'count': 3705.0, 'percentage': 3.041847, 'color': '#404040'},  # Dark Gray\n",
    "    'C': {'x_min': 35, 'x_max': 39.5, 'y_min': 25, 'y_max': 38, 'count': 6610.0, 'percentage': 5.426885, 'color': '#808080'},  # Medium Gray\n",
    "    'BW': {'x_min': 23, 'x_max': 27, 'y_min': 25, 'y_max': 38, 'count': 2800.0, 'percentage': 2.298832, 'color': '#b3b3b3'},  # Light Gray\n",
    "    'W': {'x_min': 19, 'x_max': 23, 'y_min': 25, 'y_max': 38, 'count': 18680.0, 'percentage': 15.336491, 'color': '#ffffff'},  # White (most)\n",
    "}\n",
    "\n",
    "# \"NCTL\" (Not Close to the Line) ServeWidth categories (black to white)\n",
    "regions_nctl = {\n",
    "    'W': {'x_min': 19, 'x_max': 23, 'y_min': 38, 'y_max': 50, 'count': 7175.0, 'percentage': 5.890756, 'color': '#d9d9d9'},  # Light Gray\n",
    "    'B': {'x_min': 27, 'x_max': 31, 'y_min': 38, 'y_max': 50, 'count': 9987.0, 'percentage': 8.199440, 'color': '#808080'},  # Dark Gray\n",
    "    'BW': {'x_min': 23, 'x_max': 27, 'y_min': 38, 'y_max': 50, 'count': 19675.0, 'percentage': 16.153398, 'color': '#4d4d4d'},  # Darker Gray\n",
    "    'BC': {'x_min': 31, 'x_max': 35, 'y_min': 38, 'y_max': 50, 'count': 16245.0, 'percentage': 13.337329, 'color': '#b3b3b3'},  # Medium Gray\n",
    "    'C': {'x_min': 35, 'x_max': 39.5, 'y_min': 38, 'y_max': 50, 'count': 25482.0, 'percentage': 20.921011, 'color': '#1f1f1f'},  # Near Black\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Function to add regions to the plot\n",
    "def add_region(regions):\n",
    "    for label, region in regions.items():\n",
    "        plt.gca().add_patch(patches.Rectangle(\n",
    "            (region['x_min'], region['y_min']),\n",
    "            region['x_max'] - region['x_min'], \n",
    "            region['y_max'] - region['y_min'],\n",
    "            linewidth=1, edgecolor='none', facecolor=region['color'], alpha=0.5\n",
    "        ))\n",
    "\n",
    "# Add CTL (hot colors) and NCTL (cool colors) regions\n",
    "add_region(regions_ctl)\n",
    "add_region(regions_nctl)\n",
    "\n",
    "# Custom label coordinates for ServeWidth categories\n",
    "label_positions = {\n",
    "    'C': {'x': 50, 'y': 30},\n",
    "    'BC': {'x': 45, 'y': 20},\n",
    "    'B': {'x': 30, 'y': 10},\n",
    "    'BW': {'x': 15, 'y': 20},\n",
    "    'W': {'x': 12, 'y': 30}\n",
    "}\n",
    "\n",
    "# Function to add count and percentage labels with a small colored rectangle matching the region\n",
    "def add_labels_for_regions(data_counts, label_positions, region_type, regions):\n",
    "    for index, row in data_counts.iterrows():\n",
    "        serve_width = row['ServeWidth']\n",
    "        count = row['count']\n",
    "        percentage = row['percentage']\n",
    "        \n",
    "        # Label format: \"NCTL W\\ncount shots\\n(percentage%)\"\n",
    "        label = f\"{region_type} {serve_width}\\n{count} shots\\n({percentage:.2f}%)\"\n",
    "        \n",
    "        # Get the label position\n",
    "        x = label_positions[serve_width]['x']\n",
    "        y = label_positions[serve_width]['y']\n",
    "        \n",
    "        # Calculate center of the respective region for connecting line\n",
    "        region_center_x = (regions[serve_width]['x_min'] + regions[serve_width]['x_max']) / 2\n",
    "        region_center_y = (regions[serve_width]['y_min'] + regions[serve_width]['y_max']) / 2\n",
    "\n",
    "        # Draw a line connecting the label to the region\n",
    "        plt.plot([x, region_center_x], [y, region_center_y], color='white', lw=1)\n",
    "\n",
    "        # Add a colored rectangle behind the label, matching the region color\n",
    "        label_box = patches.FancyBboxPatch((x-6, y-3.5), 15, 8, boxstyle=\"round,pad=0.3\", \n",
    "                                           edgecolor='none', facecolor=regions[serve_width]['color'], alpha=0.6)\n",
    "        plt.gca().add_patch(label_box)\n",
    "        \n",
    "        # Add label text\n",
    "        plt.text(x, y, label, fontsize=10, ha='center', va='center', color='white')\n",
    "\n",
    "# Add labels for CTL (ServeWidth categories)\n",
    "add_labels_for_regions(ctl_counts, label_positions, 'CTL', regions_ctl)\n",
    "\n",
    "# Adjust label positions for NCTL (shift them down or choose new positions)\n",
    "label_positions_nctl = {\n",
    "    'C': {'x': 50, 'y': 50},\n",
    "    'BC': {'x': 45, 'y': 60},\n",
    "    'B': {'x': 30, 'y': 70},\n",
    "    'BW': {'x': 15, 'y': 60},\n",
    "    'W': {'x': 12, 'y': 50}\n",
    "}\n",
    "\n",
    "# Add labels for NCTL (ServeWidth categories)\n",
    "add_labels_for_regions(nctl_counts, label_positions_nctl, 'NCTL', regions_nctl)\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Court X (width)')\n",
    "plt.ylabel('Court Y (length)')\n",
    "plt.title('Serve Depth (CTL/NCTL) and Serve Width (C, BC, B, BW, W) Distribution with Counts and Percentages')\n",
    "\n",
    "# Hide axis ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aed04e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ServeDepth ServeWidth    count  percentage\n",
      "0         CTL          W  18385.0   15.094293\n",
      "1         CTL         BW   2595.0    2.130524\n",
      "2         CTL          B   1854.0    1.522155\n",
      "3         CTL         BC   3555.0    2.918695\n",
      "4         CTL          C   6588.0    5.408823\n",
      "5         CTL          0      0.0    0.000000\n",
      "6        NCTL          W   6704.0    5.504060\n",
      "7        NCTL         BW  16282.0   13.367706\n",
      "8        NCTL          B   9107.0    7.476950\n",
      "9        NCTL         BC  13623.0   11.184637\n",
      "10       NCTL          C  23153.0   19.008875\n",
      "11       NCTL          0      0.0    0.000000\n",
      "12          0          W      0.0    0.000000\n",
      "13          0         BW      0.0    0.000000\n",
      "14          0          B      0.0    0.000000\n",
      "15          0         BC      0.0    0.000000\n",
      "16          0          C      0.0    0.000000\n",
      "17          0          0   3990.0    3.275835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define all possible combinations of ServeDepth and ServeWidth\n",
    "serve_depths = ['CTL', 'NCTL','0']\n",
    "serve_widths = ['W', 'BW', 'B', 'BC', 'C','0']\n",
    "\n",
    "# Create a DataFrame with all combinations\n",
    "all_combinations = pd.MultiIndex.from_product([serve_depths, serve_widths], names=['ServeDepth', 'ServeWidth'])\n",
    "all_counts = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "# Count the occurrences of each combination\n",
    "counts = wim.groupby(['ServeDepth', 'ServeWidth']).size().reset_index(name='count')\n",
    "\n",
    "# Merge the counts with all combinations to fill in missing combinations with zero counts\n",
    "all_counts = all_counts.merge(counts, on=['ServeDepth', 'ServeWidth'], how='left').fillna(0)\n",
    "\n",
    "# Calculate percentages\n",
    "all_counts['percentage'] = (all_counts['count'] / total_shots) * 100\n",
    "\n",
    "# Display the counts and percentages\n",
    "print(all_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ae335eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>ElapsedTime</th>\n",
       "      <th>SetNo</th>\n",
       "      <th>P1GamesWon</th>\n",
       "      <th>P2GamesWon</th>\n",
       "      <th>SetWinner</th>\n",
       "      <th>GameNo</th>\n",
       "      <th>GameWinner</th>\n",
       "      <th>PointNumber</th>\n",
       "      <th>PointWinner</th>\n",
       "      <th>...</th>\n",
       "      <th>WinnerType</th>\n",
       "      <th>WinnerShotType</th>\n",
       "      <th>P1DistanceRun</th>\n",
       "      <th>P2DistanceRun</th>\n",
       "      <th>RallyCount</th>\n",
       "      <th>ServeWidth</th>\n",
       "      <th>ServeDepth</th>\n",
       "      <th>ReturnDepth</th>\n",
       "      <th>player1</th>\n",
       "      <th>player2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-usopen-1101</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0X</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roberto Carballes Baena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-usopen-1101</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0Y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roberto Carballes Baena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-usopen-1101</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.095</td>\n",
       "      <td>33.480</td>\n",
       "      <td>9</td>\n",
       "      <td>BC</td>\n",
       "      <td>NCTL</td>\n",
       "      <td>D</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roberto Carballes Baena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-usopen-1101</td>\n",
       "      <td>0:00:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roberto Carballes Baena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-usopen-1101</td>\n",
       "      <td>0:01:22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.642</td>\n",
       "      <td>8.791</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>NCTL</td>\n",
       "      <td>ND</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roberto Carballes Baena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>2021-ausopen-MS701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N Djokovic</td>\n",
       "      <td>D Medvedev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>2021-ausopen-MS701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N Djokovic</td>\n",
       "      <td>D Medvedev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400000</th>\n",
       "      <td>2021-ausopen-MS701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N Djokovic</td>\n",
       "      <td>D Medvedev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400001</th>\n",
       "      <td>2021-ausopen-MS701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N Djokovic</td>\n",
       "      <td>D Medvedev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400002</th>\n",
       "      <td>2021-ausopen-MS701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N Djokovic</td>\n",
       "      <td>D Medvedev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400003 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  match_id ElapsedTime  SetNo  P1GamesWon  P2GamesWon  \\\n",
       "0         2019-usopen-1101     0:00:00      1         0.0         0.0   \n",
       "1         2019-usopen-1101     0:00:00      1         0.0         0.0   \n",
       "2         2019-usopen-1101     0:00:00      1         0.0         0.0   \n",
       "3         2019-usopen-1101     0:00:55      1         0.0         0.0   \n",
       "4         2019-usopen-1101     0:01:22      1         0.0         0.0   \n",
       "...                    ...         ...    ...         ...         ...   \n",
       "399998  2021-ausopen-MS701         NaN      3         NaN         NaN   \n",
       "399999  2021-ausopen-MS701         NaN      3         NaN         NaN   \n",
       "400000  2021-ausopen-MS701         NaN      3         NaN         NaN   \n",
       "400001  2021-ausopen-MS701         NaN      3         NaN         NaN   \n",
       "400002  2021-ausopen-MS701         NaN      3         NaN         NaN   \n",
       "\n",
       "        SetWinner  GameNo  GameWinner PointNumber  PointWinner  ...  \\\n",
       "0             0.0       1         0.0          0X            0  ...   \n",
       "1             0.0       1         0.0          0Y            0  ...   \n",
       "2             0.0       1         0.0           1            1  ...   \n",
       "3             0.0       1         0.0           2            2  ...   \n",
       "4             0.0       1         0.0           3            1  ...   \n",
       "...           ...     ...         ...         ...          ...  ...   \n",
       "399998        NaN      28         NaN         151            1  ...   \n",
       "399999        NaN      28         NaN         152            2  ...   \n",
       "400000        NaN      28         NaN         153            2  ...   \n",
       "400001        NaN      28         NaN         154            1  ...   \n",
       "400002        NaN      28         NaN         155            1  ...   \n",
       "\n",
       "        WinnerType  WinnerShotType P1DistanceRun P2DistanceRun  RallyCount  \\\n",
       "0                0               0         0.000         0.000           0   \n",
       "1                0               0         0.000         0.000           0   \n",
       "2                0               0        29.095        33.480           9   \n",
       "3                0               0         0.577         0.510           0   \n",
       "4                0               0        14.642         8.791           5   \n",
       "...            ...             ...           ...           ...         ...   \n",
       "399998         NaN             NaN           NaN           NaN           2   \n",
       "399999         NaN             NaN           NaN           NaN          15   \n",
       "400000         NaN             NaN           NaN           NaN           1   \n",
       "400001         NaN             NaN           NaN           NaN           4   \n",
       "400002         NaN             NaN           NaN           NaN           8   \n",
       "\n",
       "        ServeWidth  ServeDepth  ReturnDepth         player1  \\\n",
       "0              NaN         NaN          NaN  Novak Djokovic   \n",
       "1              NaN         NaN          NaN  Novak Djokovic   \n",
       "2               BC        NCTL            D  Novak Djokovic   \n",
       "3                0           0            0  Novak Djokovic   \n",
       "4                C        NCTL           ND  Novak Djokovic   \n",
       "...            ...         ...          ...             ...   \n",
       "399998         NaN         NaN          NaN      N Djokovic   \n",
       "399999         NaN         NaN          NaN      N Djokovic   \n",
       "400000         NaN         NaN          NaN      N Djokovic   \n",
       "400001         NaN         NaN          NaN      N Djokovic   \n",
       "400002         NaN         NaN          NaN      N Djokovic   \n",
       "\n",
       "                        player2  \n",
       "0       Roberto Carballes Baena  \n",
       "1       Roberto Carballes Baena  \n",
       "2       Roberto Carballes Baena  \n",
       "3       Roberto Carballes Baena  \n",
       "4       Roberto Carballes Baena  \n",
       "...                         ...  \n",
       "399998               D Medvedev  \n",
       "399999               D Medvedev  \n",
       "400000               D Medvedev  \n",
       "400001               D Medvedev  \n",
       "400002               D Medvedev  \n",
       "\n",
       "[400003 rows x 50 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming us and wim are pandas DataFrames\n",
    "wimus = pd.concat([us, wim], ignore_index=True)\n",
    "every = pd.concat([us, wim, rg, ao], ignore_index=True)\n",
    "every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c8abf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for player1:\n",
      "Novak Djokovic         14043\n",
      "Alexander Zverev        6802\n",
      "Stefanos Tsitsipas      6566\n",
      "Denis Shapovalov        6002\n",
      "Daniil Medvedev         5852\n",
      "                       ...  \n",
      "M. Janvier               147\n",
      "C Stebe                  144\n",
      "R. Harrison              142\n",
      "Juan Pablo Varillas      140\n",
      "Bernard Tomic            127\n",
      "Name: player1, Length: 279, dtype: int64\n",
      "\n",
      "Value counts for player2:\n",
      "Rafael Nadal         8699\n",
      "Daniil Medvedev      7531\n",
      "Alexander Zverev     6614\n",
      "Andrey Rublev        6332\n",
      "Diego Schwartzman    5572\n",
      "                     ... \n",
      "A. Tabilo             156\n",
      "R. Harrison           152\n",
      "Stefan Kozlov         147\n",
      "G. Sakharov           146\n",
      "Marcel Granollers       2\n",
      "Name: player2, Length: 281, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize names based on the full version of the name\n",
    "def standardize_names(series):\n",
    "    # Create a dictionary to hold standardized names\n",
    "    standardized = {}\n",
    "    \n",
    "    for name in series:\n",
    "        # Split into first name and last name\n",
    "        parts = name.split()\n",
    "        if len(parts) < 2:\n",
    "            continue  # Skip invalid names\n",
    "        \n",
    "        first_initial, last_name = parts[0][0], parts[1]\n",
    "        full_key = f\"{first_initial} {last_name}\"\n",
    "        \n",
    "        # If we encounter the first full name for this pattern, use it as the standard\n",
    "        if full_key not in standardized:\n",
    "            standardized[full_key] = name\n",
    "        \n",
    "    # Replace names with the standardized version\n",
    "    return series.apply(lambda x: standardized.get(f\"{x.split()[0][0]} {x.split()[1]}\", x))\n",
    "\n",
    "# Apply standardization to both player1 and player2 columns in the `every` dataset\n",
    "every['player1'] = standardize_names(every['player1'])\n",
    "every['player2'] = standardize_names(every['player2'])\n",
    "\n",
    "\n",
    "player1_counts = every['player1'].value_counts()\n",
    "player2_counts = every['player2'].value_counts()\n",
    "\n",
    "# Display value counts\n",
    "print(\"Value counts for player1:\")\n",
    "print(player1_counts)\n",
    "\n",
    "print(\"\\nValue counts for player2:\")\n",
    "print(player2_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b53abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full names with the same last name but different first names:\n",
      "Last Name: Benchetrit\n",
      "  E Benchetrit\n",
      "  E. Benchetrit\n",
      "Last Name: Cazaux\n",
      "  A Cazaux\n",
      "  Arthur Cazaux\n",
      "Last Name: Cerundolo\n",
      "  Juan Cerundolo\n",
      "  Francisco Cerundolo\n",
      "Last Name: Coppejans\n",
      "  Kimmer Coppejans\n",
      "  K. Coppejans\n",
      "Last Name: Darcis\n",
      "  S. Darcis\n",
      "  Steve Darcis\n",
      "Last Name: Donskoy\n",
      "  Evgeny Donskoy\n",
      "  E. Donskoy\n",
      "Last Name: Dzumhur\n",
      "  Damir Dzumhur\n",
      "  D. Dzumhur\n",
      "Last Name: Ebden\n",
      "  M. Ebden\n",
      "  Matthew Ebden\n",
      "Last Name: Fratangelo\n",
      "  B Fratangelo\n",
      "  B. Fratangelo\n",
      "Last Name: Galan\n",
      "  De Galan\n",
      "  Daniel Galan\n",
      "Last Name: Gaston\n",
      "  Hugo Gaston\n",
      "  H Gaston\n",
      "Last Name: Gombos\n",
      "  Norbert Gombos\n",
      "  N Gombos\n",
      "Last Name: Gulbis\n",
      "  E. Gulbis\n",
      "  Ernests Gulbis\n",
      "Last Name: Gunneswaran\n",
      "  P. Gunneswaran\n",
      "  Prajnesh Gunneswaran\n",
      "Last Name: Harris\n",
      "  A. Harris\n",
      "  Lloyd Harris\n",
      "Last Name: Harrison\n",
      "  R. Harrison\n",
      "  Christian Harrison\n",
      "Last Name: Herbert\n",
      "  P. Herbert\n",
      "  Pierre Herbert\n",
      "Last Name: Janvier\n",
      "  M Janvier\n",
      "  M. Janvier\n",
      "Last Name: Jaziri\n",
      "  Malek Jaziri\n",
      "  M. Jaziri\n",
      "Last Name: Karlovic\n",
      "  Ivo Karlovic\n",
      "  I. Karlovic\n",
      "Last Name: Kovalik\n",
      "  J. Kovalik\n",
      "  Jozef Kovalik\n",
      "Last Name: Londero\n",
      "  J. Londero\n",
      "  Juan Londero\n",
      "Last Name: Lopez\n",
      "  Feliciano Lopez\n",
      "  Guillermo Lopez\n",
      "Last Name: Lu\n",
      "  Yh Lu\n",
      "  Yen Lu\n",
      "Last Name: Martin\n",
      "  Andrej Martin\n",
      "  A Martin\n",
      "Last Name: Martinez\n",
      "  M Martinez\n",
      "  Pedro Martinez\n",
      "Last Name: Mayot\n",
      "  Harold Mayot\n",
      "  H Mayot\n",
      "Last Name: Mcdonald\n",
      "  M Mcdonald\n",
      "  M. Mcdonald\n",
      "Last Name: Ramos-Vinolas\n",
      "  A. Ramos-Vinolas\n",
      "  A Ramos-Vinolas\n",
      "Last Name: Sousa\n",
      "  Joao Sousa\n",
      "  Pedro Sousa\n",
      "Last Name: Stebe\n",
      "  C Stebe\n",
      "  C. Stebe\n",
      "  Cedrik Stebe\n",
      "Last Name: Struff\n",
      "  J. Struff\n",
      "  Jan Struff\n",
      "Last Name: Tabilo\n",
      "  Alejandro Tabilo\n",
      "  A. Tabilo\n",
      "Last Name: Tomic\n",
      "  Bernard Tomic\n",
      "  B. Tomic\n",
      "Last Name: Tsonga\n",
      "  J. Tsonga\n",
      "  Jo Tsonga\n",
      "Last Name: Vera\n",
      "  Tomas Vera\n",
      "  Marcelo Vera\n",
      "Last Name: Vukic\n",
      "  A Vukic\n",
      "  Aleksandar Vukic\n",
      "Last Name: Ymer\n",
      "  Elias Ymer\n",
      "  Mikael Ymer\n",
      "Last Name: Zverev\n",
      "  Alexander Zverev\n",
      "  M. Zverev\n"
     ]
    }
   ],
   "source": [
    "# Extract first and last names from player1 and player2\n",
    "every['first_name_player1'] = every['player1'].apply(lambda x: x.split()[0] if pd.notnull(x) else None)\n",
    "every['last_name_player1'] = every['player1'].apply(lambda x: x.split()[-1] if pd.notnull(x) else None)\n",
    "every['first_name_player2'] = every['player2'].apply(lambda x: x.split()[0] if pd.notnull(x) else None)\n",
    "every['last_name_player2'] = every['player2'].apply(lambda x: x.split()[-1] if pd.notnull(x) else None)\n",
    "\n",
    "# Combine first and last names from both columns\n",
    "all_names = pd.DataFrame({\n",
    "    'first_name': pd.concat([every['first_name_player1'], every['first_name_player2']]),\n",
    "    'last_name': pd.concat([every['last_name_player1'], every['last_name_player2']])\n",
    "}).dropna()\n",
    "\n",
    "# Group by last name and find last names with multiple first names\n",
    "last_name_groups = all_names.groupby('last_name')['first_name'].apply(list)\n",
    "duplicate_last_names = last_name_groups[last_name_groups.apply(lambda x: len(set(x)) > 1)]\n",
    "\n",
    "# Display full names for duplicate last names\n",
    "print(\"Full names with the same last name but different first names:\")\n",
    "for last_name, first_names in duplicate_last_names.items():\n",
    "    unique_first_names = set(first_names)  # Get unique first names\n",
    "    print(f\"Last Name: {last_name}\")\n",
    "    for first_name in unique_first_names:\n",
    "        print(f\"  {first_name} {last_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1aabd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/4188663787.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ctl_counts['percentage'] = (ctl_counts['count'] / total_shots) * 100\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/4188663787.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nctl_counts['percentage'] = (nctl_counts['count'] / total_shots) * 100\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/4188663787.py:119: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Load your image\n",
    "court_img = mpimg.imread('wimbledon_grass_court.jpg')\n",
    "\n",
    "# Total shots in the dataset\n",
    "total_shots = wimus.shape[0]\n",
    "\n",
    "# Calculate the counts for ServeDepth and ServeWidth categories\n",
    "serve_depth_width_counts = wimus.groupby(['ServeDepth', 'ServeWidth']).size().reset_index(name='count')\n",
    "\n",
    "# ServeDepth and ServeWidth categories counts\n",
    "ctl_counts = serve_depth_width_counts[serve_depth_width_counts['ServeDepth'] == 'CTL']\n",
    "nctl_counts = serve_depth_width_counts[serve_depth_width_counts['ServeDepth'] == 'NCTL']\n",
    "\n",
    "# Calculate percentages for CTL and NCTL\n",
    "ctl_counts['percentage'] = (ctl_counts['count'] / total_shots) * 100\n",
    "nctl_counts['percentage'] = (nctl_counts['count'] / total_shots) * 100\n",
    "\n",
    "# Display the tennis court image\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(court_img, extent=[court_x_min, court_x_max, court_y_min, court_y_max])\n",
    "\n",
    "# Define the coordinates for ServeDepth and ServeWidth regions\n",
    "# Adjust these coordinates based on your image size\n",
    "\n",
    "# \"CTL\" (Close to the Line) ServeWidth categories (hot colors)\n",
    "regions_ctl = {\n",
    "    'W': {'x_min': 22, 'x_max': 26, 'y_min': 26, 'y_max': 36, 'count': 18385.0, 'percentage': 15.094293, 'color': '#d7d7d7'},  # Light gray\n",
    "    'BW': {'x_min': 26, 'x_max': 29, 'y_min': 26, 'y_max': 36, 'count': 2595.0, 'percentage': 2.130524, 'color': '#1f1f1f'},  # Dark gray\n",
    "    'B': {'x_min': 29, 'x_max': 33, 'y_min': 26, 'y_max': 36, 'count': 1854.0, 'percentage': 1.522155, 'color': '#141414'},  # Near black\n",
    "    'BC': {'x_min': 33, 'x_max': 36, 'y_min': 26, 'y_max': 36, 'count': 3555.0, 'percentage': 2.918695, 'color': '#2d2d2d'},  # Dark gray\n",
    "    'C': {'x_min': 36, 'x_max': 40, 'y_min': 26, 'y_max': 36, 'count': 6588.0, 'percentage': 5.408823, 'color': '#484848'},  # Medium gray\n",
    "}\n",
    "\n",
    "regions_nctl = {\n",
    "    'W': {'x_min': 22, 'x_max': 26, 'y_min': 36, 'y_max': 46, 'count': 6704.0, 'percentage': 5.504060, 'color': '#4d4d4d'},  # Medium gray\n",
    "    'BW': {'x_min': 26, 'x_max': 29, 'y_min': 36, 'y_max': 46, 'count': 16282.0, 'percentage': 13.367706, 'color': '#a7a7a7'},  # Light gray\n",
    "    'B': {'x_min': 29, 'x_max': 33, 'y_min': 36, 'y_max': 46, 'count': 9107.0, 'percentage': 7.476950, 'color': '#636363'},  # Medium gray\n",
    "    'BC': {'x_min': 33, 'x_max': 36, 'y_min': 36, 'y_max': 46, 'count': 13623.0, 'percentage': 11.184637, 'color': '#888888'},  # Light gray\n",
    "    'C': {'x_min': 36, 'x_max': 40, 'y_min': 36, 'y_max': 46, 'count': 23153.0, 'percentage': 19.008875, 'color': '#ffffff'},  # White\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Function to add regions to the plot\n",
    "def add_region(regions):\n",
    "    for label, region in regions.items():\n",
    "        plt.gca().add_patch(patches.Rectangle(\n",
    "            (region['x_min'], region['y_min']),\n",
    "            region['x_max'] - region['x_min'], \n",
    "            region['y_max'] - region['y_min'],\n",
    "            linewidth=1, edgecolor='none', facecolor=region['color'], alpha=0.5\n",
    "        ))\n",
    "\n",
    "# Add CTL (hot colors) and NCTL (cool colors) regions\n",
    "add_region(regions_ctl)\n",
    "add_region(regions_nctl)\n",
    "\n",
    "# Custom label coordinates for ServeWidth categories\n",
    "label_positions = {\n",
    "    'C': {'x': 50, 'y': 30},\n",
    "    'BC': {'x': 45, 'y': 20},\n",
    "    'B': {'x': 30, 'y': 10},\n",
    "    'BW': {'x': 15, 'y': 20},\n",
    "    'W': {'x': 8, 'y': 30}\n",
    "}\n",
    "\n",
    "# Function to add count and percentage labels with a small colored rectangle matching the region\n",
    "def add_labels_for_regions(data_counts, label_positions, region_type, regions):\n",
    "    for index, row in data_counts.iterrows():\n",
    "        serve_width = row['ServeWidth']\n",
    "        count = row['count']\n",
    "        percentage = row['percentage']\n",
    "        label = f\"{region_type} {serve_width}\\n{count} shots\\n({percentage:.2f}%)\"\n",
    "        \n",
    "        # Get the label position\n",
    "        x = label_positions[serve_width]['x']\n",
    "        y = label_positions[serve_width]['y']\n",
    "        \n",
    "        # Calculate center of the respective region for connecting line\n",
    "        region_center_x = (regions[serve_width]['x_min'] + regions[serve_width]['x_max']) / 2\n",
    "        region_center_y = (regions[serve_width]['y_min'] + regions[serve_width]['y_max']) / 2\n",
    "\n",
    "        # Draw a line connecting the label to the region\n",
    "        plt.plot([x, region_center_x], [y, region_center_y], color='white', lw=1)\n",
    "\n",
    "        # Add a colored rectangle behind the label, matching the region color\n",
    "        label_box = patches.FancyBboxPatch((x-6, y-3.5), 15, 8, boxstyle=\"round,pad=0.3\", \n",
    "                                           edgecolor='none', facecolor=regions[serve_width]['color'], alpha=0.6)\n",
    "        plt.gca().add_patch(label_box)\n",
    "        \n",
    "        # Add label text\n",
    "        plt.text(x, y, label, fontsize=10, ha='center', va='center', color='white')\n",
    "\n",
    "# Add labels for CTL (ServeWidth categories)\n",
    "add_labels_for_regions(ctl_counts, label_positions, 'CTL', regions_ctl)\n",
    "\n",
    "# Adjust label positions for NCTL (shift them down or choose new positions)\n",
    "label_positions_nctl = {\n",
    "    'C': {'x': 50, 'y': 50},\n",
    "    'BC': {'x': 45, 'y': 60},\n",
    "    'B': {'x': 30, 'y': 70},\n",
    "    'BW': {'x': 15, 'y': 60},\n",
    "    'W': {'x': 8, 'y': 50}\n",
    "}\n",
    "\n",
    "# Add labels for NCTL (ServeWidth categories)\n",
    "add_labels_for_regions(nctl_counts, label_positions_nctl, 'NCTL', regions_nctl)\n",
    "\n",
    "# Set axis labels and title\n",
    "plt.xlabel('Court X (width)')\n",
    "plt.ylabel('Court Y (length)')\n",
    "plt.title('Serve Depth (CTL/NCTL) and Serve Width (C, BC, B, BW, W) Distribution with Counts and Percentages')\n",
    "\n",
    "# Hide axis ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf8e292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "us['Server_win_point'] = us.apply(lambda row: 1 if row['PointServer'] == row['PointWinner'] else 0, axis=1)\n",
    "wim['Server_win_point'] = wim.apply(lambda row: 1 if row['PointServer'] == row['PointWinner'] else 0, axis=1)\n",
    "us['Returned'] = us.apply(lambda row: 1 if (row['ReturnDepth'] in ['ND', 'D'] or row['RallyCount'] >= 2) else 0, axis=1)\n",
    "wim['Returned'] = wim.apply(lambda row: 1 if (row['ReturnDepth'] in ['ND', 'D'] or row['RallyCount'] >= 2) else 0, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbc61c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551875\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Returned   No. Observations:               121801\n",
      "Model:                          Logit   Df Residuals:                   121790\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                  0.1266\n",
      "Time:                        00:01:12   Log-Likelihood:                -67219.\n",
      "converged:                       True   LL-Null:                       -76961.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.5929      0.027    -59.286      0.000      -1.646      -1.540\n",
      "CTL_B          2.9887      0.069     43.558      0.000       2.854       3.123\n",
      "CTL_BC         3.0306      0.050     61.073      0.000       2.933       3.128\n",
      "CTL_BW         3.0244      0.055     55.070      0.000       2.917       3.132\n",
      "CTL_C          1.7092      0.036     46.883      0.000       1.638       1.781\n",
      "CTL_W          1.7940      0.031     58.570      0.000       1.734       1.854\n",
      "NCTL_B         3.3617      0.039     86.046      0.000       3.285       3.438\n",
      "NCTL_BC        3.2553      0.034     94.718      0.000       3.188       3.323\n",
      "NCTL_BW        3.0882      0.033     94.780      0.000       3.024       3.152\n",
      "NCTL_C         2.2129      0.030     73.993      0.000       2.154       2.272\n",
      "NCTL_W         2.5715      0.038     68.148      0.000       2.498       2.645\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "##LOGISTIC REGRESSION, THE SIGNIFICANCE OF SERVE DIRECTION TO BE RETURNED IN US OPEN\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming your dataset is stored in 'data'\n",
    "# Combine ServeDepth and ServeWidth into a single interaction variable\n",
    "us['ServeDepth_Width'] = us['ServeDepth'] + '_' + us['ServeWidth']\n",
    "wim['ServeDepth_Width'] = wim['ServeDepth'] + '_' + wim['ServeWidth']\n",
    "\n",
    "\n",
    "# One-hot encode the interaction variable\n",
    "interaction_dummies = pd.get_dummies(us['ServeDepth_Width'], drop_first=True)\n",
    "\n",
    "# Prepare the dependent and independent variables\n",
    "X = interaction_dummies\n",
    "y = us['Returned']\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaa8038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553762\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Returned   No. Observations:               108725\n",
      "Model:                          Logit   Df Residuals:                   108714\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                  0.1249\n",
      "Time:                        00:01:12   Log-Likelihood:                -60208.\n",
      "converged:                       True   LL-Null:                       -68802.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.1402      0.039    -54.473      0.000      -2.217      -2.063\n",
      "CTL_B          3.4372      0.069     49.909      0.000       3.302       3.572\n",
      "CTL_BC         3.3639      0.056     59.981      0.000       3.254       3.474\n",
      "CTL_BW         3.3878      0.061     55.199      0.000       3.268       3.508\n",
      "CTL_C          2.2807      0.046     49.143      0.000       2.190       2.372\n",
      "CTL_W          2.3100      0.042     55.019      0.000       2.228       2.392\n",
      "NCTL_B         3.8654      0.049     78.915      0.000       3.769       3.961\n",
      "NCTL_BC        3.8125      0.046     83.293      0.000       3.723       3.902\n",
      "NCTL_BW        3.6142      0.044     81.871      0.000       3.528       3.701\n",
      "NCTL_C         2.8134      0.042     67.508      0.000       2.732       2.895\n",
      "NCTL_W         3.0922      0.048     64.673      0.000       2.998       3.186\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "##LOGISTIC REGRESSION, THE SIGNIFICANCE OF SERVE DIRECTION TO BE RETURNED IN WIMBLEDON\n",
    "\n",
    "# Combine ServeDepth and ServeWidth into a single interaction variable\n",
    "us['ServeDepth_Width'] = us['ServeDepth'] + '_' + us['ServeWidth']\n",
    "wim['ServeDepth_Width'] = wim['ServeDepth'] + '_' + wim['ServeWidth']\n",
    "\n",
    "\n",
    "# One-hot encode the interaction variable\n",
    "interaction_dummies = pd.get_dummies(wim['ServeDepth_Width'], drop_first=True)\n",
    "\n",
    "# Prepare the dependent and independent variables\n",
    "X = interaction_dummies\n",
    "y = wim['Returned']\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d65ed0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615512\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       Server_win_point   No. Observations:               108725\n",
      "Model:                          Logit   Df Residuals:                   108714\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                 0.04416\n",
      "Time:                        00:01:13   Log-Likelihood:                -66921.\n",
      "converged:                       True   LL-Null:                       -70013.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6035      0.025    -23.930      0.000      -0.653      -0.554\n",
      "CTL_B          1.1987      0.055     21.920      0.000       1.092       1.306\n",
      "CTL_BC         1.1555      0.043     26.871      0.000       1.071       1.240\n",
      "CTL_BW         1.0574      0.048     22.251      0.000       0.964       1.151\n",
      "CTL_C          1.9025      0.039     48.521      0.000       1.826       1.979\n",
      "CTL_W          1.9705      0.031     63.201      0.000       1.909       2.032\n",
      "NCTL_B         0.8979      0.033     27.262      0.000       0.833       0.962\n",
      "NCTL_BC        0.9289      0.031     30.337      0.000       0.869       0.989\n",
      "NCTL_BW        0.9900      0.030     33.167      0.000       0.932       1.049\n",
      "NCTL_C         1.5205      0.029     52.221      0.000       1.463       1.578\n",
      "NCTL_W         1.3941      0.036     38.213      0.000       1.323       1.466\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "##LOGISTIC REGRESSION, THE SIGNIFICANCE OF SERVE DIRECTION TO WIN A POINT IN WIMBLEDON\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming your dataset is stored in 'data'\n",
    "# Combine ServeDepth and ServeWidth into a single interaction variable\n",
    "wim['ServeDepth_Width'] = wim['ServeDepth'] + '_' + wim['ServeWidth']\n",
    "\n",
    "# One-hot encode the interaction variable\n",
    "interaction_dummies = pd.get_dummies(wim['ServeDepth_Width'], drop_first=True)\n",
    "\n",
    "# Prepare the dependent and independent variables\n",
    "X = interaction_dummies\n",
    "y = wim['Server_win_point']\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de273ac9",
   "metadata": {},
   "source": [
    "We observe that the using a Close to the Line serve (CTL) will give players a higher chance in winning a point, compared to Not Close to the Line (NCTL), while Center (C) and Wide (W) will give players a higher a chance in winning a point than other positions of Serve Width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7105a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617570\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       Server_win_point   No. Observations:               121801\n",
      "Model:                          Logit   Df Residuals:                   121797\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                 0.05576\n",
      "Time:                        00:01:14   Log-Likelihood:                -75221.\n",
      "converged:                       True   LL-Null:                       -79663.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.4891      0.033    -45.475      0.000      -1.553      -1.425\n",
      "1              2.2846      0.040     57.019      0.000       2.206       2.363\n",
      "2              1.6001      0.038     41.625      0.000       1.525       1.675\n",
      "Speed_KMH      0.0010      0.000      7.431      0.000       0.001       0.001\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# One-hot encode ServeNumber\n",
    "serve_number_dummies = pd.get_dummies(us['ServeNumber'], drop_first=True)\n",
    "\n",
    "# Prepare the independent variables (ServeNumber and Speed_KMH)\n",
    "X = pd.concat([serve_number_dummies, us[['Speed_KMH']]], axis=1)\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "y = us['Server_win_point']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c218172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556120\n",
      "         Iterations 12\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Returned   No. Observations:               108725\n",
      "Model:                          Logit   Df Residuals:                   108721\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                  0.1212\n",
      "Time:                        00:01:14   Log-Likelihood:                -60464.\n",
      "converged:                       True   LL-Null:                       -68802.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -8.5069      1.000     -8.506      0.000     -10.467      -6.547\n",
      "1              9.3839      1.000      9.382      0.000       7.424      11.344\n",
      "2             10.3057      1.000     10.303      0.000       8.345      12.266\n",
      "Speed_KMH     -0.0027   7.86e-05    -34.344      0.000      -0.003      -0.003\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# One-hot encode ServeNumber\n",
    "serve_number_dummies = pd.get_dummies(wim['ServeNumber'], drop_first=True)\n",
    "\n",
    "# Prepare the independent variables (ServeNumber and Speed_KMH)\n",
    "X = pd.concat([serve_number_dummies, wim[['Speed_KMH']]], axis=1)\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "y = wim['Returned']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c40c6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617570\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       Server_win_point   No. Observations:               121801\n",
      "Model:                          Logit   Df Residuals:                   121797\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                 0.05576\n",
      "Time:                        00:01:15   Log-Likelihood:                -75221.\n",
      "converged:                       True   LL-Null:                       -79663.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.4891      0.033    -45.475      0.000      -1.553      -1.425\n",
      "1              2.2846      0.040     57.019      0.000       2.206       2.363\n",
      "2              1.6001      0.038     41.625      0.000       1.525       1.675\n",
      "Speed_KMH      0.0010      0.000      7.431      0.000       0.001       0.001\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode ServeNumber\n",
    "serve_number_dummies = pd.get_dummies(us['ServeNumber'], drop_first=True)\n",
    "\n",
    "# Prepare the independent variables (ServeNumber and Speed_KMH)\n",
    "X = pd.concat([serve_number_dummies, us[['Speed_KMH']]], axis=1)\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "y = us['Server_win_point']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "617d3a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639929\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       Server_win_point   No. Observations:               121801\n",
      "Model:                          Logit   Df Residuals:                   121800\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                 0.02158\n",
      "Time:                        00:01:15   Log-Likelihood:                -77944.\n",
      "converged:                       True   LL-Null:                       -79663.\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Speed_MPH      0.0067   6.13e-05    110.057      0.000       0.007       0.007\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = us[['Speed_MPH']]\n",
    "\n",
    "# Define the dependent variable\n",
    "y = us['Server_win_point']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96aef7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34491f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming gs19, gs20, gs21, gs22, and gs23 are pandas DataFrames\n",
    "gs = pd.concat([gs19, gs20, gs21, gs22, gs23], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59764e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter, only include Grand Slam matches\n",
    "gs = gs[gs['tourney_level'] == \"G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c37ff543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DoubleFault column with categorical values\n",
    "wimus['DoubleFault'] = pd.Categorical(((wimus['P1DoubleFault'] == 1) | (wimus['P2DoubleFault'] == 1)).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91edb36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             RallyCount   R-squared:                       0.025\n",
      "Model:                            OLS   Adj. R-squared:                  0.025\n",
      "Method:                 Least Squares   F-statistic:                     4241.\n",
      "Date:                Wed, 25 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                        00:01:15   Log-Likelihood:            -4.4509e+05\n",
      "No. Observations:              165624   AIC:                         8.902e+05\n",
      "Df Residuals:                  165622   BIC:                         8.902e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          7.8883      0.067    117.760      0.000       7.757       8.020\n",
      "Speed_KMH     -0.0251      0.000    -65.125      0.000      -0.026      -0.024\n",
      "==============================================================================\n",
      "Omnibus:                    73510.925   Durbin-Watson:                   1.693\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           403847.807\n",
      "Skew:                           2.110   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.380   Cond. No.                     1.33e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.33e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1323886683.py:43: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the Seaborn style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Filter the data to include Speed_KMH > 100 and Speed_KMH < 230, and RallyCount <= 30\n",
    "filtered_data = wimus[(wimus['Speed_KMH'] > 100) & (wimus['Speed_KMH'] < 230) & (wimus['RallyCount'] <= 30)]\n",
    "\n",
    "# Independent variable (Speed_KMH) and dependent variable (RallyCount) from the filtered data\n",
    "X = filtered_data['Speed_KMH']\n",
    "y = filtered_data['RallyCount']\n",
    "\n",
    "# Add a constant to the independent variable\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Output the summary of the linear regression model\n",
    "print(result.summary())\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use a scatter plot with reduced marker size and transparency\n",
    "plt.scatter(filtered_data['Speed_KMH'], filtered_data['RallyCount'], \n",
    "            color='blue', s=10, alpha=0.3, label='Serving Data Points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(filtered_data['Speed_KMH'], result.predict(X), color='red', linewidth=2, label='Regression Line')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.xlabel('Speed_KMH', fontsize=12)\n",
    "plt.ylabel('RallyCount', fontsize=12)\n",
    "plt.title('Linear Regression: Speed_KMH vs RallyCount (Filtered Data)', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3388b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Stack player1 and player2 into a single 'player' column\n",
    "wimus_long = pd.melt(wimus, \n",
    "                     id_vars=['ServeWidth', 'ServeDepth', 'ReturnDepth', 'Speed_KMH', 'ServeNumber'], \n",
    "                     value_vars=['player1', 'player2'], \n",
    "                     var_name='PlayerType', value_name='player_name')\n",
    "\n",
    "# Group by the player_name and calculate the necessary aggregates\n",
    "grouped_data = wimus_long.groupby('player_name').agg(\n",
    "    ServeWidth_count=('ServeWidth', 'count'),\n",
    "    ServeDepth_count=('ServeDepth', 'count'),\n",
    "    ReturnDepth_count=('ReturnDepth', 'count'),\n",
    "    Avg_1st_ServeSpeed=('Speed_KMH', lambda x: x[wimus_long['ServeNumber'] == 1].mean()),\n",
    "    Avg_2nd_ServeSpeed=('Speed_KMH', lambda x: x[wimus_long['ServeNumber'] == 2].mean())\n",
    ").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e2b3235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>0_0</th>\n",
       "      <th>CTL_B</th>\n",
       "      <th>CTL_BC</th>\n",
       "      <th>CTL_BW</th>\n",
       "      <th>CTL_C</th>\n",
       "      <th>CTL_W</th>\n",
       "      <th>NCTL_B</th>\n",
       "      <th>NCTL_BC</th>\n",
       "      <th>NCTL_BW</th>\n",
       "      <th>...</th>\n",
       "      <th>NCTL_W</th>\n",
       "      <th>0</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "      <th>ND</th>\n",
       "      <th>Avg_1st_ServeSpeed</th>\n",
       "      <th>Avg_2nd_ServeSpeed</th>\n",
       "      <th>Backhand_Winners</th>\n",
       "      <th>Forehand_Winners</th>\n",
       "      <th>match_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>113.0</td>\n",
       "      <td>217</td>\n",
       "      <td>617</td>\n",
       "      <td>659</td>\n",
       "      <td>1120</td>\n",
       "      <td>179.026140</td>\n",
       "      <td>146.568569</td>\n",
       "      <td>256.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Ramos Vinolas</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>152</td>\n",
       "      <td>201</td>\n",
       "      <td>363</td>\n",
       "      <td>383</td>\n",
       "      <td>176.865440</td>\n",
       "      <td>148.683333</td>\n",
       "      <td>121.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>223</td>\n",
       "      <td>720</td>\n",
       "      <td>557</td>\n",
       "      <td>1255</td>\n",
       "      <td>181.311547</td>\n",
       "      <td>150.135729</td>\n",
       "      <td>269.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>66</td>\n",
       "      <td>307</td>\n",
       "      <td>88</td>\n",
       "      <td>520</td>\n",
       "      <td>178.296029</td>\n",
       "      <td>145.719745</td>\n",
       "      <td>85.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player_name   0_0  CTL_B  CTL_BC  CTL_BW  CTL_C  CTL_W  \\\n",
       "0             Adrian Mannarino  45.0   27.0    50.0    27.0   87.0  315.0   \n",
       "1                Alastair Gray   4.0    0.0     1.0     3.0    5.0   14.0   \n",
       "2         Albert Ramos Vinolas  39.0   11.0    40.0    20.0   36.0  130.0   \n",
       "3  Alejandro Davidovich Fokina  74.0   62.0    96.0    65.0   82.0  246.0   \n",
       "4             Alejandro Tabilo  28.0    8.0    28.0    20.0   29.0  106.0   \n",
       "\n",
       "   NCTL_B  NCTL_BC  NCTL_BW  ...  NCTL_W    0    D    M    ND  \\\n",
       "0   116.0    276.0    316.0  ...   113.0  217  617  659  1120   \n",
       "1    13.0     20.0     30.0  ...     9.0    8   67    0   122   \n",
       "2    67.0    138.0     97.0  ...    40.0  152  201  363   383   \n",
       "3   292.0    359.0    301.0  ...    90.0  223  720  557  1255   \n",
       "4    37.0     71.0     91.0  ...    36.0   66  307   88   520   \n",
       "\n",
       "   Avg_1st_ServeSpeed  Avg_2nd_ServeSpeed  Backhand_Winners  Forehand_Winners  \\\n",
       "0          179.026140          146.568569             256.0             459.0   \n",
       "1                 NaN                 NaN              26.0              41.0   \n",
       "2          176.865440          148.683333             121.0             288.0   \n",
       "3          181.311547          150.135729             269.0             600.0   \n",
       "4          178.296029          145.719745              85.0             164.0   \n",
       "\n",
       "   match_played  \n",
       "0          33.0  \n",
       "1           2.0  \n",
       "2           NaN  \n",
       "3          36.0  \n",
       "4           7.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Melt the gs_m dataset to get player names\n",
    "gs_m_long = pd.melt(gs_m, \n",
    "                     id_vars=['match_id'], \n",
    "                     value_vars=['player1', 'player2'], \n",
    "                     var_name='PlayerType', \n",
    "                     value_name='player_name')\n",
    "\n",
    "# Standardize player names to a consistent format (capitalize first letter of each word)\n",
    "gs_m_long['player_name'] = gs_m_long['player_name'].str.title()\n",
    "\n",
    "# Count rows where each player appears as a winner\n",
    "matches_as_winner = gs['winner_name'].value_counts()\n",
    "\n",
    "# Count rows where each player appears as a loser\n",
    "matches_as_loser = gs['loser_name'].value_counts()\n",
    "\n",
    "# Combine counts to get total matches played\n",
    "matches_played = (matches_as_winner + matches_as_loser).rename('match_played')\n",
    "\n",
    "# Convert to DataFrame for merging\n",
    "matches_played = matches_played.reset_index().rename(columns={'index': 'player_name'})\n",
    "\n",
    "\n",
    "# Step 2: Melt the wimus dataset to get player statistics\n",
    "wimus_long = pd.melt(wimus, \n",
    "                     id_vars=['match_id', 'ServeWidth', 'ServeDepth', 'ReturnDepth', 'Speed_KMH', 'ServeNumber', 'PointServer', 'WinnerShotType'],  # include PointServer column\n",
    "                     value_vars=['player1', 'player2'], \n",
    "                     var_name='PlayerType', \n",
    "                     value_name='player_name')\n",
    "\n",
    "# Standardize player names in wimus dataset\n",
    "wimus_long['player_name'] = wimus_long['player_name'].str.title()\n",
    "\n",
    "# Step 3: Filter based on PointServer for Serve_Depth_Width\n",
    "# If PlayerType == 'player1', count only rows where PointServer == 1\n",
    "# If PlayerType == 'player2', count only rows where PointServer == 2\n",
    "wimus_long_serve = wimus_long[\n",
    "    ((wimus_long['PlayerType'] == 'player1') & (wimus_long['PointServer'] == 1)) | \n",
    "    ((wimus_long['PlayerType'] == 'player2') & (wimus_long['PointServer'] == 2))\n",
    "].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Safely concatenate ServeDepth and ServeWidth into a new column Serve_Depth_Width\n",
    "wimus_long_serve['Serve_Depth_Width'] = wimus_long_serve['ServeDepth'] + '_' + wimus_long_serve['ServeWidth']\n",
    "\n",
    "# Step 4: Count the occurrences of each Serve_Depth_Width value for each player\n",
    "serve_depth_width_counts = wimus_long_serve.groupby('player_name')['Serve_Depth_Width'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Step 5: Filter based on PointServer for ReturnDepth\n",
    "# If PlayerType == 'player1', count rows where PointServer == 1 or PointServer == 2\n",
    "# If PlayerType == 'player2', count only rows where PointServer == 1\n",
    "wimus_long_return = wimus_long[\n",
    "    ((wimus_long['PlayerType'] == 'player1') & ((wimus_long['PointServer'] == 1) | (wimus_long['PointServer'] == 2))) | \n",
    "    ((wimus_long['PlayerType'] == 'player2') & (wimus_long['PointServer'] == 1))\n",
    "].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Step 6: Count the occurrences of each ReturnDepth value for each player\n",
    "return_depth_counts = wimus_long_return.groupby('player_name')['ReturnDepth'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Step 7: Calculate the average 1st and 2nd serve speeds for each player, excluding Speed_KMH == 0\n",
    "avg_serve_speeds = wimus_long.groupby('player_name').agg(\n",
    "    Avg_1st_ServeSpeed=('Speed_KMH', lambda x: x[(wimus_long['ServeNumber'] == 1) & (x > 0)].mean()),\n",
    "    Avg_2nd_ServeSpeed=('Speed_KMH', lambda x: x[(wimus_long['ServeNumber'] == 2) & (x > 0)].mean())\n",
    ")\n",
    "\n",
    "# Step 8: Merge counts and serve speeds with matches played\n",
    "player_stats = pd.concat([serve_depth_width_counts, return_depth_counts, avg_serve_speeds], axis=1)\n",
    "\n",
    "\n",
    "# Step 9: Filter rows where WinnerShotType is either 'F' or 'B'\n",
    "winner_shot_counts = wimus_long[wimus_long['WinnerShotType'].isin(['F', 'B'])]\n",
    "\n",
    "# Step 10: Count the occurrences of each WinnerShotType ('F' or 'B') for each player\n",
    "winner_shot_counts = winner_shot_counts.groupby('player_name')['WinnerShotType'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Rename columns for clarity\n",
    "winner_shot_counts.columns = ['Backhand_Winners', 'Forehand_Winners']\n",
    "\n",
    "# Step 11: Merge the winner shot counts into the player_stats DataFrame\n",
    "player_stats = pd.concat([player_stats, winner_shot_counts], axis=1)\n",
    "player_stats = player_stats.reset_index()\n",
    "\n",
    "player_stats = pd.merge(player_stats, matches_played, how='left', on='player_name')\n",
    "\n",
    "\n",
    "# Display the resulting dataframe\n",
    "player_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1f680a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure matches_as_winner is a Series with player_name as index\n",
    "matches_as_winner = matches_as_winner.rename_axis('player_name').reset_index(name='matches_as_winner')\n",
    "\n",
    "# Merge matches_as_winner into player_stats\n",
    "player_stats = pd.merge(player_stats, matches_as_winner, how='left', on='player_name')\n",
    "\n",
    "# Calculate Match_Win_Percentage\n",
    "player_stats['Match_Win_Percentage'] = (player_stats['matches_as_winner'] / player_stats['match_played']) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1042c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now map the heights as before\n",
    "winner_ht_map = dict(zip(gs['winner_name'], gs['winner_ht']))\n",
    "loser_ht_map = dict(zip(gs['loser_name'], gs['loser_ht']))\n",
    "\n",
    "# Map the heights to player_stats based on player_name\n",
    "player_stats['height'] = player_stats['player_name'].map(winner_ht_map).fillna(player_stats['player_name'].map(loser_ht_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e84bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map player_name to their height (both winners and losers)\n",
    "winner_ht_map = dict(zip(gs['winner_name'], gs['winner_ht']))\n",
    "loser_ht_map = dict(zip(gs['loser_name'], gs['loser_ht']))\n",
    "\n",
    "# Map the heights to player_stats based on player_name\n",
    "player_stats['height'] = player_stats['player_name'].map(winner_ht_map).fillna(player_stats['player_name'].map(loser_ht_map))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a48266e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Count the number of NaN values in each row\n",
    "na_counts = player_stats.isnull().sum(axis=1)\n",
    "\n",
    "# Step 2: Filter out rows with more than 5 NaN values\n",
    "player_stats = player_stats[na_counts <= 5]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89eea81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>0_0</th>\n",
       "      <th>CTL_B</th>\n",
       "      <th>CTL_BC</th>\n",
       "      <th>CTL_BW</th>\n",
       "      <th>CTL_C</th>\n",
       "      <th>CTL_W</th>\n",
       "      <th>NCTL_B</th>\n",
       "      <th>NCTL_BC</th>\n",
       "      <th>NCTL_BW</th>\n",
       "      <th>...</th>\n",
       "      <th>df</th>\n",
       "      <th>svpt</th>\n",
       "      <th>1stIn</th>\n",
       "      <th>1stWon</th>\n",
       "      <th>2ndWon</th>\n",
       "      <th>SvGms</th>\n",
       "      <th>bpSaved</th>\n",
       "      <th>bpFaced</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>37238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Ramos Vinolas</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>4416.0</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>41039.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>3868.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player_name   0_0  CTL_B  CTL_BC  CTL_BW  CTL_C  CTL_W  \\\n",
       "0             Adrian Mannarino  45.0   27.0    50.0    27.0   87.0  315.0   \n",
       "1                Alastair Gray   4.0    0.0     1.0     3.0    5.0   14.0   \n",
       "2         Albert Ramos Vinolas  39.0   11.0    40.0    20.0   36.0  130.0   \n",
       "3  Alejandro Davidovich Fokina  74.0   62.0    96.0    65.0   82.0  246.0   \n",
       "4             Alejandro Tabilo  28.0    8.0    28.0    20.0   29.0  106.0   \n",
       "\n",
       "   NCTL_B  NCTL_BC  NCTL_BW  ...     df    svpt   1stIn  1stWon  2ndWon  \\\n",
       "0   116.0    276.0    316.0  ...   97.0  3714.0  2227.0  1546.0   749.0   \n",
       "1    13.0     20.0     30.0  ...    8.0   205.0   130.0    97.0    34.0   \n",
       "2    67.0    138.0     97.0  ...    NaN     NaN     NaN     NaN     NaN   \n",
       "3   292.0    359.0    301.0  ...  133.0  4416.0  2954.0  1961.0   758.0   \n",
       "4    37.0     71.0     91.0  ...   39.0   896.0   575.0   411.0   154.0   \n",
       "\n",
       "   SvGms  bpSaved  bpFaced    rank  rank_points  \n",
       "0  566.0    231.0    366.0  1584.0      37238.0  \n",
       "1   29.0     14.0     19.0   576.0        346.0  \n",
       "2    NaN      NaN      NaN     NaN          NaN  \n",
       "3  691.0    215.0    383.0  1831.0      41039.0  \n",
       "4  139.0     46.0     76.0   849.0       3868.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_and_aggregate(gs_dataset, player_stats):\n",
    "    # Merge for winner stats\n",
    "    winner_merge = gs[['winner_name', 'w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon', 'w_2ndWon',\n",
    "                               'w_SvGms', 'w_bpSaved', 'w_bpFaced', 'winner_rank', 'winner_rank_points']].copy()\n",
    "    \n",
    "    # Rename 'w_' columns to remove the prefix\n",
    "    winner_merge.columns = ['player_name', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms',\n",
    "                            'bpSaved', 'bpFaced', 'rank', 'rank_points']\n",
    "\n",
    "    # Merge for loser stats\n",
    "    loser_merge = gs[['loser_name', 'l_ace', 'l_df', 'l_svpt', 'l_1stIn', 'l_1stWon', 'l_2ndWon',\n",
    "                              'l_SvGms', 'l_bpSaved', 'l_bpFaced', 'loser_rank', 'loser_rank_points']].copy()\n",
    "    \n",
    "    # Rename 'l_' columns to remove the prefix\n",
    "    loser_merge.columns = ['player_name', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms',\n",
    "                           'bpSaved', 'bpFaced', 'rank', 'rank_points']\n",
    "\n",
    "    # Concatenate winner and loser stats into a single DataFrame\n",
    "    combined = pd.concat([winner_merge, loser_merge], ignore_index=True)\n",
    "    \n",
    "    # Group by player_name and sum up the statistics for each player\n",
    "    aggregated_stats = combined.groupby('player_name').sum().reset_index()\n",
    "    player_stats_merged = pd.merge(player_stats, aggregated_stats, how='left', left_on='player_name', right_on='player_name')\n",
    "    return player_stats_merged\n",
    "\n",
    "# Example usage:\n",
    "merged_stats = merge_and_aggregate(gs, player_stats)\n",
    "\n",
    "# Save or inspect the result\n",
    "# merged_stats.to_csv('merged_player_stats.csv', index=False)\n",
    "merged_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef52f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def classify_rank_elite(gs, player_stats):\n",
    "    # Handle winner stats\n",
    "    winner_ranks = gs[['winner_name', 'winner_rank', 'tourney_id']].copy()\n",
    "    winner_ranks.columns = ['player_name', 'rank', 'tourney_id']\n",
    "\n",
    "    # Handle loser stats\n",
    "    loser_ranks = gs[['loser_name', 'loser_rank', 'tourney_id']].copy()\n",
    "    loser_ranks.columns = ['player_name', 'rank', 'tourney_id']\n",
    "\n",
    "    # Combine winner and loser ranks\n",
    "    combined_ranks = pd.concat([winner_ranks, loser_ranks], ignore_index=True)\n",
    "\n",
    "    # Calculate the average rank for each player\n",
    "    avg_ranks = combined_ranks.groupby('player_name')['rank'].mean().reset_index()\n",
    "\n",
    "    # Find if the player has rank <= 8.1 in 4 or more tournaments\n",
    "    elite_tourney = combined_ranks[combined_ranks['rank'] <= 8.1].groupby('player_name').tourney_id.nunique().reset_index()\n",
    "    elite_tourney['is_elite_tourney'] = elite_tourney['tourney_id'] >= 4  # At least 4 different tournaments with rank <= 8.1\n",
    "\n",
    "    # Merge with avg_ranks to get both conditions\n",
    "    avg_ranks = pd.merge(avg_ranks, elite_tourney[['player_name', 'is_elite_tourney']], how='left', on='player_name')\n",
    "\n",
    "    # Fill NaN values in is_elite_tourney with False (for players with less than 4 tournaments)\n",
    "    avg_ranks['is_elite_tourney'].fillna(False, inplace=True)\n",
    "\n",
    "    # Classify players as Elite (E) or Non-Elite (NE) based on both conditions\n",
    "    avg_ranks['rank_elite'] = avg_ranks.apply(lambda row: 'E' if row['rank'] <= 17 or row['is_elite_tourney'] else 'NE', axis=1)\n",
    "\n",
    "    # Merge the rank classification back into the player_stats dataset\n",
    "    player_stats_merged = pd.merge(merged_stats, avg_ranks[['player_name', 'rank_elite']], how='left', on='player_name')\n",
    "\n",
    "    return player_stats_merged\n",
    "\n",
    "player_stats = classify_rank_elite(gs, player_stats)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e618ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alexander Zverev', 'Andrey Rublev', 'Carlos Alcaraz', 'Casper Ruud', 'Daniil Medvedev', 'Dominic Thiem', 'Felix Auger Aliassime', 'Matteo Berrettini', 'Novak Djokovic', 'Rafael Nadal', 'Roger Federer', 'Stefanos Tsitsipas']\n"
     ]
    }
   ],
   "source": [
    "# Filter the players where rank_elite is 'E'\n",
    "elite_players = player_stats[player_stats['rank_elite'] == 'E']['player_name'].tolist()\n",
    "\n",
    "# Output the list of elite players\n",
    "print(elite_players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ec6abdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1560701722.py:34: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def plot_avg_1st_serve_by_rank_elite(player_stats):\n",
    "    # Group the data by rank_elite and calculate the average 1st serve speed\n",
    "    serve_speeds = player_stats.groupby('rank_elite')['Avg_1st_ServeSpeed'].mean().reset_index()\n",
    "\n",
    "    # Create a bar chart\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "    bars = ax.bar(serve_speeds['rank_elite'], serve_speeds['Avg_1st_ServeSpeed'], \n",
    "                  color=['#1f77b4', '#ff7f0e'], edgecolor='black', linewidth=1.2)\n",
    "\n",
    "    # Adding value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}',  # Format the label\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),  # Label position\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Adding title and labels\n",
    "    ax.set_title('Average 1st Serve Speed: Elite vs Non-Elite', fontsize=16, fontweight='bold', color='darkblue')\n",
    "    ax.set_xlabel('Rank Elite (E vs NE)', fontsize=14)\n",
    "    ax.set_ylabel('Average 1st Serve Speed (km/h)', fontsize=14)\n",
    "\n",
    "    # Customize ticks and grid\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Non-Elite (NE)', 'Elite (E)'], fontsize=12)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Set background color\n",
    "    ax.set_facecolor('#f9f9f9')\n",
    "\n",
    "    # Display the bar chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_avg_1st_serve_by_rank_elite(player_stats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcede529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1691057835.py:33: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1691057835.py:34: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def plot_avg_1st_serve_by_rank_elite(player_stats):\n",
    "    # Group the data by rank_elite and calculate the average 1st serve speed\n",
    "    serve_speeds = player_stats.groupby('rank_elite')['Avg_2nd_ServeSpeed'].mean().reset_index()\n",
    "\n",
    "    # Create a bar chart\n",
    "    fig, ax = plt.subplots(figsize=(3, 1))\n",
    "    bars = ax.bar(serve_speeds['rank_elite'], serve_speeds['Avg_2nd_ServeSpeed'], \n",
    "                  color=['#1f77b4', '#ff7f0e'], edgecolor='black', linewidth=1.2)\n",
    "\n",
    "    # Adding value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}',  # Format the label\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),  # Label position\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Adding title and labels\n",
    "    ax.set_title('Average 2nd Serve Speed: Elite vs Non-Elite', fontsize=16, fontweight='bold', color='darkblue')\n",
    "    ax.set_xlabel('Rank Elite (E vs NE)', fontsize=14)\n",
    "    ax.set_ylabel('Average 1st Serve Speed (km/h)', fontsize=14)\n",
    "\n",
    "    # Customize ticks and grid\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Non-Elite (NE)', 'Elite (E)'], fontsize=12)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Set background color\n",
    "    ax.set_facecolor('#f9f9f9')\n",
    "\n",
    "    # Display the bar chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_avg_1st_serve_by_rank_elite(player_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d3b4b",
   "metadata": {},
   "source": [
    "This implies that in fact the Elite player has a weaker serve in terms of speed, which suggested that speed is not a significant key component for being a great player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20e2ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2244087147.py:27: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pie_charts_for_serve_depth_width(player_stats):\n",
    "    # List of serve categories\n",
    "    categories = ['CTL_B', 'CTL_BC', 'CTL_BW', 'CTL_C', 'CTL_W', 'NCTL_B', 'NCTL_BC', 'NCTL_BW', 'NCTL_C', 'NCTL_W']\n",
    "\n",
    "    # Grouping by rank_elite ('E' and 'NE')\n",
    "    group_e = player_stats[player_stats['rank_elite'] == 'E'][categories].sum()\n",
    "    group_ne = player_stats[player_stats['rank_elite'] == 'NE'][categories].sum()\n",
    "\n",
    "    # Calculate percentages for each group\n",
    "    group_e_percentage = (group_e / group_e.sum()) * 100\n",
    "    group_ne_percentage = (group_ne / group_ne.sum()) * 100\n",
    "\n",
    "    # Plotting the pie chart for Elite players\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    ax[0].pie(group_e_percentage, labels=categories, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "    ax[0].set_title('Distribution of Serve Depth & Width for Elite Players (E)', fontsize=14)\n",
    "\n",
    "    # Plotting the pie chart for Non-Elite players\n",
    "    ax[1].pie(group_ne_percentage, labels=categories, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "    ax[1].set_title('Distribution of Serve Depth & Width for Non-Elite Players (NE)', fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_pie_charts_for_serve_depth_width(player_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb5319ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2456782814.py:31: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pie_charts_for_return_depth(player_stats):\n",
    "    # List of ReturnDepth categories\n",
    "    categories = ['ND', 'D']\n",
    "\n",
    "    # Calculating the total ReturnDepth counts divided by the number of matches played for each player\n",
    "    player_stats['ND_per_match'] = player_stats['ND'] / player_stats['match_played']\n",
    "    player_stats['D_per_match'] = player_stats['D'] / player_stats['match_played']\n",
    "\n",
    "    # Grouping by rank_elite ('E' and 'NE') and calculating mean values\n",
    "    group_e = player_stats[player_stats['rank_elite'] == 'E'][['ND_per_match', 'D_per_match']].mean()\n",
    "    group_ne = player_stats[player_stats['rank_elite'] == 'NE'][['ND_per_match', 'D_per_match']].mean()\n",
    "\n",
    "    # Calculate percentages for each group\n",
    "    group_e_percentage = (group_e / group_e.sum()) * 100\n",
    "    group_ne_percentage = (group_ne / group_ne.sum()) * 100\n",
    "\n",
    "    # Plotting the pie chart for Elite players\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    ax[0].pie(group_e_percentage, labels=categories, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "    ax[0].set_title('Distribution of Return Depth for Elite Players (E)', fontsize=14)\n",
    "\n",
    "    # Plotting the pie chart for Non-Elite players\n",
    "    ax[1].pie(group_ne_percentage, labels=categories, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "    ax[1].set_title('Distribution of Return Depth for Non-Elite Players (NE)', fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_pie_charts_for_return_depth(player_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc772d",
   "metadata": {},
   "source": [
    "This graph implies that the variations and percentage of service position does not significantly contribute to the differences in performance between elite players and non elite players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a58eddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>1stIn</th>\n",
       "      <th>1stWon</th>\n",
       "      <th>match_played</th>\n",
       "      <th>1stIn_per_match</th>\n",
       "      <th>1stWon_per_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.484848</td>\n",
       "      <td>46.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>130.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>48.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Ramos Vinolas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>2954.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>82.055556</td>\n",
       "      <td>54.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>575.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>58.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player_name   1stIn  1stWon  match_played  1stIn_per_match  \\\n",
       "0             Adrian Mannarino  2227.0  1546.0          33.0        67.484848   \n",
       "1                Alastair Gray   130.0    97.0           2.0        65.000000   \n",
       "2         Albert Ramos Vinolas     NaN     NaN           NaN              NaN   \n",
       "3  Alejandro Davidovich Fokina  2954.0  1961.0          36.0        82.055556   \n",
       "4             Alejandro Tabilo   575.0   411.0           7.0        82.142857   \n",
       "\n",
       "   1stWon_per_match  \n",
       "0         46.848485  \n",
       "1         48.500000  \n",
       "2               NaN  \n",
       "3         54.472222  \n",
       "4         58.714286  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming '1stIn', '1stWon', and 'match_played' are existing columns in the player_stats DataFrame\n",
    "\n",
    "# Create new columns by dividing 1stIn and 1stWon by match_played\n",
    "player_stats['1stIn_per_match'] = player_stats['1stIn'] / player_stats['match_played']\n",
    "player_stats['1stWon_per_match'] = player_stats['1stWon'] / player_stats['match_played']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "player_stats[['player_name', '1stIn', '1stWon', 'match_played', '1stIn_per_match', '1stWon_per_match']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adeaa80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/256254782.py:34: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group by rank_elite and calculate the average for 1stIn_per_match and 1stWon_per_match\n",
    "avg_serve_stats = player_stats.groupby('rank_elite').agg({\n",
    "    '1stIn_per_match': 'mean',\n",
    "    '1stWon_per_match': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the bar chart\n",
    "ax = avg_serve_stats.plot(kind='bar', x='rank_elite', y=['1stIn_per_match', '1stWon_per_match'], \n",
    "                          color=['#1f77b4', '#ff7f0e'], edgecolor='black', width=0.8, legend=True)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Average 1st Serve In and 1st Serve Won per Match by Rank Elite (NE vs E)', fontsize=14)\n",
    "plt.ylabel('Average per Match', fontsize=12)\n",
    "plt.xlabel('Rank Elite (NE vs E)', fontsize=12)\n",
    "\n",
    "# Add numbers on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.2f}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=10)\n",
    "\n",
    "# Adjust the legend\n",
    "plt.legend(['1stIn_per_match', '1stWon_per_match'], loc='upper right', fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bf4d0",
   "metadata": {},
   "source": [
    "This implies that the elite players have a considerable average number of 1st serve in and 1st serve won compared to the non-elite players, with about 20 units for each category. Even though by percentage, 20 units is not that significant, however, during professional matches, every point matters, and 20 points are about 5 games of tennis. These 20 points only counts for 1st Serve In and 1st Serve Won, not to mention 2nd Serves, which differentiates between great players and those who are yet to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6845b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats['2ndWon_per_match'] = player_stats['2ndWon'] / player_stats['match_played']\n",
    "player_stats['bpSaved_per_match'] = player_stats['bpSaved'] / player_stats['match_played']\n",
    "player_stats['bpFaced_per_match'] = player_stats['bpFaced'] / player_stats['match_played']\n",
    "player_stats['bpSaved%'] = player_stats['bpSaved'] / player_stats['bpFaced']\n",
    "\n",
    "\n",
    "\n",
    "# Display the updated DataFrame\n",
    "player_stats[['player_name', '1stIn', '1stWon', 'match_played', '1stIn_per_match', '1stWon_per_match',\n",
    "              '2ndWon_per_match', 'bpSaved_per_match', 'bpFaced_per_match']].head()\n",
    "\n",
    "player_stats = player_stats.dropna(thresh=player_stats.shape[1] - 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c9a3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2308800457.py:49: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Group the data by 'rank_elite' and calculate the mean for each variable\n",
    "grouped_data = player_stats.groupby('rank_elite').agg({\n",
    "    '2ndWon_per_match': 'mean',\n",
    "    'bpSaved_per_match': 'mean',\n",
    "    'bpFaced_per_match': 'mean',\n",
    "    'bpSaved%': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Set the style for the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a figure with subplots for each variable\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "# Plot for 2ndWon_per_match\n",
    "sns.barplot(ax=axes[0], x='rank_elite', y='2ndWon_per_match', data=grouped_data, palette=\"muted\")\n",
    "axes[0].set_title('Avg 2ndWon per Match by Rank Elite')\n",
    "axes[0].set_xlabel('Rank Elite')\n",
    "axes[0].set_ylabel('2ndWon per Match')\n",
    "\n",
    "# Plot for bpSaved_per_match\n",
    "sns.barplot(ax=axes[1], x='rank_elite', y='bpSaved_per_match', data=grouped_data, palette=\"muted\")\n",
    "axes[1].set_title('Avg bpSaved per Match by Rank Elite')\n",
    "axes[1].set_xlabel('Rank Elite')\n",
    "axes[1].set_ylabel('bpSaved per Match')\n",
    "\n",
    "# Plot for bpFaced_per_match\n",
    "sns.barplot(ax=axes[2], x='rank_elite', y='bpFaced_per_match', data=grouped_data, palette=\"muted\")\n",
    "axes[2].set_title('Avg bpFaced per Match by Rank Elite')\n",
    "axes[2].set_xlabel('Rank Elite')\n",
    "axes[2].set_ylabel('bpFaced per Match')\n",
    "\n",
    "# Plot for bpSaved%\n",
    "sns.barplot(ax=axes[3], x='rank_elite', y='bpSaved%', data=grouped_data, palette=\"muted\")\n",
    "axes[3].set_title('Avg bpSaved% by Rank Elite')\n",
    "axes[3].set_xlabel('Rank Elite')\n",
    "axes[3].set_ylabel('bpSaved%')\n",
    "\n",
    "# Add labels to the bars with the average values\n",
    "for ax in axes:\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.2f}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='center', xytext=(0, 9), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fb41a",
   "metadata": {},
   "source": [
    "The graphs also imply that the elite players took the edge of number of 2nd Serve Point won per matches compared to the non-elite ones, by average of 6 points. In total for both first and second serve point, the elite players edged by 26 points, which is a significant number in professional tennis. Although they have fewer break point saved than their non-elite counterparts, it may be due to the fact that they faced considerably fewer break points than the non-elite. In terms of break point saved % (saved/faced), elite players again edged the non-elite by 6%, implying that the elites are clutcher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c53715de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wimus['0-4'] = wimus['RallyCount'].apply(lambda x: 1 if 0 <= x <= 4 else 0)\n",
    "wimus['5-8'] = wimus['RallyCount'].apply(lambda x: 1 if 5 <= x <= 8 else 0)\n",
    "wimus['9+'] = wimus['RallyCount'].apply(lambda x: 1 if x >= 9 else 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10b9781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for wins and losses by rally categories\n",
    "wimus['0-4_w'] = wimus['0-4']\n",
    "wimus['5-8_w'] = wimus['5-8']\n",
    "wimus['9+_w'] = wimus['9+']\n",
    "\n",
    "wimus['0-4_l'] = wimus['0-4']\n",
    "wimus['5-8_l'] = wimus['5-8']\n",
    "wimus['9+_l'] = wimus['9+']\n",
    "\n",
    "# Determine the winner's and loser's names\n",
    "wimus['Point_Winner'] = wimus.apply(\n",
    "    lambda row: row['player1'] if row['PointWinner'] == 1 else row['player2'], axis=1\n",
    ")\n",
    "wimus['Point_Loser'] = wimus.apply(\n",
    "    lambda row: row['player2'] if row['PointWinner'] == 1 else row['player1'], axis=1\n",
    ")\n",
    "\n",
    "# Group by Point_Winner for wins\n",
    "wins = wimus.groupby('Point_Winner')[['0-4_w', '5-8_w', '9+_w']].sum().reset_index()\n",
    "\n",
    "# Group by Point_Loser for losses\n",
    "losses = wimus.groupby('Point_Loser')[['0-4_l', '5-8_l', '9+_l']].sum().reset_index()\n",
    "\n",
    "# Rename columns for merging clarity\n",
    "wins.rename(columns={'Point_Winner': 'player_name'}, inplace=True)\n",
    "losses.rename(columns={'Point_Loser': 'player_name'}, inplace=True)\n",
    "\n",
    "# Merge wins and losses on player_name\n",
    "result = pd.merge(wins, losses, on='player_name', how='outer').fillna(0)\n",
    "\n",
    "# Filter players with at least one non-zero value in their row\n",
    "result = result.loc[(result.iloc[:, 1:] != 0).all(axis=1)]\n",
    "\n",
    "# Calculate the percentage columns\n",
    "\n",
    "result['0-4_%'] = result['0-4_w']*100 / (result['0-4_w'] + result['0-4_l'])\n",
    "result['5-8_%'] = result['5-8_w']*100 / (result['5-8_w'] + result['5-8_l'])\n",
    "result['9+_%'] = result['9+_w']*100 / (result['9+_w'] + result['9+_l'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "078ea4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for each rally count value from 1 to 14 and one for 15+\n",
    "for i in range(1, 15):\n",
    "    every[f'{i}'] = every['RallyCount'].apply(lambda x: 1 if x == i else 0)\n",
    "\n",
    "# Create a column for values greater than or equal to 15\n",
    "every['15+'] = every['RallyCount'].apply(lambda x: 1 if x >= 15 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d95d2ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>0_0</th>\n",
       "      <th>CTL_B</th>\n",
       "      <th>CTL_BC</th>\n",
       "      <th>CTL_BW</th>\n",
       "      <th>CTL_C</th>\n",
       "      <th>CTL_W</th>\n",
       "      <th>NCTL_B</th>\n",
       "      <th>NCTL_BC</th>\n",
       "      <th>NCTL_BW</th>\n",
       "      <th>...</th>\n",
       "      <th>6_%</th>\n",
       "      <th>7_%</th>\n",
       "      <th>8_%</th>\n",
       "      <th>9_%</th>\n",
       "      <th>10_%</th>\n",
       "      <th>11_%</th>\n",
       "      <th>12_%</th>\n",
       "      <th>13_%</th>\n",
       "      <th>14_%</th>\n",
       "      <th>15+_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>53.403141</td>\n",
       "      <td>34.146341</td>\n",
       "      <td>53.061224</td>\n",
       "      <td>40.277778</td>\n",
       "      <td>49.295775</td>\n",
       "      <td>39.024390</td>\n",
       "      <td>69.565217</td>\n",
       "      <td>38.095238</td>\n",
       "      <td>42.335766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.783550</td>\n",
       "      <td>50.471698</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>53.968254</td>\n",
       "      <td>59.782609</td>\n",
       "      <td>60.714286</td>\n",
       "      <td>66.071429</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>47.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aleksandar Vukic</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player_name   0_0  CTL_B  CTL_BC  CTL_BW  CTL_C  CTL_W  \\\n",
       "0             Adrian Mannarino  45.0   27.0    50.0    27.0   87.0  315.0   \n",
       "1                Alastair Gray   4.0    0.0     1.0     3.0    5.0   14.0   \n",
       "2  Alejandro Davidovich Fokina  74.0   62.0    96.0    65.0   82.0  246.0   \n",
       "3             Alejandro Tabilo  28.0    8.0    28.0    20.0   29.0  106.0   \n",
       "4             Aleksandar Vukic   6.0    3.0     7.0     2.0   14.0   38.0   \n",
       "\n",
       "   NCTL_B  NCTL_BC  NCTL_BW  ...        6_%        7_%        8_%        9_%  \\\n",
       "0   116.0    276.0    316.0  ...  43.478261  53.403141  34.146341  53.061224   \n",
       "1    13.0     20.0     30.0  ...        NaN        NaN        NaN        NaN   \n",
       "2   292.0    359.0    301.0  ...  49.783550  50.471698  54.545455  53.968254   \n",
       "3    37.0     71.0     91.0  ...        NaN        NaN        NaN        NaN   \n",
       "4    18.0     19.0     25.0  ...        NaN        NaN        NaN        NaN   \n",
       "\n",
       "        10_%       11_%       12_%       13_%       14_%      15+_%  \n",
       "0  40.277778  49.295775  39.024390  69.565217  38.095238  42.335766  \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "2  59.782609  60.714286  66.071429  47.500000  54.545455  47.872340  \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create columns for wins and losses by rally categories (1 to 15+)\n",
    "for i in range(1, 15):\n",
    "    every[f'{i}_w'] = every[f'{i}']\n",
    "    every[f'{i}_l'] = every[f'{i}']\n",
    "\n",
    "# Create the 15+ win and loss columns\n",
    "every['15+_w'] = every['15+']\n",
    "every['15+_l'] = every['15+']\n",
    "\n",
    "# Determine the winner's and loser's names\n",
    "every['Point_Winner'] = every.apply(\n",
    "    lambda row: row['player1'] if row['PointWinner'] == 1 else row['player2'], axis=1\n",
    ")\n",
    "every['Point_Loser'] = every.apply(\n",
    "    lambda row: row['player2'] if row['PointWinner'] == 1 else row['player1'], axis=1\n",
    ")\n",
    "\n",
    "# Group by Point_Winner for wins (for all categories 1 to 15+)\n",
    "wins = every.groupby('Point_Winner')[['1_w', '2_w', '3_w', '4_w', '5_w', '6_w', '7_w', '8_w', '9_w', '10_w', '11_w', '12_w', '13_w', '14_w', '15+_w']].sum().reset_index()\n",
    "\n",
    "# Group by Point_Loser for losses (for all categories 1 to 15+)\n",
    "losses = every.groupby('Point_Loser')[['1_l', '2_l', '3_l', '4_l', '5_l', '6_l', '7_l', '8_l', '9_l', '10_l', '11_l', '12_l', '13_l', '14_l', '15+_l']].sum().reset_index()\n",
    "\n",
    "# Rename columns for merging clarity\n",
    "wins.rename(columns={'Point_Winner': 'player_name'}, inplace=True)\n",
    "losses.rename(columns={'Point_Loser': 'player_name'}, inplace=True)\n",
    "\n",
    "# Merge wins and losses on player_name\n",
    "result1 = pd.merge(wins, losses, on='player_name', how='outer').fillna(0)\n",
    "result = pd.merge(result, result1, on='player_name', how='outer').fillna(0)\n",
    "\n",
    "\n",
    "# Filter players with at least one non-zero value in their row\n",
    "result = result.loc[(result.iloc[:, 1:] != 0).all(axis=1)]\n",
    "\n",
    "# Calculate the percentage columns for each range from 1 to 15+\n",
    "for i in range(1, 15):\n",
    "    result[f'{i}_%'] = result[f'{i}_w'] * 100 / (result[f'{i}_w'] + result[f'{i}_l'])\n",
    "\n",
    "# Calculate the 15+ percentage\n",
    "result['15+_%'] = result['15+_w'] * 100 / (result['15+_w'] + result['15+_l'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge the result DataFrame with player_stats on 'player_name'\n",
    "player_stats = player_stats.merge(\n",
    "    result[['player_name', '0-4_%', '5-8_%', '9+_%', \n",
    "            '1_%', '2_%', '3_%', '4_%', '5_%', '6_%', '7_%', '8_%', '9_%', '10_%', '11_%', '12_%', '13_%', '14_%', '15+_%']],\n",
    "    on='player_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "player_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0609e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     Avg_1st_ServeSpeed   R-squared:                       0.264\n",
      "Model:                            OLS   Adj. R-squared:                  0.261\n",
      "Method:                 Least Squares   F-statistic:                     73.72\n",
      "Date:                Wed, 25 Dec 2024   Prob (F-statistic):           2.26e-15\n",
      "Time:                        00:02:09   Log-Likelihood:                -610.60\n",
      "No. Observations:                 207   AIC:                             1225.\n",
      "Df Residuals:                     205   BIC:                             1232.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        108.4993      8.708     12.460      0.000      91.331     125.667\n",
      "height         0.4004      0.047      8.586      0.000       0.308       0.492\n",
      "==============================================================================\n",
      "Omnibus:                       21.904   Durbin-Watson:                   2.167\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.711\n",
      "Skew:                          -0.372   Prob(JB):                     2.41e-14\n",
      "Kurtosis:                       5.592   Cond. No.                     5.04e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.04e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Ensure the data is clean (drop rows with missing Avg_1st_ServeSpeed or height)\n",
    "player_stats_clean = player_stats.dropna(subset=['Avg_1st_ServeSpeed', 'height'])\n",
    "\n",
    "# Step 2: Define dependent (y) and independent (X) variables\n",
    "X = player_stats_clean['height']  # Independent variable (height)\n",
    "y = player_stats_clean['Avg_1st_ServeSpeed']  # Dependent variable (1st Serve Speed)\n",
    "\n",
    "# Step 3: Add a constant to the independent variable for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Step 4: Perform linear regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Step 5: Print the summary of the regression results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f0a6a",
   "metadata": {},
   "source": [
    "## Regression Model Interpretation\n",
    "\n",
    "This regression model suggest that an 1cm increase in height may result in a 0.3 km/h increase in average first serve speed. It shows positive correlational relationship between the players' height and their average first serve speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d6b01dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player1</th>\n",
       "      <th>player2</th>\n",
       "      <th>P1PointsWon</th>\n",
       "      <th>P2PointsWon</th>\n",
       "      <th>P1Deficit</th>\n",
       "      <th>P2Deficit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-usopen-1101</td>\n",
       "      <td>Novak Djokovic</td>\n",
       "      <td>Roberto Carballes Baena</td>\n",
       "      <td>94</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-usopen-1102</td>\n",
       "      <td>Sam Querrey</td>\n",
       "      <td>Juan Ignacio Londero</td>\n",
       "      <td>107</td>\n",
       "      <td>127</td>\n",
       "      <td>-20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-usopen-1105</td>\n",
       "      <td>Stan Wawrinka</td>\n",
       "      <td>Jannik Sinner</td>\n",
       "      <td>142</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-usopen-1108</td>\n",
       "      <td>Zachary Svajda</td>\n",
       "      <td>Paolo Lorenzi</td>\n",
       "      <td>166</td>\n",
       "      <td>181</td>\n",
       "      <td>-15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-usopen-1111</td>\n",
       "      <td>Tomas Berdych</td>\n",
       "      <td>Jenson Brooksby</td>\n",
       "      <td>96</td>\n",
       "      <td>113</td>\n",
       "      <td>-17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           match_id         player1                  player2  P1PointsWon  \\\n",
       "0  2019-usopen-1101  Novak Djokovic  Roberto Carballes Baena           94   \n",
       "1  2019-usopen-1102     Sam Querrey     Juan Ignacio Londero          107   \n",
       "2  2019-usopen-1105   Stan Wawrinka            Jannik Sinner          142   \n",
       "3  2019-usopen-1108  Zachary Svajda            Paolo Lorenzi          166   \n",
       "4  2019-usopen-1111   Tomas Berdych          Jenson Brooksby           96   \n",
       "\n",
       "   P2PointsWon  P1Deficit  P2Deficit  \n",
       "0           70         24        -24  \n",
       "1          127        -20         20  \n",
       "2          128         14        -14  \n",
       "3          181        -15         15  \n",
       "4          113        -17         17  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming wimus is your DataFrame\n",
    "# Step 1: Group by 'match_id' and take the last row for each group\n",
    "last_points_per_match = wimus.groupby('match_id').last().reset_index()\n",
    "\n",
    "# Step 2: Calculate the deficits for player1 and player2\n",
    "last_points_per_match['P1Deficit'] = last_points_per_match['P1PointsWon'] - last_points_per_match['P2PointsWon']\n",
    "last_points_per_match['P2Deficit'] = last_points_per_match['P2PointsWon'] - last_points_per_match['P1PointsWon']\n",
    "\n",
    "# Step 3: Create the deficit dataset with the necessary columns\n",
    "deficit = last_points_per_match[['match_id', 'player1', 'player2', 'P1PointsWon', 'P2PointsWon', 'P1Deficit', 'P2Deficit']]\n",
    "\n",
    "# Display the first few rows of the resulting deficit dataset\n",
    "deficit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c027c4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>total_deficit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>-59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Ramos Vinolas</td>\n",
       "      <td>-177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Yuichi Sugita</td>\n",
       "      <td>-104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Zachary Svajda</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Zdenek Kolar</td>\n",
       "      <td>-28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Zhizhen Zhang</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Zizou Bergs</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     player_name  total_deficit\n",
       "0               Adrian Mannarino          -59.0\n",
       "1                  Alastair Gray           23.0\n",
       "2           Albert Ramos Vinolas         -177.0\n",
       "3    Alejandro Davidovich Fokina           69.0\n",
       "4               Alejandro Tabilo           13.0\n",
       "..                           ...            ...\n",
       "266                Yuichi Sugita         -104.0\n",
       "267               Zachary Svajda          -34.0\n",
       "268                 Zdenek Kolar          -28.0\n",
       "269                Zhizhen Zhang          -19.0\n",
       "270                  Zizou Bergs          -13.0\n",
       "\n",
       "[271 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Sum P1Deficit for player1 and P2Deficit for player2, then combine them\n",
    "player1_deficit = deficit.groupby('player1')['P1Deficit'].sum().rename('total_deficit')\n",
    "player2_deficit = deficit.groupby('player2')['P2Deficit'].sum().rename('total_deficit')\n",
    "\n",
    "# Combine the two deficit series, summing them where players appear in both columns\n",
    "total_def = player1_deficit.add(player2_deficit, fill_value=0).reset_index()\n",
    "\n",
    "# Rename the 'index' column to 'player_name' for clarity\n",
    "total_def = total_def.rename(columns={'index': 'player_name'})\n",
    "\n",
    "# Ensure the resulting dataset has player_name and their total_deficit\n",
    "total_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e98cc0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>0_0</th>\n",
       "      <th>CTL_B</th>\n",
       "      <th>CTL_BC</th>\n",
       "      <th>CTL_BW</th>\n",
       "      <th>CTL_C</th>\n",
       "      <th>CTL_W</th>\n",
       "      <th>NCTL_B</th>\n",
       "      <th>NCTL_BC</th>\n",
       "      <th>NCTL_BW</th>\n",
       "      <th>...</th>\n",
       "      <th>7_%</th>\n",
       "      <th>8_%</th>\n",
       "      <th>9_%</th>\n",
       "      <th>10_%</th>\n",
       "      <th>11_%</th>\n",
       "      <th>12_%</th>\n",
       "      <th>13_%</th>\n",
       "      <th>14_%</th>\n",
       "      <th>15+_%</th>\n",
       "      <th>total_deficit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.403141</td>\n",
       "      <td>34.146341</td>\n",
       "      <td>53.061224</td>\n",
       "      <td>40.277778</td>\n",
       "      <td>49.295775</td>\n",
       "      <td>39.024390</td>\n",
       "      <td>69.565217</td>\n",
       "      <td>38.095238</td>\n",
       "      <td>42.335766</td>\n",
       "      <td>-59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.471698</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>53.968254</td>\n",
       "      <td>59.782609</td>\n",
       "      <td>60.714286</td>\n",
       "      <td>66.071429</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>47.872340</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aleksandar Vukic</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Yu Hsiou Hsu</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Yuichi Sugita</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Zachary Svajda</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>56.521739</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>48.275862</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Zdenek Kolar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Zhizhen Zhang</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.589744</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     player_name   0_0  CTL_B  CTL_BC  CTL_BW  CTL_C  CTL_W  \\\n",
       "0               Adrian Mannarino  45.0   27.0    50.0    27.0   87.0  315.0   \n",
       "1                  Alastair Gray   4.0    0.0     1.0     3.0    5.0   14.0   \n",
       "2    Alejandro Davidovich Fokina  74.0   62.0    96.0    65.0   82.0  246.0   \n",
       "3               Alejandro Tabilo  28.0    8.0    28.0    20.0   29.0  106.0   \n",
       "4               Aleksandar Vukic   6.0    3.0     7.0     2.0   14.0   38.0   \n",
       "..                           ...   ...    ...     ...     ...    ...    ...   \n",
       "214                 Yu Hsiou Hsu   5.0    2.0     5.0     3.0    8.0   59.0   \n",
       "215                Yuichi Sugita  10.0    3.0    11.0    12.0   22.0   62.0   \n",
       "216               Zachary Svajda  14.0    4.0    15.0    14.0   25.0   86.0   \n",
       "217                 Zdenek Kolar   4.0    3.0     1.0     3.0    2.0    7.0   \n",
       "218                Zhizhen Zhang  21.0   16.0    39.0    20.0   58.0  135.0   \n",
       "\n",
       "     NCTL_B  NCTL_BC  NCTL_BW  ...        7_%        8_%        9_%  \\\n",
       "0     116.0    276.0    316.0  ...  53.403141  34.146341  53.061224   \n",
       "1      13.0     20.0     30.0  ...        NaN        NaN        NaN   \n",
       "2     292.0    359.0    301.0  ...  50.471698  54.545455  53.968254   \n",
       "3      37.0     71.0     91.0  ...        NaN        NaN        NaN   \n",
       "4      18.0     19.0     25.0  ...        NaN        NaN        NaN   \n",
       "..      ...      ...      ...  ...        ...        ...        ...   \n",
       "214    11.0     23.0     42.0  ...  73.333333  64.285714  46.153846   \n",
       "215    17.0     38.0     66.0  ...        NaN        NaN        NaN   \n",
       "216    84.0     79.0    126.0  ...  55.555556  41.666667  56.521739   \n",
       "217    16.0     17.0     16.0  ...        NaN        NaN        NaN   \n",
       "218    71.0    144.0    145.0  ...  43.589744  61.111111  31.250000   \n",
       "\n",
       "          10_%       11_%       12_%       13_%       14_%      15+_%  \\\n",
       "0    40.277778  49.295775  39.024390  69.565217  38.095238  42.335766   \n",
       "1          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2    59.782609  60.714286  66.071429  47.500000  54.545455  47.872340   \n",
       "3          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "214  62.500000  42.857143  50.000000  33.333333  25.000000  53.333333   \n",
       "215        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "216  42.857143  77.777778  46.153846  71.428571  60.000000  48.275862   \n",
       "217        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "218  47.619048  71.428571  50.000000  28.571429  20.000000  50.000000   \n",
       "\n",
       "     total_deficit  \n",
       "0            -59.0  \n",
       "1             23.0  \n",
       "2             69.0  \n",
       "3             13.0  \n",
       "4            -14.0  \n",
       "..             ...  \n",
       "214            9.0  \n",
       "215         -104.0  \n",
       "216          -34.0  \n",
       "217          -28.0  \n",
       "218          -19.0  \n",
       "\n",
       "[219 rows x 63 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Calculate total deficits by player across both `player1` and `player2`\n",
    "# Aggregate P1Deficit for player1 and P2Deficit for player2, then combine them\n",
    "player1_deficit = deficit.groupby('player1')['P1Deficit'].sum().rename('total_deficit')\n",
    "player2_deficit = deficit.groupby('player2')['P2Deficit'].sum().rename('total_deficit')\n",
    "\n",
    "# Combine the deficits from both player1 and player2 perspectives\n",
    "combined_deficit = player1_deficit.add(player2_deficit, fill_value=0).reset_index()\n",
    "combined_deficit = combined_deficit.rename(columns={'index': 'player_name'})\n",
    "\n",
    "# Step 2: Merge the combined deficit data into the player_stats dataset\n",
    "# Ensure player_name column in player_stats if it was an index\n",
    "player_stats = player_stats.reset_index() if 'player_name' not in player_stats.columns else player_stats\n",
    "\n",
    "# Merge the combined deficit data on player_name\n",
    "player_stats = player_stats.merge(combined_deficit, on='player_name', how='left')\n",
    "\n",
    "# Fill any NaN values with 0 (in case some players have no deficit data)\n",
    "player_stats['total_deficit'] = player_stats['total_deficit'].fillna(0)\n",
    "\n",
    "# Confirm the new total_deficit column in player_stats\n",
    "player_stats\n",
    "\n",
    "#principal components analysis\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2588a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>0_0</th>\n",
       "      <th>CTL_B</th>\n",
       "      <th>CTL_BC</th>\n",
       "      <th>CTL_BW</th>\n",
       "      <th>CTL_C</th>\n",
       "      <th>CTL_W</th>\n",
       "      <th>NCTL_B</th>\n",
       "      <th>NCTL_BC</th>\n",
       "      <th>NCTL_BW</th>\n",
       "      <th>...</th>\n",
       "      <th>8_%</th>\n",
       "      <th>9_%</th>\n",
       "      <th>10_%</th>\n",
       "      <th>11_%</th>\n",
       "      <th>12_%</th>\n",
       "      <th>13_%</th>\n",
       "      <th>14_%</th>\n",
       "      <th>15+_%</th>\n",
       "      <th>total_deficit</th>\n",
       "      <th>avg_deficit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.146341</td>\n",
       "      <td>53.061224</td>\n",
       "      <td>40.277778</td>\n",
       "      <td>49.295775</td>\n",
       "      <td>39.024390</td>\n",
       "      <td>69.565217</td>\n",
       "      <td>38.095238</td>\n",
       "      <td>42.335766</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-1.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alastair Gray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>53.968254</td>\n",
       "      <td>59.782609</td>\n",
       "      <td>60.714286</td>\n",
       "      <td>66.071429</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>47.872340</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alejandro Tabilo</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aleksandar Vukic</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Yu Hsiou Hsu</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Yuichi Sugita</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Zachary Svajda</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>56.521739</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>48.275862</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Zdenek Kolar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Zhizhen Zhang</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>47.619048</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-1.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows  64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     player_name   0_0  CTL_B  CTL_BC  CTL_BW  CTL_C  CTL_W  \\\n",
       "0               Adrian Mannarino  45.0   27.0    50.0    27.0   87.0  315.0   \n",
       "1                  Alastair Gray   4.0    0.0     1.0     3.0    5.0   14.0   \n",
       "2    Alejandro Davidovich Fokina  74.0   62.0    96.0    65.0   82.0  246.0   \n",
       "3               Alejandro Tabilo  28.0    8.0    28.0    20.0   29.0  106.0   \n",
       "4               Aleksandar Vukic   6.0    3.0     7.0     2.0   14.0   38.0   \n",
       "..                           ...   ...    ...     ...     ...    ...    ...   \n",
       "214                 Yu Hsiou Hsu   5.0    2.0     5.0     3.0    8.0   59.0   \n",
       "215                Yuichi Sugita  10.0    3.0    11.0    12.0   22.0   62.0   \n",
       "216               Zachary Svajda  14.0    4.0    15.0    14.0   25.0   86.0   \n",
       "217                 Zdenek Kolar   4.0    3.0     1.0     3.0    2.0    7.0   \n",
       "218                Zhizhen Zhang  21.0   16.0    39.0    20.0   58.0  135.0   \n",
       "\n",
       "     NCTL_B  NCTL_BC  NCTL_BW  ...        8_%        9_%       10_%  \\\n",
       "0     116.0    276.0    316.0  ...  34.146341  53.061224  40.277778   \n",
       "1      13.0     20.0     30.0  ...        NaN        NaN        NaN   \n",
       "2     292.0    359.0    301.0  ...  54.545455  53.968254  59.782609   \n",
       "3      37.0     71.0     91.0  ...        NaN        NaN        NaN   \n",
       "4      18.0     19.0     25.0  ...        NaN        NaN        NaN   \n",
       "..      ...      ...      ...  ...        ...        ...        ...   \n",
       "214    11.0     23.0     42.0  ...  64.285714  46.153846  62.500000   \n",
       "215    17.0     38.0     66.0  ...        NaN        NaN        NaN   \n",
       "216    84.0     79.0    126.0  ...  41.666667  56.521739  42.857143   \n",
       "217    16.0     17.0     16.0  ...        NaN        NaN        NaN   \n",
       "218    71.0    144.0    145.0  ...  61.111111  31.250000  47.619048   \n",
       "\n",
       "          11_%       12_%       13_%       14_%      15+_%  total_deficit  \\\n",
       "0    49.295775  39.024390  69.565217  38.095238  42.335766          -59.0   \n",
       "1          NaN        NaN        NaN        NaN        NaN           23.0   \n",
       "2    60.714286  66.071429  47.500000  54.545455  47.872340           69.0   \n",
       "3          NaN        NaN        NaN        NaN        NaN           13.0   \n",
       "4          NaN        NaN        NaN        NaN        NaN          -14.0   \n",
       "..         ...        ...        ...        ...        ...            ...   \n",
       "214  42.857143  50.000000  33.333333  25.000000  53.333333            9.0   \n",
       "215        NaN        NaN        NaN        NaN        NaN         -104.0   \n",
       "216  77.777778  46.153846  71.428571  60.000000  48.275862          -34.0   \n",
       "217        NaN        NaN        NaN        NaN        NaN          -28.0   \n",
       "218  71.428571  50.000000  28.571429  20.000000  50.000000          -19.0   \n",
       "\n",
       "     avg_deficit  \n",
       "0      -1.787879  \n",
       "1      11.500000  \n",
       "2       1.916667  \n",
       "3       1.857143  \n",
       "4      -1.750000  \n",
       "..           ...  \n",
       "214     3.000000  \n",
       "215   -13.000000  \n",
       "216    -8.500000  \n",
       "217    -9.333333  \n",
       "218    -1.900000  \n",
       "\n",
       "[219 rows x 64 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_stats['avg_deficit'] = player_stats['total_deficit'] / player_stats['match_played']\n",
    "\n",
    "player_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98ddeca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats['elite_numeric'] = player_stats['rank_elite'].map({'E': 1, 'NE': 0})\n",
    "player_stats.drop(columns=['rank_elite'], inplace=True)\n",
    "\n",
    "# # Calculate median of avg_deficit\n",
    "# threshold = player_stats['avg_deficit'].median()\n",
    "\n",
    "# # Create binary target based on threshold (1 if above median, 0 if below or equal)\n",
    "# player_stats['avg_deficit_binary'] = (player_stats['avg_deficit'] > threshold).astype(int)\n",
    "\n",
    "# # Re-define y and X using the binary target\n",
    "# filtered_data = player_stats[['avg_deficit_binary', 'elite_numeric', 'Avg_1st_ServeSpeed']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# y = filtered_data['avg_deficit_binary']\n",
    "# X = filtered_data[['elite_numeric', 'Avg_1st_ServeSpeed']]\n",
    "# X['elite_serve_interaction'] = X['elite_numeric'] * X['Avg_1st_ServeSpeed']\n",
    "\n",
    "# # Add constant\n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "# # Fit logistic regression\n",
    "# logit_model = sm.Logit(y, X)\n",
    "# result = logit_model.fit()\n",
    "\n",
    "# # Display results\n",
    "# print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa87e1b",
   "metadata": {},
   "source": [
    "## Regression Model Interpretation\n",
    "The regression suggests that the number of 1st Serve In or 1st Serve Won has limited impact to the change in average deficit of the matches, while the fact a player is an elite or non-elite played a significant impact, as if one is an elite, they may earn more than 10 points compared to non-elite counterparts on average. Regarding the factor 1st Serve In multiplies with 1st Serve Won, it has little to no relationship with average deficit points per match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51df70d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2911383967.py:14: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatterplot with linear regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='winner_rank_points', y='loser_rank_points', data=gs, scatter_kws={'s': 5}, line_kws={'color': 'red'})\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Winner Rank Points')\n",
    "plt.ylabel('Loser Rank Points')\n",
    "plt.title('Scatterplot with Linear Regression: Winner vs Loser Rank Points')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277da4a",
   "metadata": {},
   "source": [
    "## Linear Regression Model Interpretation\n",
    "\n",
    "The linear regression suggests that the majority of data points is located below median of both variables, which means most matches are played between players with points below median.There is a wide spread of loser rank points for any given winner rank point, indicating variability in the rank points of losers. Some matches involve losers with very high rank points, which are outliers compared to the general trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd0156ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/3369738171.py:11: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Scatterplot with linear regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='winner_age', y='loser_age', data=gs, scatter_kws={'s': 5}, line_kws={'color': 'red'})\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Winner Age')\n",
    "plt.ylabel('Loser Age')\n",
    "plt.title('Scatterplot with Linear Regression: Winner vs Loser Age')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4b3fbc",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "It suggests that the difference in ranking points has little to no relationship in determining the winner or loser of a Grand Slam match, and the same argument applies to the age differences. \n",
    "\n",
    "P/S:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36da503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming player_stats has already been defined with Forehand_Winners, Backhand_Winners, and match_played\n",
    "\n",
    "# Create avg_Forehand and avg_Backhand columns\n",
    "player_stats['avg_Forehand'] = player_stats['Forehand_Winners'] / player_stats['match_played']\n",
    "player_stats['avg_Backhand'] = player_stats['Backhand_Winners'] / player_stats['match_played']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0280659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.093768\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          elite_numeric   No. Observations:                  219\n",
      "Model:                          Logit   Df Residuals:                      216\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 25 Dec 2024   Pseudo R-squ.:                  0.5585\n",
      "Time:                        00:02:09   Log-Likelihood:                -20.535\n",
      "converged:                       True   LL-Null:                       -46.515\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.213e-12\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               -6.9560      1.193     -5.831      0.000      -9.294      -4.618\n",
      "Forehand_Winners     0.0125      0.004      2.799      0.005       0.004       0.021\n",
      "Backhand_Winners    -0.0116      0.009     -1.248      0.212      -0.030       0.007\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Prepare the data by removing any rows with NaN in avg_Forehand or avg_Backhand\n",
    "regression_data = player_stats[['elite_numeric', 'Forehand_Winners', 'Backhand_Winners']].dropna()\n",
    "\n",
    "# Set up the independent variables (with constant for intercept) and dependent variable\n",
    "X = regression_data[['Forehand_Winners', 'Backhand_Winners']]\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "y = regression_data['elite_numeric']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y, X)\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "# Display the results\n",
    "print(logit_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7e8f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant columns that should be removed: Index([], dtype='object')\n",
      "Correlation matrix:\n",
      "                    Avg_1st_ServeSpeed  Avg_2nd_ServeSpeed  match_played  \\\n",
      "Avg_1st_ServeSpeed            1.000000            0.672441      0.211292   \n",
      "Avg_2nd_ServeSpeed            0.672441            1.000000      0.093584   \n",
      "match_played                  0.211292            0.093584      1.000000   \n",
      "height                        0.514284            0.420506      0.142018   \n",
      "ace                           0.474768            0.333392      0.811198   \n",
      "df                            0.283370            0.211695      0.847447   \n",
      "svpt                          0.219453            0.100356      0.993222   \n",
      "1stIn                         0.207969            0.098886      0.991897   \n",
      "1stWon                        0.249187            0.131118      0.991736   \n",
      "2ndWon                        0.234982            0.106777      0.980677   \n",
      "rank                          0.029735            0.043498      0.146174   \n",
      "rank_points                   0.168792            0.080422      0.790792   \n",
      "ND_per_match                 -0.103989           -0.225949     -0.225600   \n",
      "D_per_match                  -0.081771           -0.197569     -0.219152   \n",
      "1stIn_per_match              -0.091588           -0.001617     -0.094281   \n",
      "1stWon_per_match              0.209879            0.251574      0.070672   \n",
      "2ndWon_per_match              0.269896            0.131096      0.012723   \n",
      "bpSaved_per_match            -0.310041           -0.282612     -0.308482   \n",
      "bpFaced_per_match            -0.434948           -0.382549     -0.401582   \n",
      "avg_deficit                   0.292843            0.186895      0.600528   \n",
      "avg_Forehand                 -0.129427           -0.208711     -0.240365   \n",
      "avg_Backhand                 -0.105302           -0.149776     -0.205265   \n",
      "elite_numeric                 0.181850            0.094398      0.618274   \n",
      "\n",
      "                      height       ace        df      svpt     1stIn  \\\n",
      "Avg_1st_ServeSpeed  0.514284  0.474768  0.283370  0.219453  0.207969   \n",
      "Avg_2nd_ServeSpeed  0.420506  0.333392  0.211695  0.100356  0.098886   \n",
      "match_played        0.142018  0.811198  0.847447  0.993222  0.991897   \n",
      "height              1.000000  0.505074  0.242935  0.157058  0.156514   \n",
      "ace                 0.505074  1.000000  0.790784  0.821254  0.815769   \n",
      "df                  0.242935  0.790784  1.000000  0.859421  0.845965   \n",
      "svpt                0.157058  0.821254  0.859421  1.000000  0.996350   \n",
      "1stIn               0.156514  0.815769  0.845965  0.996350  1.000000   \n",
      "1stWon              0.202079  0.854735  0.854811  0.994086  0.996324   \n",
      "2ndWon              0.146554  0.810854  0.839898  0.987404  0.972594   \n",
      "rank               -0.041146  0.098646  0.174198  0.187381  0.177412   \n",
      "rank_points         0.114729  0.634502  0.616679  0.737925  0.749069   \n",
      "ND_per_match        0.029985 -0.155552 -0.207624 -0.224364 -0.221544   \n",
      "D_per_match         0.019744 -0.148360 -0.202462 -0.216462 -0.213049   \n",
      "1stIn_per_match     0.077855 -0.033031 -0.077033 -0.041358 -0.013108   \n",
      "1stWon_per_match    0.365226  0.289210  0.124742  0.122407  0.139359   \n",
      "2ndWon_per_match    0.059483  0.086623  0.084745  0.060898  0.016028   \n",
      "bpSaved_per_match  -0.296561 -0.393197 -0.247394 -0.279641 -0.283765   \n",
      "bpFaced_per_match  -0.406317 -0.538617 -0.324298 -0.376440 -0.379546   \n",
      "avg_deficit         0.169448  0.551007  0.503019  0.605114  0.601412   \n",
      "avg_Forehand        0.003286 -0.154374 -0.217080 -0.242228 -0.240132   \n",
      "avg_Backhand        0.028447 -0.132186 -0.154768 -0.203890 -0.203408   \n",
      "elite_numeric       0.106943  0.543294  0.469433  0.581675  0.592986   \n",
      "\n",
      "                      1stWon    2ndWon  ...  D_per_match  1stIn_per_match  \\\n",
      "Avg_1st_ServeSpeed  0.249187  0.234982  ...    -0.081771        -0.091588   \n",
      "Avg_2nd_ServeSpeed  0.131118  0.106777  ...    -0.197569        -0.001617   \n",
      "match_played        0.991736  0.980677  ...    -0.219152        -0.094281   \n",
      "height              0.202079  0.146554  ...     0.019744         0.077855   \n",
      "ace                 0.854735  0.810854  ...    -0.148360        -0.033031   \n",
      "df                  0.854811  0.839898  ...    -0.202462        -0.077033   \n",
      "svpt                0.994086  0.987404  ...    -0.216462        -0.041358   \n",
      "1stIn               0.996324  0.972594  ...    -0.213049        -0.013108   \n",
      "1stWon              1.000000  0.974070  ...    -0.200173        -0.025731   \n",
      "2ndWon              0.974070  1.000000  ...    -0.207429        -0.091907   \n",
      "rank                0.150047  0.168728  ...    -0.127028         0.123497   \n",
      "rank_points         0.771332  0.731943  ...    -0.091471        -0.138561   \n",
      "ND_per_match       -0.208741 -0.214834  ...     0.969245         0.285976   \n",
      "D_per_match        -0.200173 -0.207429  ...     1.000000         0.310664   \n",
      "1stIn_per_match    -0.025731 -0.091907  ...     0.310664         1.000000   \n",
      "1stWon_per_match    0.158037  0.091122  ...     0.306184         0.865358   \n",
      "2ndWon_per_match    0.027403  0.146194  ...     0.178704         0.243194   \n",
      "bpSaved_per_match  -0.313850 -0.288906  ...     0.054306         0.393549   \n",
      "bpFaced_per_match  -0.420151 -0.392177  ...     0.010730         0.320969   \n",
      "avg_deficit         0.611820  0.612094  ...     0.097785         0.102746   \n",
      "avg_Forehand       -0.223455 -0.228497  ...     0.828189         0.258404   \n",
      "avg_Backhand       -0.191641 -0.195203  ...     0.759645         0.275055   \n",
      "elite_numeric       0.616854  0.579951  ...    -0.059371        -0.111697   \n",
      "\n",
      "                    1stWon_per_match  2ndWon_per_match  bpSaved_per_match  \\\n",
      "Avg_1st_ServeSpeed          0.209879          0.269896          -0.310041   \n",
      "Avg_2nd_ServeSpeed          0.251574          0.131096          -0.282612   \n",
      "match_played                0.070672          0.012723          -0.308482   \n",
      "height                      0.365226          0.059483          -0.296561   \n",
      "ace                         0.289210          0.086623          -0.393197   \n",
      "df                          0.124742          0.084745          -0.247394   \n",
      "svpt                        0.122407          0.060898          -0.279641   \n",
      "1stIn                       0.139359          0.016028          -0.283765   \n",
      "1stWon                      0.158037          0.027403          -0.313850   \n",
      "2ndWon                      0.091122          0.146194          -0.288906   \n",
      "rank                        0.109611          0.115568           0.108043   \n",
      "rank_points                 0.006651         -0.065838          -0.303442   \n",
      "ND_per_match                0.278939          0.148750           0.049188   \n",
      "D_per_match                 0.306184          0.178704           0.054306   \n",
      "1stIn_per_match             0.865358          0.243194           0.393549   \n",
      "1stWon_per_match            1.000000          0.367085           0.072856   \n",
      "2ndWon_per_match            0.367085          1.000000           0.122794   \n",
      "bpSaved_per_match           0.072856          0.122794           1.000000   \n",
      "bpFaced_per_match          -0.079133          0.029673           0.925260   \n",
      "avg_deficit                 0.307564          0.177187          -0.340534   \n",
      "avg_Forehand                0.279488          0.144554          -0.020149   \n",
      "avg_Backhand                0.271470          0.159830           0.023925   \n",
      "elite_numeric               0.025347         -0.053218          -0.288330   \n",
      "\n",
      "                    bpFaced_per_match  avg_deficit  avg_Forehand  \\\n",
      "Avg_1st_ServeSpeed          -0.434948     0.292843     -0.129427   \n",
      "Avg_2nd_ServeSpeed          -0.382549     0.186895     -0.208711   \n",
      "match_played                -0.401582     0.600528     -0.240365   \n",
      "height                      -0.406317     0.169448      0.003286   \n",
      "ace                         -0.538617     0.551007     -0.154374   \n",
      "df                          -0.324298     0.503019     -0.217080   \n",
      "svpt                        -0.376440     0.605114     -0.242228   \n",
      "1stIn                       -0.379546     0.601412     -0.240132   \n",
      "1stWon                      -0.420151     0.611820     -0.223455   \n",
      "2ndWon                      -0.392177     0.612094     -0.228497   \n",
      "rank                         0.096881     0.128845     -0.120788   \n",
      "rank_points                 -0.381426     0.452161     -0.094983   \n",
      "ND_per_match                 0.011988     0.059973      0.881957   \n",
      "D_per_match                  0.010730     0.097785      0.828189   \n",
      "1stIn_per_match              0.320969     0.102746      0.258404   \n",
      "1stWon_per_match            -0.079133     0.307564      0.279488   \n",
      "2ndWon_per_match             0.029673     0.177187      0.144554   \n",
      "bpSaved_per_match            0.925260    -0.340534     -0.020149   \n",
      "bpFaced_per_match            1.000000    -0.487129     -0.024812   \n",
      "avg_deficit                 -0.487129     1.000000     -0.020801   \n",
      "avg_Forehand                -0.024812    -0.020801      1.000000   \n",
      "avg_Backhand                 0.029263    -0.051138      0.887636   \n",
      "elite_numeric               -0.361932     0.374097     -0.041339   \n",
      "\n",
      "                    avg_Backhand  elite_numeric  \n",
      "Avg_1st_ServeSpeed     -0.105302       0.181850  \n",
      "Avg_2nd_ServeSpeed     -0.149776       0.094398  \n",
      "match_played           -0.205265       0.618274  \n",
      "height                  0.028447       0.106943  \n",
      "ace                    -0.132186       0.543294  \n",
      "df                     -0.154768       0.469433  \n",
      "svpt                   -0.203890       0.581675  \n",
      "1stIn                  -0.203408       0.592986  \n",
      "1stWon                 -0.191641       0.616854  \n",
      "2ndWon                 -0.195203       0.579951  \n",
      "rank                   -0.102927      -0.250472  \n",
      "rank_points            -0.085819       0.771509  \n",
      "ND_per_match            0.811960      -0.062300  \n",
      "D_per_match             0.759645      -0.059371  \n",
      "1stIn_per_match         0.275055      -0.111697  \n",
      "1stWon_per_match        0.271470       0.025347  \n",
      "2ndWon_per_match        0.159830      -0.053218  \n",
      "bpSaved_per_match       0.023925      -0.288330  \n",
      "bpFaced_per_match       0.029263      -0.361932  \n",
      "avg_deficit            -0.051138       0.374097  \n",
      "avg_Forehand            0.887636      -0.041339  \n",
      "avg_Backhand            1.000000      -0.067731  \n",
      "elite_numeric          -0.067731       1.000000  \n",
      "\n",
      "[23 rows x 23 columns]\n",
      "Dropping highly correlated columns: {'1stWon', '1stIn', '2ndWon', 'svpt', 'bpFaced_per_match', 'D_per_match'}\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for elite_numeric, dropping NaN values for specific columns\n",
    "regression_data_elite = player_stats.dropna(subset=[\n",
    "    'Avg_1st_ServeSpeed', 'Avg_2nd_ServeSpeed', 'match_played',\n",
    "    'height', 'ace', 'df', 'svpt', 'rank',\n",
    "    'rank_points', 'ND_per_match', 'D_per_match', '1stIn_per_match',\n",
    "    '1stWon_per_match', '2ndWon_per_match', 'bpSaved_per_match',\n",
    "    'bpFaced_per_match', 'avg_deficit',\n",
    " 'avg_Forehand', 'avg_Backhand', 'elite_numeric', \n",
    "])\n",
    "\n",
    "# Check for constant variables\n",
    "constant_columns = regression_data_elite.columns[\n",
    "    regression_data_elite.nunique() <= 1\n",
    "]\n",
    "print(\"Constant columns that should be removed:\", constant_columns)\n",
    "\n",
    "# Remove constant variables\n",
    "X_elite = regression_data_elite.drop(columns=constant_columns)[[\n",
    "    'Avg_1st_ServeSpeed', 'Avg_2nd_ServeSpeed', 'match_played',\n",
    "    'height', 'ace', 'df', 'svpt',\n",
    "    '1stIn', '1stWon', '2ndWon', 'rank',\n",
    "    'rank_points', 'ND_per_match', 'D_per_match', '1stIn_per_match',\n",
    "    '1stWon_per_match', '2ndWon_per_match', 'bpSaved_per_match',\n",
    "    'bpFaced_per_match', 'avg_deficit',\n",
    "     'avg_Forehand', 'avg_Backhand', 'elite_numeric'\n",
    "]]\n",
    "\n",
    "# Check for multicollinearity\n",
    "correlation_matrix = X_elite.corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Identify and drop highly correlated variables\n",
    "threshold = 0.9  # Set a threshold for high correlation\n",
    "to_drop = set()\n",
    "\n",
    "# Loop through the correlation matrix\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:  # If the correlation is high\n",
    "            colname = correlation_matrix.columns[i]  # Get the column name\n",
    "            to_drop.add(colname)  # Mark for dropping\n",
    "\n",
    "print(\"Dropping highly correlated columns:\", to_drop)\n",
    "X_elite = X_elite.drop(columns=to_drop)\n",
    "\n",
    "# Add intercept\n",
    "X_elite = sm.add_constant(X_elite)\n",
    "y_elite = regression_data_elite['avg_deficit']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45a88931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1.787879\n",
       "1      11.500000\n",
       "2       1.916667\n",
       "3       1.857143\n",
       "4      -1.750000\n",
       "         ...    \n",
       "214     3.000000\n",
       "215   -13.000000\n",
       "216    -8.500000\n",
       "217    -9.333333\n",
       "218    -1.900000\n",
       "Name: avg_deficit, Length: 219, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_stats['avg_deficit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb5e3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2910408435.py:8: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(X_elite.corr(), dtype=bool))\n",
    "sns.heatmap(X_elite.corr(), mask=mask, annot=True, fmt=\".2f\", cmap=\"coolwarm\", \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .8}, linecolor='black')\n",
    "\n",
    "plt.title('Correlation Heatmap with Rectangles')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad0274",
   "metadata": {},
   "source": [
    "## Key Observations:\n",
    "Avg_1st_ServeSpeed and Avg_2nd_ServeSpeed have a moderate positive correlation (0.70). As the average speed of a player's first serve increases, the average speed of their second serve also tends to increase. \n",
    " player fixed effect. for a specific person, difference of 1st and 2nd serve. (slow server and fast server), same correlation \n",
    "\n",
    "Ace and df (double faults) have a strong positive correlation (0.78), suggesting players who serve more aces also tend to have more double faults.\n",
    "\n",
    "Rank and rank_points have a moderate negative correlation (-0.26), indicating that higher-ranked players tend to have more rank points.\n",
    "\n",
    "Avg_Backhand and Avg_Forehand also have a moderate positive correlation, suggesting that players with good forehand tends to also have a good backhand and vice versa, thus produce more winners o\n",
    "\n",
    "Match_played and rank_points have strong positive correlation (0.71), indicating that the more matches a player plays in a Grand Slam, the more likely they have higher ranking points. It is true in most cases, considering elite players or great players will play more matches than others, which help them accumulate more ranking points than the others.\n",
    "\n",
    "Breakpoint saved per match and 1st In per match have the strongest positive correlation (0.88), suggesting that the better the first serve is, the more break points players can save. It is a solid case, as in a tennis game, players always rely on their serves to perform well in their service games.\n",
    "\n",
    "Elite_numeric and ranking points have strong positive correlation (0.77) as the elite players are mostly top players who earn higher ranking points that others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07e697aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/351733501.py:20: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  plt.subplot(rows, 4, i + 1)\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/351733501.py:26: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# New list of dimensions for histograms\n",
    "dimensions = [\n",
    "    '0_0', 'CTL_B', 'CTL_BC', 'CTL_BW', 'CTL_C', 'CTL_W',\n",
    "    'NCTL_B', 'NCTL_BC', 'NCTL_BW', 'NCTL_C', 'NCTL_W', '0', 'D', 'M', 'ND',\n",
    "    'Avg_1st_ServeSpeed', 'Avg_2nd_ServeSpeed', 'match_played',\n",
    "    'height', 'ace', 'df', 'svpt', 'rank',\n",
    "    'rank_points', 'ND_per_match', 'D_per_match', '1stIn_per_match',\n",
    "    '1stWon_per_match', '2ndWon_per_match', 'bpSaved_per_match',\n",
    "    'bpFaced_per_match', 'avg_deficit',\n",
    "    'avg_Forehand', 'avg_Backhand'\n",
    "]\n",
    "\n",
    "plt.figure(1, figsize=(30, 18))\n",
    "\n",
    "# Adjust the number of subplots based on the number of dimensions\n",
    "num_dimensions = len(dimensions)\n",
    "rows = num_dimensions // 4 + (num_dimensions % 4 > 0)  # Calculate number of rows needed\n",
    "\n",
    "for i in range(num_dimensions):\n",
    "    plt.subplot(rows, 4, i + 1)\n",
    "    player_stats[dimensions[i]].plot(kind='hist', title=dimensions[i], bins=30, edgecolor='black')\n",
    "    plt.xlabel(dimensions[i])  # Add x-label for clarity\n",
    "    plt.ylabel('Frequency')  # Add y-label for clarity\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d3047",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37abf9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Excel\n",
    "#player_stats.to_excel('player_stats.xlsx', index=False, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65916f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats['Deep_Return%'] = player_stats['D']*100/(player_stats['D']+player_stats['ND'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ca73ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages\n",
    "player_stats['avg_ace'] = player_stats['ace'] / player_stats['match_played']\n",
    "player_stats['avg_df'] = player_stats['df'] / player_stats['match_played']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486aa63",
   "metadata": {},
   "source": [
    "## Analyze the Serve/Return patterns of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53017f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your original dataset is called df\n",
    "selected_columns = [\n",
    "    'match_id','SetNo', 'P1GamesWon', 'P2GamesWon', 'SetWinner', 'GameNo', 'GameWinner',\n",
    "    'PointNumber', 'PointWinner', 'PointServer', 'Speed_KMH', 'P1Score',\n",
    "    'P2Score', 'P1Ace', 'P2Ace', 'P1DoubleFault', 'P2DoubleFault',\n",
    "    'ServeWidth', 'ServeDepth', 'DoubleFault', 'ReturnDepth', 'player1', 'player2', 'P1BreakPoint', 'P2BreakPoint'\n",
    "    ,'P1BreakPointWon', 'P2BreakPointWon'\n",
    "]\n",
    "\n",
    "# Creating a new DataFrame with the selected columns\n",
    "pat = wimus[selected_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "676c96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pat.copy()\n",
    "\n",
    "# Calculate Score column based on PointServer\n",
    "pat['ScoreConcat'] = pat.apply(\n",
    "    lambda row: f\"{row['P1Score']}-{row['P2Score']}\" if row['PointServer'] == 1 \n",
    "                else f\"{row['P2Score']}-{row['P1Score']}\", axis=1\n",
    ")\n",
    "\n",
    "# Calculate Games column based on PointServer\n",
    "pat['GameConcat'] = pat.apply(\n",
    "    lambda row: f\"{row['P1GamesWon']}-{row['P2GamesWon']}\" if row['PointServer'] == 1 \n",
    "                else f\"{row['P2GamesWon']}-{row['P1GamesWon']}\", axis=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c48f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the ScoreConcat and GameConcat columns by 1 to assign previous row values\n",
    "pat['Score'] = pat['ScoreConcat'].shift(1)\n",
    "pat['Games'] = pat['GameConcat'].shift(1) if 'GameConcat' in pat.columns else None\n",
    "\n",
    "# Handle rows where PointNumber starts with \"0X\"\n",
    "# Assuming PointNumber is stored as a string\n",
    "pat.loc[pat['PointNumber'].astype(str).str.startswith('0X'), ['Score', 'Games']] = pat.loc[\n",
    "    pat['PointNumber'].astype(str).str.startswith('0X'), ['ScoreConcat', 'GameConcat']\n",
    "].values\n",
    "\n",
    "# Copy values from the previous row for the last row in Score and Game\n",
    "pat.iloc[-1, pat.columns.get_loc('Score')] = pat.iloc[-2]['ScoreConcat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5647a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create player1_e and player2_e columns\n",
    "top_players = [\n",
    "    'Alexander Zverev', 'Andrey Rublev', 'Carlos Alcaraz', 'Casper Ruud',\n",
    "    'Daniil Medvedev', 'Dominic Thiem', 'Felix Auger Aliassime',\n",
    "    'Matteo Berrettini', 'Novak Djokovic', 'Rafael Nadal',\n",
    "    'Roger Federer', 'Stefanos Tsitsipas', 'Taylor Fritz', 'Jannik Sinner'\n",
    "]\n",
    "\n",
    "pat['player1_e'] = pat['player1'].apply(lambda x: 1 if x in top_players else 0)\n",
    "pat['player2_e'] = pat['player2'].apply(lambda x: 1 if x in top_players else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "597c0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/4211171549.py:32: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtering data based on the conditions\n",
    "filtered_pat = pat[\n",
    "    ((pat['player1_e'] == 1) & (pat['PointServer'] == 1) & (pat['P2BreakPoint'] == 1)) |\n",
    "    ((pat['player2_e'] == 1) & (pat['PointServer'] == 2) & (pat['P1BreakPoint'] == 1))\n",
    "]\n",
    "filtered_pat1 = pat[\n",
    "    ((pat['player1_e'] == 1) & (pat['PointServer'] == 1) & (pat['P2BreakPoint'] == 0)) |\n",
    "    ((pat['player2_e'] == 1) & (pat['PointServer'] == 2) & (pat['P1BreakPoint'] == 0))\n",
    "]\n",
    "\n",
    "# Plotting ServeDepth and ServeWidth distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ServeDepth distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(filtered_pat['ServeDepth'], kde=True, bins=10, color='blue')\n",
    "plt.title('ServeDepth Distribution of an Elite Player facing break points')\n",
    "plt.xlabel('ServeDepth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# ServeWidth distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(filtered_pat1['ServeDepth'], kde=True, bins=10, color='green')\n",
    "plt.title('ServeWidth Distribution of an Elite Player facing break points')\n",
    "plt.xlabel('ServeDepth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ceb2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/3672457725.py:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ServeWidth distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(filtered_pat['ServeWidth'], kde=True, bins=10, color='green')\n",
    "plt.title('ServeWidth Distribution of an Elite Player facing break points')\n",
    "plt.xlabel('ServeWidth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(filtered_pat1['ServeWidth'], kde=True, bins=20, color='green')\n",
    "plt.title('ServeWidth Distribution of an Elite Player on serve and play normal points')\n",
    "plt.xlabel('ServeWidth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72f42c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/931930615.py:33: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtering data based on the conditions\n",
    "filtered_pat2 = pat[\n",
    "    ((pat['player1_e'] == 0) & (pat['PointServer'] == 1) & (pat['P2BreakPoint'] == 1)) |\n",
    "    ((pat['player2_e'] == 0) & (pat['PointServer'] == 2) & (pat['P1BreakPoint'] == 1))\n",
    "]\n",
    "\n",
    "filtered_pat3 = pat[\n",
    "    ((pat['player1_e'] == 0) & (pat['PointServer'] == 1) & (pat['P2BreakPoint'] == 0)) |\n",
    "    ((pat['player2_e'] == 0) & (pat['PointServer'] == 2) & (pat['P1BreakPoint'] == 0))\n",
    "]\n",
    "\n",
    "\n",
    "# Plotting ServeDepth and ServeWidth distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ServeDepth distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(filtered_pat2['ServeDepth'], kde=True, bins=10, color='blue')\n",
    "plt.title('ServeDepth Distribution of an Non-Elite Player facing break points')\n",
    "plt.xlabel('ServeDepth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(filtered_pat3['ServeDepth'], kde=True, bins=10, color='green')\n",
    "plt.title('ServeDepth Distribution of an Non-Elite Player on serve and play normal points')\n",
    "plt.xlabel('ServeWidth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4bb0f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/342655082.py:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ServeWidth distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(filtered_pat2['ServeWidth'], kde=True, bins=10, color='green')\n",
    "plt.title('ServeWidth Distribution of an Elite Player facing break points')\n",
    "plt.xlabel('ServeWidth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(filtered_pat3['ServeWidth'], kde=True, bins=20, color='green')\n",
    "plt.title('ServeWidth Distribution of an Elite Player on serve and play normal points')\n",
    "plt.xlabel('ServeWidth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b449f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/2245389648.py:29: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtering data based on the conditions\n",
    "filtered_pat = pat[\n",
    "    ((pat['player1_e'] == 1) & (pat['PointServer'] == 2) & (pat['P1BreakPointWon'] == 1)) |\n",
    "    ((pat['player2_e'] == 1) & (pat['PointServer'] == 1) & (pat['P2BreakPointWon'] == 0))\n",
    "]\n",
    "\n",
    "\n",
    "# Plotting ServeDepth and ServeWidth distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ReturnDepth distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(filtered_pat['ReturnDepth'], kde=True, bins=10, color='blue')\n",
    "plt.title('ReturnDepth Distribution')\n",
    "plt.xlabel('ReturnDepth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# ServeWidth distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(filtered_pat1['ReturnDepth'], kde=True, bins=10, color='red')\n",
    "plt.title('ReturnDepth Distribution')\n",
    "plt.xlabel('ServeWidth')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ced7c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1692704621.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_pat['ServeDepthWidth'] = filtered_pat['ServeDepth'] + \"_\" + filtered_pat['ServeWidth']\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1692704621.py:25: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# 1. Filter for specific Score values\n",
    "selected_scores = ['0-0', '15-0', '0-15', '30-0', '0-30', '30-15', '15-30', \n",
    "                   '40-15', '15-40', '40-0', '0-40', '40-30', '30-40', \n",
    "                   '40-40', 'AD-40', '40-AD']\n",
    "filtered_pat = pat[pat['Score'].isin(selected_scores)]\n",
    "\n",
    "# 2. Concatenate ServeDepth and ServeWidth to create ServeDepthWidth\n",
    "filtered_pat['ServeDepthWidth'] = filtered_pat['ServeDepth'] + \"_\" + filtered_pat['ServeWidth']\n",
    "\n",
    "# 3. Group by Score and calculate proportions\n",
    "grouped = filtered_pat.groupby(['Score', 'ServeDepthWidth']).size().unstack(fill_value=0)\n",
    "proportions = grouped.div(grouped.sum(axis=1), axis=0) * 100  # Convert to percentages\n",
    "\n",
    "# 4. Plot stacked bar chart\n",
    "ax = proportions.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='viridis')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_title('ServeDepthWidth Distribution by Selected Scores (Percentage)', fontsize=14)\n",
    "ax.set_ylabel('Percentage', fontsize=12)\n",
    "ax.set_xlabel('Score', fontsize=12)\n",
    "ax.legend(title='ServeDepthWidth', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380d962",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "#### We observe that the serve distribution of each player during different moments of the games are not different. This may be due to the fact that the players themselves cannot always control the outcomes of the serve shot (they may have missed the first serve, or not hit the targeted position). It is understandable that professional players sometimes make mistakes. \n",
    "\n",
    "#### With this analysis and the regression models, we may conclude that the serve distribution in particular and serve performance in general does not play an extremely significant role in the players' performance at Grand Slam. It is even harder to keep the serve performance consistently, considering the long duration of each Grand Slam match (best of 5 instead of best of 3 like other tournaments). The dashboard below will partially reclaimed this argument, and will argue that elite players will have a higher percentage of winning long rallies compared to their non-elite compatriots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9205875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>0_0</th>\n",
       "      <th>CTL_B</th>\n",
       "      <th>CTL_BC</th>\n",
       "      <th>CTL_BW</th>\n",
       "      <th>CTL_C</th>\n",
       "      <th>CTL_W</th>\n",
       "      <th>NCTL_B</th>\n",
       "      <th>NCTL_BC</th>\n",
       "      <th>NCTL_BW</th>\n",
       "      <th>...</th>\n",
       "      <th>14_%</th>\n",
       "      <th>15+_%</th>\n",
       "      <th>total_deficit</th>\n",
       "      <th>avg_deficit</th>\n",
       "      <th>elite_numeric</th>\n",
       "      <th>avg_Forehand</th>\n",
       "      <th>avg_Backhand</th>\n",
       "      <th>Deep_Return%</th>\n",
       "      <th>avg_ace</th>\n",
       "      <th>avg_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian Mannarino</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.095238</td>\n",
       "      <td>42.335766</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-1.787879</td>\n",
       "      <td>0</td>\n",
       "      <td>13.909091</td>\n",
       "      <td>7.757576</td>\n",
       "      <td>35.521013</td>\n",
       "      <td>7.030303</td>\n",
       "      <td>2.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alejandro Davidovich Fokina</td>\n",
       "      <td>74.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>47.872340</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>7.472222</td>\n",
       "      <td>36.455696</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>3.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alex Bolt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>61.290323</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alex De Minaur</td>\n",
       "      <td>96.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>55.769231</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.395833</td>\n",
       "      <td>6.937500</td>\n",
       "      <td>35.233645</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>3.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alex Molcan</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>37.037037</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-2.352941</td>\n",
       "      <td>0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.705882</td>\n",
       "      <td>35.331230</td>\n",
       "      <td>5.529412</td>\n",
       "      <td>3.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player_name   0_0  CTL_B  CTL_BC  CTL_BW  CTL_C  CTL_W  \\\n",
       "0             Adrian Mannarino  45.0   27.0    50.0    27.0   87.0  315.0   \n",
       "2  Alejandro Davidovich Fokina  74.0   62.0    96.0    65.0   82.0  246.0   \n",
       "5                    Alex Bolt   2.0    4.0     3.0     3.0    8.0   41.0   \n",
       "6               Alex De Minaur  96.0   48.0   123.0    85.0  114.0  289.0   \n",
       "8                  Alex Molcan  34.0   13.0    29.0    22.0   56.0   82.0   \n",
       "\n",
       "   NCTL_B  NCTL_BC  NCTL_BW  ...       14_%      15+_%  total_deficit  \\\n",
       "0   116.0    276.0    316.0  ...  38.095238  42.335766          -59.0   \n",
       "2   292.0    359.0    301.0  ...  54.545455  47.872340           69.0   \n",
       "5    17.0     28.0     17.0  ...  38.461538  61.290323          -18.0   \n",
       "6   258.0    453.0    475.0  ...  70.588235  55.769231           90.0   \n",
       "8    95.0    169.0    151.0  ...  30.000000  37.037037          -40.0   \n",
       "\n",
       "   avg_deficit  elite_numeric  avg_Forehand  avg_Backhand  Deep_Return%  \\\n",
       "0    -1.787879              0     13.909091      7.757576     35.521013   \n",
       "2     1.916667              0     16.666667      7.472222     36.455696   \n",
       "5    -1.800000              0      4.800000      2.700000     42.857143   \n",
       "6     1.875000              0     15.395833      6.937500     35.233645   \n",
       "8    -2.352941              0     17.000000      8.705882     35.331230   \n",
       "\n",
       "     avg_ace    avg_df  \n",
       "0   7.030303  2.939394  \n",
       "2   4.416667  3.694444  \n",
       "5  10.400000  2.600000  \n",
       "6   5.625000  3.812500  \n",
       "8   5.529412  3.588235  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming player_stats is a pandas DataFrame\n",
    "player_stats = player_stats[player_stats.isnull().sum(axis=1) <= 15]\n",
    "\n",
    "player_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a90c6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"player_stats.csv\"\n",
    "player_stats.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8499b",
   "metadata": {},
   "source": [
    "# FINAL DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd8ca67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = false;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.4/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.4/dist/panel.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.4/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.4/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='3d422f21-b586-4df6-b7c3-0851190efac8'>\n",
       "  <div id=\"c71189a0-dd34-4bd4-9560-24be20f20bf3\" data-root-id=\"3d422f21-b586-4df6-b7c3-0851190efac8\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"7e2ad127-2fab-473c-86e0-b68e7f8c268a\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"3d422f21-b586-4df6-b7c3-0851190efac8\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"32340e71-8d40-4af3-aa60-3ab6be7fc000\",\"attributes\":{\"plot_id\":\"3d422f21-b586-4df6-b7c3-0851190efac8\",\"comm_id\":\"2f791bb6f4b54da99dfacc79b847e2e9\",\"client_comm_id\":\"bdde096529f0400da8b6189acc3cd1fe\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"7e2ad127-2fab-473c-86e0-b68e7f8c268a\",\"roots\":{\"3d422f21-b586-4df6-b7c3-0851190efac8\":\"c71189a0-dd34-4bd4-9560-24be20f20bf3\"},\"root_ids\":[\"3d422f21-b586-4df6-b7c3-0851190efac8\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "3d422f21-b586-4df6-b7c3-0851190efac8"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.Select: Providing a width-responsive sizing_mode ('stretch_width') and a fixed width is not supported. Converting fixed width to min_width. If you intended the component to be fully width-responsive remove the heightsetting, otherwise change it to min_height. To error on the incorrect specification disable the config.layout_compatibility option.\n",
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1051316115.py:372: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0, 0.7, 1])  # Leave space for the notes on the right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:50336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/vcnthth57d14bptc1cdgq9g80000gn/T/ipykernel_1296/1051316115.py:388: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(8, 6))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x297abf3d0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import panel as pn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# Initialize Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Title and Introduction\n",
    "header = pn.pane.Markdown(\"## Player Statistics Dashboard presented by Minh Trinh, collaborated with Professor Eren Bilen\")\n",
    "intro = pn.pane.Markdown(\"\"\"\n",
    "Welcome to the Complex Tennis Player Statistics Interactive Dashboard!\n",
    "This interactive dashboard illustrates a comprehensive overview of individual player statistics in Grand Slam events from 2019 to 2023. You can compare the selected players performance against the averages of other\n",
    "elite and non-elite players, as well as visualize their serve distribution.\"\"\")\n",
    "comparison_table_title = pn.pane.Markdown(\"\"\"\n",
    "### Comparison Table: Player vs Elite vs Non-Elite Statistics \n",
    "##### Elite players are the players with the best performances in Grand Slam from 2019-2023. The list includes: Novak Djokovic, Alexander Zverev, Andrey Rublev, Carlos Alcaraz, Casper Ruud, Daniil Medvedev, Dominic Thiem, Felix Auger Aliassime, Matteo Berrettini, Rafael Nadal, Roger Federer, Stefanos Tsitsipas\n",
    "\"\"\")\n",
    "# Sidebar Dropdown for Player Selection\n",
    "selected_player_widget = pn.widgets.Select(\n",
    "    name=\"Select Player\", \n",
    "    options=list(player_stats['player_name'].unique()),  # Convert to list\n",
    "    value=player_stats['player_name'].iloc[0],\n",
    "    width=200,\n",
    "    sizing_mode=\"stretch_width\"\n",
    ")\n",
    "image_path = \"novakthegoat.jpg\"  # Replace with the correct path if it's not in the working directory\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    sidebar_image = pn.layout.Column(\n",
    "        pn.pane.JPG(image_path, width=300, height=200),\n",
    "        align=\"center\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Image '{image_path}' not found. Using a placeholder.\")\n",
    "    sidebar_image = pn.pane.Markdown(\"### [Image Not Found]\")\n",
    "\n",
    "# Calculate Average Stats for Elite and Non-Elite Players\n",
    "elite_avg_stats = player_stats[player_stats[\"elite_numeric\"] == 1].mean(numeric_only=True)\n",
    "non_elite_avg_stats = player_stats[player_stats[\"elite_numeric\"] == 0].mean(numeric_only=True)\n",
    "\n",
    "# Function to create comparison table\n",
    "def create_comparison_table(selected_player):\n",
    "    player_data = player_stats[player_stats[\"player_name\"] == selected_player].iloc[0]\n",
    "    \n",
    "    comparison_table = pd.DataFrame({\n",
    "        \"Metric\": [\n",
    "            \"Grand Slam Matches Win%\",\"Avg 1st Serve Speed (KM/H)\", \"Avg 2nd Serve Speed (KM/H)\", \"Matches Played\", \n",
    "            \"Aces per Match\", \"Double Faults per Match\", \"Deep Return %\",\n",
    "             \"1st Serve In per Match\",\n",
    "            \"1st Serve Won per Match\", \"2nd Serve Won per Match\", \"Break Points Saved per Match\",\n",
    "            \"Break Points Faced per Match\", \"Break Points Saved Percentage\", \"Deficit per Match\",\n",
    "            \"Forehand Winners per Match\", \"Backhand Winners per Match\", \"0-4 Rallies Win %\", \"5-8 Rallies Win %\"\n",
    "            , \"9+ Rallies Win %\"\n",
    "        ],\n",
    "        f\"{selected_player}'s Stats\": [\n",
    "            player_data[\"Match_Win_Percentage\"],player_data[\"Avg_1st_ServeSpeed\"], player_data[\"Avg_2nd_ServeSpeed\"], player_data[\"match_played\"],\n",
    "            player_data[\"avg_ace\"], player_data[\"avg_df\"], player_data[\"Deep_Return%\"],\n",
    "            player_data[\"1stIn_per_match\"], \n",
    "            player_data[\"1stWon_per_match\"], player_data[\"2ndWon_per_match\"], player_data[\"bpSaved_per_match\"],\n",
    "            player_data[\"bpFaced_per_match\"], player_data[\"bpSaved%\"], player_data[\"avg_deficit\"],\n",
    "            player_data[\"avg_Forehand\"], player_data[\"avg_Backhand\"],player_data[\"0-4_%\"],\n",
    "            player_data[\"5-8_%\"],player_data[\"9+_%\"]\n",
    "        ],\n",
    "        \"Elite Players' Average\": [\n",
    "            elite_avg_stats[\"Match_Win_Percentage\"],elite_avg_stats[\"Avg_1st_ServeSpeed\"], elite_avg_stats[\"Avg_2nd_ServeSpeed\"], elite_avg_stats[\"match_played\"],\n",
    "            elite_avg_stats[\"avg_ace\"], elite_avg_stats[\"avg_df\"], elite_avg_stats[\"Deep_Return%\"],\n",
    "            elite_avg_stats[\"1stIn_per_match\"],\n",
    "            elite_avg_stats[\"1stWon_per_match\"], elite_avg_stats[\"2ndWon_per_match\"], elite_avg_stats[\"bpSaved_per_match\"],\n",
    "            elite_avg_stats[\"bpFaced_per_match\"], elite_avg_stats[\"bpSaved%\"], elite_avg_stats[\"avg_deficit\"],\n",
    "            elite_avg_stats[\"avg_Forehand\"], elite_avg_stats[\"avg_Backhand\"],elite_avg_stats[\"0-4_%\"],\n",
    "            elite_avg_stats[\"5-8_%\"],elite_avg_stats[\"9+_%\"]\n",
    "        ],\n",
    "        \"Non-Elite Players' Average\": [\n",
    "            non_elite_avg_stats[\"Match_Win_Percentage\"],non_elite_avg_stats[\"Avg_1st_ServeSpeed\"], non_elite_avg_stats[\"Avg_2nd_ServeSpeed\"], non_elite_avg_stats[\"match_played\"],\n",
    "            non_elite_avg_stats[\"avg_ace\"], non_elite_avg_stats[\"avg_df\"], elite_avg_stats[\"Deep_Return%\"],\n",
    "            non_elite_avg_stats[\"1stIn_per_match\"],\n",
    "            non_elite_avg_stats[\"1stWon_per_match\"], non_elite_avg_stats[\"2ndWon_per_match\"], non_elite_avg_stats[\"bpSaved_per_match\"],\n",
    "            non_elite_avg_stats[\"bpFaced_per_match\"], non_elite_avg_stats[\"bpSaved%\"], non_elite_avg_stats[\"avg_deficit\"],\n",
    "           non_elite_avg_stats[\"avg_Forehand\"], non_elite_avg_stats[\"avg_Backhand\"], non_elite_avg_stats[\"0-4_%\"],\n",
    "            non_elite_avg_stats[\"5-8_%\"],non_elite_avg_stats[\"9+_%\"]\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Ensure that values are numeric and format with 2 decimals without trailing zeros\n",
    "    for col in comparison_table.columns[1:]:\n",
    "        comparison_table[col] = comparison_table[col].apply(lambda x: f\"{x:.2f}\".rstrip('0').rstrip('.'))\n",
    "    \n",
    "    return comparison_table\n",
    "\n",
    "def highlight_values(row):\n",
    "    \"\"\"\n",
    "    Apply color formatting to highlight the highest and lowest values in a row.\n",
    "    Green for the largest value, red for the smallest value.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row of numeric values.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of CSS styles for each value in the row.\n",
    "    \"\"\"\n",
    "    # Convert row to numeric values, ignoring non-numeric values\n",
    "    numeric_values = pd.to_numeric(row, errors='coerce')\n",
    "\n",
    "    # Identify max and min values (ignoring NaNs)\n",
    "    max_val = numeric_values.max()\n",
    "    min_val = numeric_values.min()\n",
    "\n",
    "    # Apply colors based on max and min values\n",
    "    colors = [\n",
    "        \"color: green;\" if value == max_val else\n",
    "        \"color: red;\" if value == min_val else\n",
    "        \"\"\n",
    "        for value in numeric_values\n",
    "    ]\n",
    "    return colors\n",
    "# Function to update the dashboard dynamically\n",
    "def update_dashboard(event):\n",
    "    selected_player = selected_player_widget.value\n",
    "    comparison_table = create_comparison_table(selected_player)\n",
    "    \n",
    "    # Apply styling to the table\n",
    "    styled_table = (\n",
    "        comparison_table.set_index(\"Metric\")\n",
    "        .style.apply(highlight_values, axis=1, subset=[f\"{selected_player}'s Stats\", \"Elite Players' Average\", \"Non-Elite Players' Average\"])\n",
    "    )\n",
    "    \n",
    "    comparison_table_pane.object = styled_table\n",
    "\n",
    "# Create initial comparison table for the first player\n",
    "comparison_table_pane = pn.pane.DataFrame(create_comparison_table(selected_player_widget.value), width=600, height=200)\n",
    "\n",
    "# Watch the player selection to update the table\n",
    "selected_player_widget.param.watch(update_dashboard, 'value')\n",
    "\n",
    "\n",
    "# Watch the player selection to update the table\n",
    "selected_player_widget.param.watch(update_dashboard, 'value')\n",
    "\n",
    "note = pn.pane.Markdown(\"\"\"\n",
    "**Note:**\n",
    "- The comparison table shows the player's statistics against the averages of elite and non-elite players.\n",
    "- **Elite players** are those ranked in the top 10, while **Non-Elite players** are those ranked outside of the top 10.\n",
    "- This dashboard helps to visualize the player's performance in comparison to their peers in Grand Slam events.\n",
    "\"\"\", width=400, height=200)\n",
    "\n",
    "# Arrange the comparison table and the note side by side\n",
    "layout = pn.layout.Column(\n",
    "    pn.Row(comparison_table_pane, note),\n",
    "    selected_player_widget\n",
    ")\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "# Define court regions\n",
    "regions_ctl = {\n",
    "    'W': {'x_min': 14, 'x_max': 16.25, 'y_min': 13, 'y_max': 18, 'color': '#d7d7d7'},\n",
    "    'BW': {'x_min': 16.25, 'x_max': 18.5, 'y_min': 13, 'y_max': 18, 'color': '#1f1f1f'},\n",
    "    'B': {'x_min': 18.5, 'x_max': 20.75, 'y_min': 13, 'y_max': 18, 'color': '#141414'},\n",
    "    'BC': {'x_min': 20.75, 'x_max': 23, 'y_min': 13, 'y_max': 18, 'color': '#2d2d2d'},\n",
    "    'C': {'x_min': 23, 'x_max': 25, 'y_min': 13, 'y_max': 18, 'color': '#484848'}\n",
    "}\n",
    "regions_nctl = {\n",
    "    'W': {'x_min': 14, 'x_max': 16.25, 'y_min': 18, 'y_max': 23, 'color': '#4d4d4d'},\n",
    "    'BW': {'x_min': 16.25, 'x_max': 18.5, 'y_min': 18, 'y_max': 23, 'color': '#a7a7a7'},\n",
    "    'B': {'x_min': 18.5, 'x_max': 20.75, 'y_min': 18, 'y_max': 23, 'color': '#636363'},\n",
    "    'BC': {'x_min': 20.75, 'x_max': 23, 'y_min': 18, 'y_max': 23, 'color': '#888888'},\n",
    "    'C': {'x_min': 23, 'x_max': 25, 'y_min': 18, 'y_max': 23, 'color': '#ffffff'}\n",
    "}\n",
    "\n",
    "# Define label positions\n",
    "label_positions = {\n",
    "    'NCTL_C': {'x': 45, 'y': 35},\n",
    "    'NCTL_BC': {'x': 40, 'y': 45},\n",
    "    'NCTL_B': {'x': 25, 'y': 45},\n",
    "    'NCTL_BW': {'x': 15, 'y': 35},\n",
    "    'NCTL_W': {'x': 5, 'y': 45},\n",
    "    'CTL_C': {'x': 45, 'y': 15},\n",
    "    'CTL_BC': {'x': 42, 'y': 5},\n",
    "    'CTL_B': {'x': 22, 'y': 7},\n",
    "    'CTL_BW': {'x': 7, 'y': 5},\n",
    "    'CTL_W': {'x': 5, 'y': 15}\n",
    "}\n",
    "\n",
    "# Function to prepare serve data for a player\n",
    "def prepare_player_serve_data(player_name):\n",
    "    player_data = player_stats[player_stats['player_name'] == player_name]\n",
    "    serve_data = []\n",
    "    for col in player_data.columns:\n",
    "        if col.startswith(\"CTL\") or col.startswith(\"NCTL\"):\n",
    "            serve_depth, serve_width = col.split(\"_\")\n",
    "            count = player_data[col].values[0]\n",
    "            serve_data.append({\n",
    "                \"ServeDepth\": serve_depth,\n",
    "                \"ServeWidth\": serve_width,\n",
    "                \"count\": count\n",
    "            })\n",
    "    serve_df = pd.DataFrame(serve_data)\n",
    "    total_shots = serve_df['count'].sum()\n",
    "    serve_df['percentage'] = (serve_df['count'] / total_shots) * 100\n",
    "    return serve_df\n",
    "\n",
    "# Function to add labels\n",
    "def add_labels_for_regions(data_counts, label_positions, region_type, regions):\n",
    "    for _, row in data_counts.iterrows():\n",
    "        serve_width = row['ServeWidth']\n",
    "        count = row['count']\n",
    "        percentage = row['percentage']\n",
    "\n",
    "        # Construct the key dynamically\n",
    "        label_key = f\"{region_type}_{serve_width}\"\n",
    "\n",
    "        # Check if label_key exists in label_positions\n",
    "        if label_key in label_positions:\n",
    "            x = label_positions[label_key]['x']\n",
    "            y = label_positions[label_key]['y']\n",
    "        else:\n",
    "            raise ValueError(f\"Label position for '{label_key}' not defined in label_positions.\")\n",
    "\n",
    "        # Label content\n",
    "        label = f\"{region_type} {serve_width}\\n{count} shots\\n({percentage:.2f}%)\"\n",
    "        \n",
    "        # Draw line to region center\n",
    "        region_center_x = (regions[serve_width]['x_min'] + regions[serve_width]['x_max']) / 2\n",
    "        region_center_y = (regions[serve_width]['y_min'] + regions[serve_width]['y_max']) / 2\n",
    "        plt.plot([x, region_center_x], [y, region_center_y], color='white', lw=1)\n",
    "\n",
    "        # Add label background box\n",
    "        label_box = patches.FancyBboxPatch(\n",
    "            (x - 6, y - 3.5), 12, 7, boxstyle=\"round,pad=0.3\",\n",
    "            edgecolor='none', facecolor=regions[serve_width]['color'], alpha=0.6\n",
    "        )\n",
    "        plt.gca().add_patch(label_box)\n",
    "        \n",
    "        # Add text\n",
    "        plt.text(x, y, label, fontsize=9, ha='center', va='center', color='white')\n",
    "\n",
    "# Function to dynamically assign colors based on serve percentages\n",
    "def assign_dynamic_colors(regions, data_counts):\n",
    "    \"\"\"\n",
    "    Assign colors to regions dynamically based on serve percentages, using a seismic color scale.\n",
    "\n",
    "    Args:\n",
    "        regions (dict): Dictionary of regions (CTL or NCTL).\n",
    "        data_counts (pd.DataFrame): Serve data with percentage for each region.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated regions with dynamically assigned colors.\n",
    "    \"\"\"\n",
    "    # Normalize percentages between -1 and 1 for seismic color mapping\n",
    "    percentages = data_counts['percentage'].values\n",
    "    normalized = 2 * ((percentages - percentages.min()) / (percentages.max() - percentages.min())) - 1 if len(percentages) > 1 else [0] * len(percentages)\n",
    "\n",
    "    # Map normalized values to the seismic color scale\n",
    "    for region, norm_val in zip(data_counts['ServeWidth'], normalized):\n",
    "        if norm_val < 0:\n",
    "            # Blue to white (low values): interpolate between Blue (#0000FF) and White (#FFFFFF)\n",
    "            r = int(255 * (1 + norm_val))  # Increase red\n",
    "            g = int(255 * (1 + norm_val))  # Increase green\n",
    "            b = 255  # Blue remains max\n",
    "        else:\n",
    "            # White to red (high values): interpolate between White (#FFFFFF) and Red (#FF0000)\n",
    "            r = 255  # Red remains max\n",
    "            g = int(255 * (1 - norm_val))  # Decrease green\n",
    "            b = int(255 * (1 - norm_val))  # Decrease blue\n",
    "\n",
    "        color = f'#{r:02x}{g:02x}{b:02x}'  # Seismic hex color\n",
    "        regions[region]['color'] = color\n",
    "\n",
    "    return regions\n",
    "\n",
    "def load_court_image():\n",
    "    court_img_path = '/Users/minhtrinh/wim/wimbledon_grass_court.jpg'\n",
    "    if os.path.exists(court_img_path):\n",
    "        return mpimg.imread(court_img_path)\n",
    "    else:\n",
    "        print(\"Court image not found. Using a placeholder.\")\n",
    "        return np.ones((500, 500, 3))  # White placeholder image\n",
    "    \n",
    "\n",
    "def plot_combined_serve_distribution(player_name):\n",
    "    \"\"\"\n",
    "    Plot the combined serve distribution for the selected player.\n",
    "    Args:\n",
    "        player_name (str): Name of the selected player.\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The plot figure for Panel rendering.\n",
    "    \"\"\"\n",
    "    # Prepare serve data\n",
    "    serve_df = prepare_player_serve_data(player_name)\n",
    "\n",
    "    # Separate CTL and NCTL data\n",
    "    ctl_data = serve_df[serve_df['ServeDepth'] == 'CTL']\n",
    "    nctl_data = serve_df[serve_df['ServeDepth'] == 'NCTL']\n",
    "\n",
    "    # Assign dynamic colors based on percentages\n",
    "    assign_dynamic_colors(regions_ctl, ctl_data)\n",
    "    assign_dynamic_colors(regions_nctl, nctl_data)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))  # Expanded figure size\n",
    "    court_img = load_court_image()\n",
    "    ax.imshow(court_img, extent=[0, 50, 0, 50])\n",
    "    ax.set_xlim(0, 50)\n",
    "    ax.set_ylim(0, 50)\n",
    "\n",
    "    # Plot CTL regions\n",
    "    for region, data in regions_ctl.items():\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (data['x_min'], data['y_min']),\n",
    "            data['x_max'] - data['x_min'], \n",
    "            data['y_max'] - data['y_min'], \n",
    "            linewidth=1, edgecolor='black', facecolor=data['color'], alpha=0.5\n",
    "        ))\n",
    "\n",
    "    # Plot NCTL regions\n",
    "    for region, data in regions_nctl.items():\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (data['x_min'], data['y_min']),\n",
    "            data['x_max'] - data['x_min'], \n",
    "            data['y_max'] - data['y_min'], \n",
    "            linewidth=1, edgecolor='black', facecolor=data['color'], alpha=0.5\n",
    "        ))\n",
    "\n",
    "    # Add labels for CTL and NCTL regions\n",
    "    add_labels_for_regions(ctl_data, label_positions, 'CTL', regions_ctl)\n",
    "    add_labels_for_regions(nctl_data, label_positions, 'NCTL', regions_nctl)\n",
    "\n",
    "    # Titles and axis labels\n",
    "    notes = (\n",
    "        \"Notes:\\n\"\n",
    "        \"1. ServeWidth: Categorizes serve placement horizontally:\\n\"\n",
    "        \"   - W: Wide\\n\"\n",
    "        \"   - BW: Body Wide\"\n",
    "        \"   - B: Body\\n\"\n",
    "        \"   - BC: Body Center\"\n",
    "        \"   - C: Center\\n\\n\"\n",
    "        \"2. ServeDepth: Categorizes serve placement vertically:\\n\"\n",
    "        \"   - CTL: Close to the Service Line\\n\"\n",
    "        \"   - NCTL: Not Close to the Service Line\\n\\n\"\n",
    "        \"3. Dynamic Colors: Represent the proportion of serves in each region, with darker red shades indicating higher percentages, and darker blye shades indicating lower percentages.\"\n",
    "    )\n",
    "\n",
    "    # Add the notes to the right of the graph\n",
    "    ax_notes = fig.add_axes([0.65, 0.1, 0.2, 0.8])  # Add new axes for the notes\n",
    "    ax_notes.axis('off')  # Turn off axes for the notes\n",
    "    ax_notes.text(\n",
    "        0, 1, notes, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8), wrap=True\n",
    "    )\n",
    "    # Add a color legend below the notes\n",
    "    ax_colorbar = fig.add_axes([0.65, 0.5, 0.25, 0.02])  # Position for the colorbar\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"\", [\"darkblue\", \"red\"])\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=100)\n",
    "    cb = plt.colorbar(\n",
    "        plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "        cax=ax_colorbar, orientation='horizontal'\n",
    "    )\n",
    "    cb.set_label(\"Percentage of Serves (%)\", fontsize=10)\n",
    "    cb.ax.tick_params(labelsize=8)\n",
    "    \n",
    "    ax.set_title(f'Serve Distribution by {player_name}', fontsize=18, weight='bold')\n",
    "    ax.set_xlabel('Serve Width', fontsize=15)\n",
    "    ax.set_ylabel('Serve Depth', fontsize=15, rotation=0, labelpad=40)\n",
    "\n",
    "    # Adjust layout to avoid clipping\n",
    "    plt.tight_layout(rect=[0, 0, 0.7, 1])  # Leave space for the notes on the right\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_player_line_graph(player_name):\n",
    "    # Get the percentages for the player\n",
    "    player_data = player_stats[player_stats['player_name'] == player_name][['1_%', '2_%', '3_%', '4_%', \n",
    "                                                                            '5_%', '6_%', '7_%', '8_%', '9_%', '10_%', \n",
    "                                                                            '11_%', '12_%', '13_%', '14_%', '15+_%']].values.flatten()\n",
    "    \n",
    "    # Get the average percentages for elite players\n",
    "    elite_data = player_stats[player_stats['elite_numeric'] == 1][['1_%', '2_%', '3_%', '4_%', \n",
    "                                                                   '5_%', '6_%', '7_%', '8_%', '9_%', '10_%', \n",
    "                                                                   '11_%', '12_%', '13_%', '14_%', '15+_%']].mean().values\n",
    "\n",
    "    # Plot the line graph\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(range(1, 16), player_data, marker='o', color='b', label=player_name)\n",
    "    ax.plot(range(1, 16), elite_data, marker='v', color='r', label='Elite Players (Average)')\n",
    "\n",
    "    ax.set_title(f'Rally Category Percentages for {player_name}')\n",
    "    ax.set_xlabel('Rally Length (Points)')\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.set_xticks(range(1, 16))\n",
    "    ax.set_xticklabels([f'{i}' for i in range(1, 16)])\n",
    "    ax.legend()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Updated: Panel integration for serve distribution\n",
    "serve_distribution_pane = pn.pane.Matplotlib(\n",
    "    plot_combined_serve_distribution(selected_player_widget.value), \n",
    "    width=800, height=600\n",
    ")\n",
    "# Create a new Matplotlib pane for the line graph\n",
    "line_graph_pane = pn.pane.Matplotlib(\n",
    "    plot_player_line_graph(selected_player_widget.value), \n",
    "    width=800, height=600\n",
    ")\n",
    "\n",
    "# Updated: Watch player selection for serve graph and line graph\n",
    "def update_graphs(event):\n",
    "    # Update the serve distribution graph\n",
    "    serve_distribution_pane.object = plot_combined_serve_distribution(selected_player_widget.value)\n",
    "    \n",
    "    # Update the line graph\n",
    "    line_graph_pane.object = plot_player_line_graph(selected_player_widget.value)\n",
    "\n",
    "# Watch for player selection changes\n",
    "selected_player_widget.param.watch(update_graphs, 'value')\n",
    "\n",
    "# Updated: Create comparison table dynamically\n",
    "comparison_table_pane = pn.pane.DataFrame(\n",
    "    create_comparison_table(selected_player_widget.value), \n",
    "    width=600, height=400\n",
    ")\n",
    "\n",
    "# Updated: Dynamic dashboard layout with line graph\n",
    "template = pn.template.FastListTemplate(\n",
    "    title='Complex Professional Tennis Player Statistics in Grand Slams from 2019-2023', \n",
    "    sidebar=[\n",
    "        pn.pane.Markdown(\"# Complex Player Statistics Interactive Dashboard\"), \n",
    "        pn.pane.Markdown(\"### This dashboard is presented by Minh Trinh in collaboration with professor Eren Bilen. \\n Contact: quangminh711@gmail.com\"),\n",
    "        intro,\n",
    "        sidebar_image,\n",
    "        selected_player_widget\n",
    "    ],\n",
    "    main=[\n",
    "        pn.Row(\n",
    "            pn.Column(width=150),\n",
    "            pn.Column(comparison_table_title, comparison_table_pane, margin=(0, 25), width=300)\n",
    "        ),\n",
    "        pn.Row(\n",
    "            serve_distribution_pane\n",
    "        ),\n",
    "        pn.Row(\n",
    "            line_graph_pane  # Add the line graph below the serve distribution\n",
    "        )\n",
    "    ],\n",
    "    accent_base_color=\"#90EE90\",  \n",
    "    header_background=\"#90EE90\", \n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "template.servable()\n",
    "template.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbaa3e2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "#### This dashboard includes a table that compares selected player with the average elite and non-elite players respectively, excluding the selected player within the calculation. The second graph is a visualization chart that displays the serve distribution of the selected player. Finally, the third graph is a visualization line chart that displays the win percentage of the selected players, grouping by 1 to 15+ rally counts. \n",
    "\n",
    "#### We may observe a considerable difference in the rally counts statistics (within the table and the line chart), while experiencing a less notable difference in serve statistics between elite players, and non-elite players. This suggests that elite players, although may or may not have a decent serve performance, will achieve greater results than non-elite players because they have better combat skills and usually win in long rallies. This is true, especially considering the modern time meta of tennis has evolved compared to the serve-volley era,  as current top players are mostly aggressive baseliners, who can attack and defend well in the baseline, and try hard to take control during the game. This is the main difference between elite players who wins tournaments and advanced deeply in the Grand Slam tournament, and non-elite players who may not achieve as much as the elite counterparts. The research suggests that players should improve their groundstroke skills in order to increase the win percentage of long rallies, along with enhancing the consistency of serve performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8fc9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats.to_excel('player_stats.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27fd2215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11          Alexander Zverev\n",
      "19             Andrey Rublev\n",
      "38            Carlos Alcaraz\n",
      "39               Casper Ruud\n",
      "50           Daniil Medvedev\n",
      "57             Dominic Thiem\n",
      "73     Felix Auger Aliassime\n",
      "142        Matteo Berrettini\n",
      "156           Novak Djokovic\n",
      "170             Rafael Nadal\n",
      "178            Roger Federer\n",
      "189       Stefanos Tsitsipas\n",
      "Name: player_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter players with elite_numeric equal to 1\n",
    "elite_players = player_stats[player_stats['elite_numeric'] == 1]\n",
    "\n",
    "# Display player names\n",
    "elite_player_names = elite_players['player_name']\n",
    "print(elite_player_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b267fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
